<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[突然情绪爆发，暴哭了一场]]></title>
    <url>%2Fothers%2Fi-just-cried.html</url>
    <content type="text"><![CDATA[刚才久违的暴哭了一场。嘛，其实也没暴走多久，满打满算，也就暴走了一个刘强东那么久。无奈，最近一段时间里，发生了太多闹心的事。有多闹心呢？你想想，能让一个网瘾少年连游戏都不想玩了，你就想这是有多闹心吧。已经不记得上次哭是什么时候了，甚至，已经忘了该怎么哭了。我说我连该怎么引导自己哭出来，都是查的知乎，你信吗。当然也不是没来由的就哭了，主要还是最近心力交瘁，最后因为一件屁事情绪爆发了。您要是想看个来龙去脉呢，那就继续往下，看我这个祥林嫂的絮叨吧。起初呢，是年中那会，经过哥们啊、领导们啊、当然还有我自己的努力，争取到了一个外派的机会嗯，这里插句嘴，其实现在我心里都抱着一点歉意的，因为当时领导也是有在挽留的，怎奈当时王八吃秤砣，铁了心的要出去看看这个大世界，最后就还是出来了。那既然外派出来了，那当然是想要好好的干啊。一方面呢，当时本来就是奔着这边有没玩过的技术，我是来学习的；另一方面呢，我毕竟是外派出来的，也挂着咱老东家的脸呢，出来混，丢啥不能丢老东家的脸呐。头先派我俩活，一个我忘了是啥了，另一个是给现有的一个系统设计并新增一个功能。这两次呢，也没跟我规定啥时候交货。我寻思着，按照这个难度，我设计啊编码啊给你做的精细点，一星期也差不多吧。结果周五验收的时候，负责人表示，我觉得你时间有点太长了。第一个活，负责人表示我快了一天就搞定，最慢也就三天，按你这效率我不如不要你了。第二个呢，负责人表示，这个应该四天就能解决的。这就不太对了吧。开始的时候也没有定一个deadline，可最后又说你不应该花这么多时间，这是什么操作啊？第二个活呢，我当时上交设计文档的时候，负责人表示没有什么要修改的，那么我就按照我自己的设计稿去做了。可到了交货的时候，却砍了一个功能。为啥我要把这个被砍了的功能拎出来说呢？因为那天上午，我就是在写这个功能。如果一开始就砍了不要，那我真的确确实实就只花了四天就完成了。当时想，算了算了，屁大点事，懒得反驳了，没劲。大不了我后面再证明我自己嘛。但是我错了。在上面发生的事情之后不久，我们开始从头设计和开发一个新的系统。而今天这次暴走，也是从这时候开始埋下了雷。在这个新项目开始不久，某一天，老东家那边的领导跟我讲，这边对我的效率好像不太满意，有一点不想再要我的意思。我一听，这不行啊。真就这么给我踹回去了，我无所谓，可是这多少会影响那哥们，和老东家的面子啊。你看啊，咱哥们，又是拼缝，又是联系，里外里没少折腾，最后就整进来这么个怂蛋，这要是后面咱哥们再想介绍谁过来，那他领导不也得犯嘀咕，他可别再给我整个怂蛋来啊。再看咱老东家，也是费劲巴拉的没少折腾了，结果这废物没干几天就让踹回去了，脸上也不好看啊。那咋整呢？废话，更玩命的干呗。豁出去命挣个脸皮呗。可事实整明，我还是 too young too naive 了。脸皮没那么好挣，但是精神却可以消耗的很快。从谈话之后，我就开始5*8的满负载工作。去卫生间，要快。喝水，要快。任何事，都不能影响我的进度。然后，有一天，就在临下班的时候，突然一阵头晕，我发现我的右眼的上半部分，看不见了。具体是什么症状呢？就像是一张损坏的图片。下半部分还是画面本来的样子。而上半部分，只剩下一片灰色。所幸，不是永久的。它只持续了不到一分钟。但是，我很害怕。我怕下次，就变成了一只眼睛半只瞎。我怕下次，就变成了两只眼睛一只瞎。当天挂了眼科急诊，第二天又挂了眼科门诊。好在经过各种检查，眼睛没有任何问题，诊断是一时性的供血不足。而且时间很短，没有对眼睛造成什么永久性的损伤。但是大夫后面说了一句话，让我不淡定了。“这种一过性的症状，通常不是眼睛的病变，而有可能是脑部的问题。”啥？老子年纪轻轻的，脑子就坏了？老子不答应！可我不答应没用啊，还是得拿诊断结果说话。再联系到那段时间总有右脑隐隐的偏头疼，所以也害怕是有肿瘤或者血栓在里面。于是就先后做了脑CT和MRI。又是各种请假。而且都这种情况了，我个废物还在考虑会不会拖团队的后腿。最后结果出来，也算是意料之中，检查都是正常。脑子里没有什么不该有的东西。血管也很通畅。死不掉，也瘫不了。悬下的心，算是放下了。既然没事了，那就继续干活吧。可是好景不长，没过一两天，右耳开始感觉耳鸣。一开始没管它，结果越是不管，声音越是大。正巧那两天虫子开始叫起来。我一时分不清是真的耳鸣，还是虫子太响。既然有疑惑，那就得去查。越拖着，疑心越重，没病都能拖出癔症。其实我是个很胆小的人。我害怕的，不是虫子骑脸，不是被疯子攮了。我怕的是，突然生大病，让远在半个中国以北的爹妈操碎心。看耳朵的时候，大夫倒是干脆，直接就说，耳屎太多了。开了瓶药，滴两天，把耳屎泡软了之后，找大夫给我取出来，就解决了。但是这事吧，它就不能平平稳稳的过去。取耳屎的前一天晚上，滴完了药之后，耳朵眼里开始觉得肿胀，而且，右耳几乎听不见了。我干哦！最后一天晚上都不让我好好过吗？而且急诊又没有耳鼻喉科！玩我呢吧！没办法求助万能的网络，结果是，耳屎彻底泡发了，涨起来堵住了耳道，造成传导性耳聋。哦。耳屎堵了啊。好吧睡觉。明天给孙子掏出来。第二天，也就是昨天，一大早心事重重的就醒了。赶了早班车，挂最早的号，去掏耳屎。中间发生了一个插曲。大夫掏耳屎用的是一个吸气的管子，来把耳屎吸出来。而这个管子，让我弄堵住了。是的耳屎太多把管子堵了。大夫都一脸很受不了的表情，说这玩意都给堵了。吸完右耳吸左耳。你以为吸完了就完了？右耳里面，还有块钉子户你敢信？我还得滴两天药水，再过来掏一次。然后一整天去体检、去退还光猫，这些杂事就按下不表。晚上回去之后，也不知道是心太累，还是天太热，只觉得心烦意乱。哥几个联机打游戏，我都没法专心的去玩，不知道思绪在哪，一团乱麻。想着，也到了吃饭的时候了吧，于是就去做饭。做饭的时候，也是心神不宁。菜出来了，吃了一口，咸，没法吃。这时候，突然情绪就爆发了。为什么？为什么就这么多破事？为什么工作也干不好，身体也养不好，就连菜都炒不好？当时就觉得想哭。但是，又哭不出来。就像前两天，上海一位住户，住着数百万的房子，却在台风天坏了马桶，蹲地痛哭。区别只是，我没哭出来。忍着恶心，扔掉饭菜，出门觅食。虽然当时一点胃口都没有，但还是强迫自己吃了一碗小馄饨。因为，任由自己的坏心情折腾自己，只会让自己离抑郁更近一步。老子，不答应。老子，要乐呵的活着。然后就是一觉醒来，到了今天5点。时间是睡饱了，可是精神还是没有恢复。早饭是逼着自己吃的。想出去走走，结果隔一分钟换一个目的地。而且，还是半憋着想哭。这不是个事，这样下去，解决不了。这样下去，老子要崩。果断掉头回住处。上网搜，“想哭哭不出来”。嗯，网络就是好，各路大神给支招。挑了个简单的，只需要三步。刚做完一步半，感觉就上来了。眼泪啊，kua的一下，就出来了。来的快，去的也快。感觉已经哭爽了，再也哭不出来之后，整理思绪，写下了这些絮絮叨叨的东西。果然啊，心情不好的时候，哭一场，就什么都过去了。谢谢您耐着性子，跟着这个胆小的家伙，回顾了一下这段波折的人生。我写这么多呢，就是为了发泄一下。您呢，就当看了一篇文笔拙劣的小说吧。$EOF.]]></content>
      <categories>
        <category>其他</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[使用Docker配置Redis哨兵]]></title>
    <url>%2Fdatabase%2FRedis%2Fredis-sentinel-in-docker.html</url>
    <content type="text"><![CDATA[接上文使用Docker配置Redis主从复制完成之后，这篇文章主要介绍如何使用Docker在本机搭建Redis的哨兵，内容包括涉及的目录结构、docker-compose.yml的编写。目录结构本文将采用如下的目录结构，其中data目录将用于存放各个容器的数据，server目录存放docker-compose.yml以及针对master和slave节点的配置文件，sentinel目录存放哨兵的配置文件和docker-compose.yml。123456789101112131415.├── data│ ├── redis-master│ │ └── dump.rdb│ ├── redis-slave-1│ │ └── dump.rdb│ └── redis-slave-2│ └── dump.rdb├── sentinel│ ├── docker-compose.yml│ └── redis-sentinel.conf└── server ├── docker-compose.yml ├── redis-master.conf └── redis-slave.conf配置哨兵编辑redis-sentinel.conf，修改下列配置：12345678910111213141516171819# 接受来自外部的连接bind 0.0.0.0# 哨兵的端口号# 因为各个哨兵节点会运行在单独的Docker容器中# 所以无需担心端口重复使用port 26379# 配置哨兵的监控参数# 格式：sentinel monitor &lt;master-name&gt; &lt;ip&gt; &lt;redis-port&gt; &lt;quorum&gt;# master-name是为这个被监控的master起的名字# ip是被监控的master的IP或主机名。因为Docker容器之间可以使用容器名访问，所以这里写master节点的容器名# redis-port是被监控节点所监听的端口号# quorom设定了当几个哨兵判定这个节点失效后，才认为这个节点真的失效了sentinel monitor local-master redis-server-master 6379 2# 连接主节点的密码# 格式：sentinel auth-pass &lt;master-name&gt; &lt;password&gt;sentinel auth-pass local-master redis配置及启动容器编写docker-compose.yml这里继续使用docker-compose管理容器。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263---version: '3'services: # 哨兵的数量应是奇数，以便于哨兵通过投票来作出决策 redis-sentinel-1: image: redis container_name: redis-sentinel-1 restart: always ports: # 向外暴露26379端口 - 26379:26379 networks: default: ipv4_address: 10.1.0.5 volumes: # 将哨兵配置文件和存放数据的文件夹挂载到容器内 - ./redis-sentinel.conf:/usr/local/etc/redis/redis-sentinel.conf - ../data/redis-sentinel-1:/data sysctls: # 设定容器的内核参数，以消除Redis启动过程中的一个warning net.core.somaxconn: '511' # 根据指定的配置文件来启动Redis哨兵 command: ["redis-sentinel", "/usr/local/etc/redis/redis-sentinel.conf"] redis-sentinel-2: image: redis container_name: redis-sentinel-2 restart: always ports: - 26380:26379 networks: default: ipv4_address: 10.1.0.6 volumes: - ./redis-sentinel.conf:/usr/local/etc/redis/redis-sentinel.conf - ../data/redis-sentinel-2:/data sysctls: net.core.somaxconn: '511' command: ["redis-sentinel", "/usr/local/etc/redis/redis-sentinel.conf"] redis-sentinel-3: image: redis container_name: redis-sentinel-3 restart: always ports: - 26381:26379 networks: default: ipv4_address: 10.1.0.7 volumes: - ./redis-sentinel.conf:/usr/local/etc/redis/redis-sentinel.conf - ../data/redis-sentinel-3:/data sysctls: net.core.somaxconn: '511' command: ["redis-sentinel", "/usr/local/etc/redis/redis-sentinel.conf"]networks: default: external: # 因为哨兵容器需要与服务端容器运行在同一网络内 # 所以这里指定了一个外部的网络 # 网络名参考《使用Docker配置Redis主从复制》中的注释 name: server_redis-cluster启动容器这里同样使用docker-compose up -d启动容器，然后使用redis-cli连接到哨兵节点，连接成功后，可以使用info sentinel检查哨兵的信息。12345678127.0.0.1:26379&gt; info sentinel# Sentinelsentinel_masters:1sentinel_tilt:0sentinel_running_scripts:0sentinel_scripts_queue_length:0sentinel_simulate_failure_flags:0master0:name=local-master,status=ok,address=10.1.0.2:6379,slaves=2,sentinels=1其中，sentinel_masters:1说明这个哨兵在监控一个master，最后一行中写明了master0这个节点别名为local-master，状态为OK，地址是10.1.0.2:6379，有2个从节点。测试一下哨兵光是启动了还是不够的，还需要测试一下当被监控节点下线之后，哨兵是否能作出反应。首先，停掉master，slave-1，slave-2，然后观察哨兵的日志，在经过一段时间之后，哨兵宣布有节点下线：123456789redis-sentinel-3 | 1:X 19 Aug 2019 11:43:13.487 # +sdown slave 10.1.0.4:6381 10.1.0.4 6381 @ local-master 10.1.0.2 6379redis-sentinel-3 | 1:X 19 Aug 2019 11:43:13.487 # +sdown slave 10.1.0.3:6380 10.1.0.3 6380 @ local-master 10.1.0.2 6379redis-sentinel-1 | 1:X 19 Aug 2019 11:43:13.502 # +sdown slave 10.1.0.3:6380 10.1.0.3 6380 @ local-master 10.1.0.2 6379redis-sentinel-1 | 1:X 19 Aug 2019 11:43:13.502 # +sdown slave 10.1.0.4:6381 10.1.0.4 6381 @ local-master 10.1.0.2 6379redis-sentinel-2 | 1:X 19 Aug 2019 11:43:13.581 # +sdown slave 10.1.0.4:6381 10.1.0.4 6381 @ local-master 10.1.0.2 6379redis-sentinel-2 | 1:X 19 Aug 2019 11:43:13.582 # +sdown slave 10.1.0.3:6380 10.1.0.3 6380 @ local-master 10.1.0.2 6379redis-sentinel-3 | 1:X 19 Aug 2019 11:43:14.429 # +sdown master local-master 10.1.0.2 6379redis-sentinel-2 | 1:X 19 Aug 2019 11:43:14.439 # +sdown master local-master 10.1.0.2 6379redis-sentinel-1 | 1:X 19 Aug 2019 11:43:14.470 # +sdown master local-master 10.1.0.2 6379然后再启动master，slave-1，slave-2，并观察哨兵的日志，在节点上线之后，哨兵宣布了节点重启，并解除了节点的下线状态：123456789101112131415161718redis-sentinel-2 | 1:X 19 Aug 2019 11:49:45.040 * +reboot slave 10.1.0.3:6380 10.1.0.3 6380 @ local-master 10.1.0.2 6379redis-sentinel-1 | 1:X 19 Aug 2019 11:49:45.081 * +reboot slave 10.1.0.4:6381 10.1.0.4 6381 @ local-master 10.1.0.2 6379redis-sentinel-3 | 1:X 19 Aug 2019 11:49:45.081 * +reboot slave 10.1.0.3:6380 10.1.0.3 6380 @ local-master 10.1.0.2 6379redis-sentinel-3 | 1:X 19 Aug 2019 11:49:45.081 * +reboot slave 10.1.0.4:6381 10.1.0.4 6381 @ local-master 10.1.0.2 6379redis-sentinel-1 | 1:X 19 Aug 2019 11:49:45.082 * +reboot slave 10.1.0.3:6380 10.1.0.3 6380 @ local-master 10.1.0.2 6379redis-sentinel-1 | 1:X 19 Aug 2019 11:49:45.132 # -sdown slave 10.1.0.3:6380 10.1.0.3 6380 @ local-master 10.1.0.2 6379redis-sentinel-3 | 1:X 19 Aug 2019 11:49:45.132 # -sdown slave 10.1.0.4:6381 10.1.0.4 6381 @ local-master 10.1.0.2 6379redis-sentinel-3 | 1:X 19 Aug 2019 11:49:45.133 # -sdown slave 10.1.0.3:6380 10.1.0.3 6380 @ local-master 10.1.0.2 6379redis-sentinel-1 | 1:X 19 Aug 2019 11:49:45.133 # -sdown slave 10.1.0.4:6381 10.1.0.4 6381 @ local-master 10.1.0.2 6379redis-sentinel-2 | 1:X 19 Aug 2019 11:49:45.140 # -sdown slave 10.1.0.3:6380 10.1.0.3 6380 @ local-master 10.1.0.2 6379redis-sentinel-2 | 1:X 19 Aug 2019 11:49:45.141 * +reboot slave 10.1.0.4:6381 10.1.0.4 6381 @ local-master 10.1.0.2 6379redis-sentinel-2 | 1:X 19 Aug 2019 11:49:45.231 # -sdown slave 10.1.0.4:6381 10.1.0.4 6381 @ local-master 10.1.0.2 6379redis-sentinel-1 | 1:X 19 Aug 2019 11:49:45.960 * +reboot master local-master 10.1.0.2 6379redis-sentinel-3 | 1:X 19 Aug 2019 11:49:45.963 * +reboot master local-master 10.1.0.2 6379redis-sentinel-1 | 1:X 19 Aug 2019 11:49:46.043 # -sdown master local-master 10.1.0.2 6379redis-sentinel-3 | 1:X 19 Aug 2019 11:49:46.046 # -sdown master local-master 10.1.0.2 6379redis-sentinel-2 | 1:X 19 Aug 2019 11:49:46.054 * +reboot master local-master 10.1.0.2 6379redis-sentinel-2 | 1:X 19 Aug 2019 11:49:46.144 # -sdown master local-master 10.1.0.2 6379系列博文使用Docker配置Redis主从复制使用Docker配置Redis哨兵]]></content>
      <categories>
        <category>数据库</category>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用Docker配置Redis主从复制]]></title>
    <url>%2Fdatabase%2FRedis%2Fredis-replication-in-docker.html</url>
    <content type="text"><![CDATA[这篇文章主要介绍如何使用Docker在本机搭建一个带有主从复制功能的Redis环境，内容包括涉及的目录结构、docker-compose.yml的编写，以及结果的验证。目录结构本文将采用如下的目录结构，其中data目录将用于存放各个容器的数据，server目录存放docker-compose.yml以及针对master和slave节点的配置文件。1234567.├── data└── server ├── docker-compose.yml ├── redis-master.conf ├── redis-slave1.conf └── redis-slave2.conf配置Redis节点配置master节点编辑redis-master.conf，修改下列配置：123456789101112131415161718192021222324252627# 监听来自外部的连接bind 0.0.0.0# 启用保护模式# 即在没有使用bind指令绑定具体地址时# 或在没有设定密码时# Redis将拒绝来自外部的连接protected-mode yes# 监听端口port 6379# 启动时不打印logo# 这个不重要，想看logo就打开它always-show-logo no# 设定密码认证requirepass redis# 禁用KEYS命令# 一方面 KEYS * 命令可以列出所有的键，会影响数据安全# 另一方面 KEYS 命令会阻塞数据库，在数据库中存储了大量数据时，该命令会消耗很长时间# 期间对Redis的访问也会被阻塞，而当锁释放的一瞬间，大量请求涌入Redis，会造成Redis直接崩溃rename-command KEYS &quot;&quot;# 此外还应禁止 FLUSHALL 和 FLUSHDB 命令# 这两个命令会清空数据，并且不会失败配置slave节点创建redis-slave1.conf，修改下列配置：12345678910111213141516171819202122232425262728293031323334353637# 监听来自外部的连接bind 0.0.0.0# 启用保护模式# 即在没有使用bind指令绑定具体地址时# 或在没有设定密码时# Redis将拒绝来自外部的连接protected-mode yes# 监听端口port 6380# 启动时不打印logo# 这个不重要，想看logo就打开它always-show-logo no# 设定密码认证requirepass redis# 禁用KEYS命令# 一方面 KEYS * 命令可以列出所有的键，会影响数据安全# 另一方面 KEYS 命令会阻塞数据库，在数据库中存储了大量数据时，该命令会消耗很长时间# 期间对Redis的访问也会被阻塞，而当锁释放的一瞬间，大量请求涌入Redis，会造成Redis直接崩溃rename-command KEYS &quot;&quot;# 此外还应禁止 FLUSHALL 和 FLUSHDB 命令# 这两个命令会清空数据，并且不会失败# 配置master节点信息# 格式：#slaveof &lt;masterip&gt; &lt;masterport&gt;# 此处masterip所指定的redis-server-master是运行master节点的容器名# Docker容器间可以使用容器名代替实际的IP地址来通信slaveof redis-server-master 6379# 设定连接主节点所使用的密码masterauth &quot;redis&quot;创建redis-slave2.conf，修改监听端口号为6381，其余配置与redis-slave1.conf相同。配置及启动容器编写docker-compose.yml本例中使用docker-compose编排相关容器。要说为什么不用Kubernetes，那是因为对于一个示例来说这玩意太重了。说的一套一套的还不是因为不会用123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475---version: '3'services: # 主节点的容器 redis-server-master: image: redis container_name: redis-server-master restart: always ports: - 6379:6379 networks: redis-cluster: # 为容器指定一个静态IP ipv4_address: 10.1.0.2 environment: TZ: "Asia/Shanghai" volumes: # 映射配置文件和数据目录 - ./redis-master.conf:/usr/local/etc/redis/redis.conf - ../data/redis-master:/data sysctls: # 必要的内核参数 net.core.somaxconn: '511' command: ["redis-server", "/usr/local/etc/redis/redis.conf"] # 从节点1的容器 redis-server-slave-1: image: redis container_name: redis-server-slave-1 restart: always depends_on: - redis-server-master ports: - 6380:6380 networks: redis-cluster: ipv4_address: 10.1.0.3 environment: TZ: "Asia/Shanghai" volumes: - ./redis-slave1.conf:/usr/local/etc/redis/redis.conf - ../data/redis-slave-1:/data sysctls: net.core.somaxconn: '511' command: ["redis-server", "/usr/local/etc/redis/redis.conf"] # 从节点2的容器 redis-server-slave-2: image: redis container_name: redis-server-slave-2 restart: always depends_on: - redis-server-master ports: - 6381:6381 networks: redis-cluster: ipv4_address: 10.1.0.4 environment: TZ: "Asia/Shanghai" volumes: - ./redis-slave2.conf:/usr/local/etc/redis/redis.conf - ../data/redis-slave-2:/data sysctls: net.core.somaxconn: '511' command: ["redis-server", "/usr/local/etc/redis/redis.conf"]networks: redis-cluster: # IP Address Management ipam: config: # 为容器分配一个独立的子网，用来方便为容器指定静态IP # 使用独立的子网可以避免IP地址冲突的问题 - subnet: 10.1.0.0/16启动容器在docker-compose.yml所在位置执行docker-compose up即可启动上述三个容器，docker-compose会将容器日志打印到终端，在日志中可以看到三个Redis服务器在启动过程中的动作，以及从节点加入主节点的信息。启动成功后，可以在本机使用redis-cli连接至主节点。连接成功后，可以使用info replication命令检查主从复制的信息。12345678910111213141516127.0.0.1:6379&gt; auth redisOK127.0.0.1:6379&gt; info replication# Replicationrole:masterconnected_slaves:2slave0:ip=10.1.0.3,port=6380,state=online,offset=476,lag=1slave1:ip=10.1.0.4,port=6381,state=online,offset=476,lag=0master_replid:f29d9059a286deb4bbe5360f9c673a2484370205master_replid2:0000000000000000000000000000000000000000master_repl_offset:476second_repl_offset:-1repl_backlog_active:1repl_backlog_size:1048576repl_backlog_first_byte_offset:1repl_backlog_histlen:476其中第6行的role:master指示该节点为主节点，第7行的connected_slaves:2说明当前有2个从节点，第8、9行则是两个从节点的信息，包括它们的地址、端口号，和状态。如果此时查看该项目的目录结构，则可以发现在data目录中增加了三个Redis服务器的数据目录。123456789101112.├── data│ ├── redis-master│ │ └── dump.rdb│ ├── redis-slave-1│ │ └── dump.rdb│ └── redis-slave-2│ └── dump.rdb└── server ├── docker-compose.yml ├── redis-master.conf └── redis-slave.conf测试一下光是启动成功还不够，还需要测试一下从节点是否能同步主节点的数据。首先连接到主节点，新增一个set：123456127.0.0.1:6379&gt; auth redisOK127.0.0.1:6379&gt; set foo barOK127.0.0.1:6379&gt; get foo&quot;bar&quot;好的，在主节点里面成功添加了一条数据。那么接下来连接到slave-1，看一下数据有没有同步过去：123456127.0.0.1:6380&gt; auth redisOK127.0.0.1:6380&gt; get foo&quot;bar&quot;127.0.0.1:6380&gt; set foo baz(error) READONLY You can&apos;t write against a read only replica.看来slave-1成功的从主节点同步了数据，并且这个节点也按照设定，是一个只读的节点。那么slave-2呢？123456127.0.0.1:6381&gt; auth redisOK127.0.0.1:6381&gt; get foo&quot;bar&quot;127.0.0.1:6381&gt; set foo baz(error) READONLY You can&apos;t write against a read only replica.OK，slave-2也成功的同步了数据，并且正在作为一个只读节点运行着。系列博文使用Docker配置Redis主从复制使用Docker配置Redis哨兵]]></content>
      <categories>
        <category>数据库</category>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JVM的栈帧]]></title>
    <url>%2Fprojects%2Fjava%2Ffundamentals%2Fjava-jvm-stack-frame.html</url>
    <content type="text"><![CDATA[栈帧是支持JVM进行方法调用和执行的数据结构，它是JVM 运行时的数据区域的栈元素，其中包含了方法的局部变量表、操作数栈、动态链接方法，和返回地址等信息。局部变量表和操作数栈的空间，在编译期就已经可以确定下来，并会随着方法表的code属性一并提供给JVM，所以每个栈帧的空间不会受运行时数据的影响，而仅取决于JVM的实现。每当一个方法被调用都会生成一个栈帧，并在方法执行完毕后被销毁，并且对于每个活动的线程，只有栈顶的栈帧是活动的，这个栈帧被称为“活动栈帧”，与其相关联的方法被称为“活动方法”，以及与其相关联的类被称为“活动类”。局部变量表每个栈帧中都会有一个被称为“局部变量表”的数组，其中保存着方法的局部变量。局部变量表的大小在编译期就已经确定下来，并保存在class文件的code区。各个变量可通过数组下标的方式被定位到，对于需要占用两个元素的数据类型，比如long和double，其对应的下标使用较小的那个值。在方法执行时，JVM使用局部变量表完成参数值到参数列表的传递过程的。如果调用的是类方法，那么参数会从局部变量表第0位开始向后排列。如果调用的是实例方法(非static方法)，则局部变量表第0位默认用于传递方法所属对象的实例的引用，在方法中使用this关键字可以访问到这个隐含的参数，其余的参数则从第1位开始向后排列；在参数表分配完毕后，方法体内部定义的变量会按照其顺序和作用域分配剩余的位置。操作数栈每个栈帧中都有一个被称为“操作数栈”的栈。操作数栈的最大深度也是在编译期就可以确定下来，并保存在class文件的code区。在栈帧创建初期，其中的操作数栈是空的。JVM提供了一系列的指令，用于将值压入操作数栈，同时也有指令来从操作数栈中取出值并进行计算，并将计算结果压入操作数栈。比如iadd指令会从操作数栈中取出最顶部的两个int数值，将其相加，然后将结果压入操作数栈。压入操作数栈的元素的类型必须与指令的要求严格匹配，比如使用iadd指令将一个float和一个double相加是不允许的，这一点不仅在编译期会被严格确定，在类校验阶段也会进行检查。动态链接每个栈帧都包含一个指向运行时常量池的引用，用来支持方法调用过程中的动态链接。字节码中的方法调用指令会以常量池中指向方法的符号引用作为参数。这些符号引用一部分会在类加载阶段或者第一次使用时转化成直接引用，这种称为静态解析；另一部分将在每一次运行期间转化为直接引用，这种称为动态链接。返回地址当一个方法开始执行后，只有两种方式可以退出这个方法：执行方法返回的指令，和遇到未处理的异常。执行方法返回的指令称为“正常方法调用出口(Normal Method Invocation Completion)”，在这种情况下，如果方法有返回值，那么返回值将会被传递到上方的调用者。此时，当前栈帧将被用来恢复调用者的状态，包括调用者的本地变量表和操作数栈，并会修改pc寄存器的值来跳过方法调用指令。当方法执行期间遇到了异常，并没有找到对应的异常处理器时，导致的方法返回称为“异常方法调用出口(Abrupt Method Invocation Completion)”，在这种情况下将不会有值被传回上方调用者。附加信息虚拟机规范允许具体的JVM实现增加一些规范中没有的信息到栈帧中，比如调试信息等，这些信息的内容将取决于JVM的具体实现。]]></content>
      <categories>
        <category>学习记录</category>
        <category>Java</category>
        <category>基础知识</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>JVM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java的垃圾回收算法]]></title>
    <url>%2Fprojects%2Fjava%2Ffundamentals%2Fjava-gc-algorithms.html</url>
    <content type="text"><![CDATA[在JVM运行时的数据区域中了解到了JVM的内存模型，那么既然使用了内存，就要考虑如何回收内存。与C语言不同，Java不需要开发人员人工回收内存，而是交给Java的垃圾回收机制来完成。哪些内存需要回收在Java中，GC的对象是堆和方法区。栈中的栈帧随着方法的调用和退出，会自行完成压栈和出栈操作，每个栈帧所需的内存空间也是在类结构确定下来时就已知的，所以不怎么需要考虑内存的回收问题。但是堆和方法区则不一样，这部分的空间是动态分配和回收的，同时也只有在运行时才可得知要生成哪些对象以及需要多少空间。判断对象是否可以被回收通常有两种算法：引用计数法和可达性分析法。引用计数法引用计数法会给每个对象添加一个引用计数器，每当有一个地方引用它时，计数器就会加一；反之，每当一个引用失效时，计数器就会减一。任何时候，如果引用计数为0，则说明这个对象可以被回收。但是，这个算法有一个问题，那就是无法处理循环引用，即这样：此时，对象1，对象2，对象3都是不可达状态，理论上这三个对象都应该被回收，但是因为它们三个形成循环引用，引用计数器不为零，导致GC不会回收它们的空间。所以实际上，JVM并没有采用这种判断方法。可达性分析法(根搜索算法)可达性分析法的原理是，从根对象(GC Root)开始向下搜索，搜索走过的路径称为“引用链”，对象与引用链可以形成一个图，当任一个对象没有到根对象的引用链，即在这个图中该对象是不可达的，那么就判定这个对象是可以被回收的。Java语言使用如下几种GC Root对象：虚拟机栈(栈帧中的本地变量表)中引用的对象方法区中静态属性引用的对象方法区中常量引用的对象本地方法栈中JNI引用的对象还是用上面这个循环引用作为示例：此时虽然对象1、对象2、对象3互相之间存在引用，但是从根对象开始无法找到到达它们的路径，即它们三个都是不可达的，也就是可以被回收的。如何进行回收在根搜索算法的基础上，现代虚拟机中实现了三种算法：标记-清除算法，复制算法，标记-整理算法。标记-清除算法标记-清除算法把垃圾回收过程分成标记和清除两个阶段。在标记阶段，通过根节点标记所有可达的对象，也就是说，未被标记的对象都是不可达的对象。然后在清除阶段回收所有未被标记的对象。详细来说的话，就是当堆中的有效内存空间被耗尽时，就会停止整个程序(stop the world)，然后逐步开始标记和清除工作。标记的过程，实际上是遍历所有的GC Roots，并标记所有可达的对象。而清除的过程，则是遍历堆中所有的对象，并清除没有被标记的对象。在回收过程中一定要停止程序运行的原因，是为了避免在标记完成而尚未开始清除时，有新的可达的对象被创建出来。一旦出现这种情况，因为新创建的对象没有被标记，所以在清除阶段这个对象又会被清除。如果停止了程序的运行，那么在清除过程中，对象的状态不会发生变化，也就不会发生前面说的这种问题。这个算法尽管可以有效的回收内存，但是也有两个比较大的缺点：遍历所有对象的效率比较低，导致程序停止运行的时间比较长这种方法清理出的内存空间是不连续的，会造成空闲空间碎片化，并会影响数组分配空间。同时为了得知哪些空间是可用的，JVM还需要额外维护内存闲置空间的信息。复制算法复制算法的思想，是将原有的内存空间分成两部分，每次只使用其中一部分。在垃圾回收时，会从正在使用的部分中，将标记的对象复制到另一块内存中，然后清除正在使用的内存块，并交换两块内存的角色，来完成空间的回收。该算法比标记-清除算法的效率高，但是该算法不适合活动对象较多的场合，比如老年代空间。此外，该算法会造成一定程度的内存空间浪费，因为总是有一片内存空间是被闲置的。为了节省空间，考虑到新生代空间中的对象存活时间大多不会很长，所以虚拟机可以选择不将内存对半分，而是将内存分割成一块比较大的Eden空间和两块比较小的Survivor空间(From Survivor和To Survivor)，每次同时使用Eden和其中一个Survivor。比如HotSpot虚拟机默认为Eden分配80%的空间，为两个Survivor各分配10%的空间。Eden区，如其名字“伊甸园”一般，对象在被创建时，首先会放在这个区域；Survivor区，也如其名字“幸存者区”一样，存放的是每次垃圾回收后被保留下来的对象。在每次垃圾回收时，Eden区中不能被回收的对象，和From Survivor区中不能被回收的对象，都将被复制到To Survivor区中，然后回收Eden区和From Survivor区的空间，并且幸存下来的对象的age属性会加一，最后From Survivor和To Survivor两者的角色对调。如果发生Survivor空间不足以存放所有活动对象时，则会使用老年代来进行分配担保，大的对象会跳过Survivor区直接进入老年代。标记-整理算法因为复制算法在活动对象较多时，会发生很多的复制操作，导致算法效率比较低，而老年代的特点就是活动的对象比较多。“标记-整理”算法就是为了应对这一情况而诞生的。标记-整理算法把垃圾回收过程分成标记和整理两个阶段。标记阶段的做法与“标记-清除”算法一样，遍历所有的GC Roots并标记出活动的对象；而在整理阶段，所有的活动对象都会向内存空间的一端移动(比如全部从内存空间的其实位置开始排列)，然后将边界以外的内存直接清理。该算法的另一个优点是，因为该算法不会分割内存空间，而且每次回收后对象占用的空间肯定小于回收前所占用的空间，所以不再需要额外的空间进行分配担保。分代收集算法分代收集算法实际上就是根据不同内存空间的特性，一般是将堆分为新生代和老年代，并根据其各自的特点，在新生代使用复制算法回收，在老年代使用标记-整理算法回收。]]></content>
      <categories>
        <category>学习记录</category>
        <category>Java</category>
        <category>基础知识</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>垃圾回收</tag>
        <tag>GC</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JVM运行时的数据区域]]></title>
    <url>%2Fprojects%2Fjava%2Ffundamentals%2Fjava-jvm-runtime-data-areas.html</url>
    <content type="text"><![CDATA[JVM在运行时，会按照程序执行的需要来创建一系列的运行时数据区域。有的区域只会随JVM起停而被创建和销毁，有的区域则会独立分配给各个线程，并随线程的起停而创建和销毁。这些运行时区域，按照功能和性质不同，会分成如下几部分：线程专有pc(program counter)寄存器JVM栈本地方法栈线程间共享堆方法区运行时常量池pc(program counter)寄存器JVM允许同时运行多个线程，每个线程都有它自己的PC寄存器。在任意时刻，每个JVM线程都在执行一个方法中的某条语句，而这个正在被执行的方法，就叫做这个线程的“当前方法”。如果当前方法不是一个本地(native)方法，那么PC寄存器的内容是当前正在执行的指令的地址；如果当前方法是本地方法，那么PC寄存器的值则是空(undefined)的。JVM栈每个JVM都会在其启动时创建自己私有的JVM栈，栈之中存储的是栈帧，用于存储局部变量和方法调用信息。规范中允许栈的深度可以是固定的，也可以根据要求动态的扩展和收缩。如果是固定深度的栈，那么每个栈的深度会在其创建时按照需要独立指定。当请求创建的栈大于所允许的深度，那么JVM会抛出StackOverflowError异常；当程序试图扩大一个可以动态伸缩的栈，或者试图为新的线程创建一个栈，但是可用内存不足以完成这个操作时，那么JVM会抛出OutOfMemoryError异常。本地方法栈本地方法栈与JVM栈类似，保存了本地方法的调用信息。本地方法栈的空间可以是固定的，也可以是动态伸缩的。当程序申请了大于所允许的本地方法栈空间，那么JVM会抛出StackOverflowError异常；如果程序申请扩展一个可以动态伸缩的本地方法栈，或者试图创建一个栈，但是可用内存不足以满足要求时，JVM会抛出OutOfMemoryError异常。堆在JVM启动时，会创建一个共享于所有线程的堆空间，其中存放着所有的对象，和被分配好空间的数组。用于存放对象的空间由一个自动化的存储空间管理机制，即垃圾回收机制(garbage collector)，来进行管理。堆空间可以是固定大小的，也可以是按需伸缩的。如果程序试图申请扩大堆空间，但是存储管理机制无法满足需求时，JVM会抛出OutOfMemory异常。在堆中，JVM又根据作用不同，将内存空间分为如下几部分：新生代(New generation)新生代保留的是生命周期短，并且很快就会被回收掉的对象。其中的空间又随着“复制算法”这一垃圾回收算法而被分为Eden Space和Survivor Space。具体可以参考Java的垃圾回收算法这篇博文。老年代(Tenured generation)在多次垃圾回收后仍然存活的对象，将会被放到老年代空间中。因此可以认为，老年代中的对象的生命周期都是比较长的。方法区方法区(method area)是一个共享于所有JVM线程的空间，创建于JVM启动时，其中存放着各个类的结构，如运行时常量池、属性、方法，以及方法和特殊方法(special methods)的代码。方法区的大小可以是固定的，也可以是按需伸缩的，但是根据虚拟机实现的不同，垃圾回收机制可能不会回收或压缩方法区的空间。如果方法区的可用内存无法满足一次申请空间的请求，那么JVM会抛出OutOfMemoryError异常。运行时常量池运行时常量池对应class文件中的constant_pool表。运行时常量池中包含了数值常量和属性的引用。每个运行时常量池的空间都会在类或接口被创建时生成，并且从方法区中分配空间。在创建运行时方法区时，如果申请的空间大于方法区可提供的空间，那么JVM会抛出OutOfMemoryError异常。参考文档《The Java Virtual Machine Specification (Java SE 8 Edition)》 - 2.5 Run-Time Data Areas]]></content>
      <categories>
        <category>学习记录</category>
        <category>Java</category>
        <category>基础知识</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>JVM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java源码阅读 - ArrayList]]></title>
    <url>%2Fprojects%2Fjava%2F%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB%2Fjava-read-src-arraylist.html</url>
    <content type="text"><![CDATA[做技术，不能只知其然而不知其所以然。在知道了工具的原理之后，才能更高效的使用这个工具。在程序的世界里，源码里面没有秘密，看懂了源码，也就看懂了原理。这次就来阅读一下ArrayList的源码。类的声明123public class ArrayList&lt;E&gt; extends AbstractList&lt;E&gt; implements List&lt;E&gt;, RandomAccess, Cloneable, java.io.Serializable &#123; ... &#125;上面代码声明了一个叫ArrayList的泛型类，继承了AbstractList，并实现了List，RandomAccess，Cloneable，Serializable接口。AbstractList抽象类提供了一个“骨架”级别的List接口的实现，用来减少实现一个支持随机存储的List的工作量。RandomAccess中没有声明任何方法，是一个标记接口(marker interface)，表明了这个类支持快速(通常是O(1)时间复杂度)的随机存取。在遍历一个集合前，可以用instanceof判断这个集合是否实现了RandomAccess，来选择合适的遍历方法。Cloneable也是一个标记接口，表明了这个类允许使用Object.clone()命令进行属性到属性的复制。Serializable也是一个标记接口，表明在这个类上启用Java的序列化功能。如何存储数据1234567891011121314/** * The array buffer into which the elements of the ArrayList are stored. * The capacity of the ArrayList is the length of this array buffer. Any * empty ArrayList with elementData == DEFAULTCAPACITY_EMPTY_ELEMENTDATA * will be expanded to DEFAULT_CAPACITY when the first element is added. */transient Object[] elementData; // non-private to simplify nested class access/** * The size of the ArrayList (the number of elements it contains). * * @serial */private int size;elementData数组用来实际存放数据，ArrayList的空间(capacity)对应这个数组的长度(size)。ArrayList实现了自己的序列化(ArrayList#writeObject())和反序列化(ArrayList#readObject())方法，所以加上transient关键字来使elementData不参与Java自带的序列化和反序列化过程。size成员变量记录当前ArrayList中元素的数量。构造方法ArrayList有三个构造方法使用默认大小的ArrayList()指定最初大小的ArrayList(int initialCapacity)根据一个给定集合来初始化的ArrayList(Collection&lt;? extends E&gt; c)使用默认大小类中首先指定了默认的大小1234/** * Default initial capacity. */private static final int DEFAULT_CAPACITY = 10;但是，在它下面，还有这么一个东西：123456/** * Shared empty array instance used for default sized empty instances. We * distinguish this from EMPTY_ELEMENTDATA to know how much to inflate when * first element is added. */private static final Object[] DEFAULTCAPACITY_EMPTY_ELEMENTDATA = &#123;&#125;;在最初被构造时，elementData会先指向DEFAULTCAPACITY_EMPTY_ELEMENTDATA，而不是直接创建一个容量为10的数组。123456/** * Constructs an empty list with an initial capacity of ten. */public ArrayList() &#123; this.elementData = DEFAULTCAPACITY_EMPTY_ELEMENTDATA;&#125;这样做的好处在于可以更合理的利用空间。试想一下，如果某个场景中需要创建5个ArrayList备用，如果直接就分配好空间的话，那么就会消耗掉至少50个元素所需要的空间。所以Java选择先将elementData指向一个空数组，在向ArrayList中添加数据时，再去创建合适大小的数组。指定最初大小1234567891011121314151617/** * Constructs an empty list with the specified initial capacity. * * @param initialCapacity the initial capacity of the list * @throws IllegalArgumentException if the specified initial capacity * is negative */public ArrayList(int initialCapacity) &#123; if (initialCapacity &gt; 0) &#123; this.elementData = new Object[initialCapacity]; &#125; else if (initialCapacity == 0) &#123; this.elementData = EMPTY_ELEMENTDATA; &#125; else &#123; throw new IllegalArgumentException("Illegal Capacity: "+ initialCapacity); &#125;&#125;当指定的大小是一个正整数时，Java会创建好对应大小的数组，并将elementData指向这个数组；如果指定的大小为零，那么Java也会将elementData指向一个共享的空数组EMPTY_ELEMENTDATA，注意这个空数组与上文提到的不是同一个；如果指定的大小为负数，则抛出一个异常。那么为什么要专门把EMPTY_ELEMENTDATA和DEFAULTCAPACITY_EMPTY_ELEMENTDATA区分出来呢？DEFAULTCAPACITY_EMPTY_ELEMENTDATA的JavaDoc是这么说的：We distinguish this from EMPTY_ELEMENTDATA to know how much to inflate when first element is added.我们将它与EMPTY_ELEMENTDATA区分开来，是方便在添加第一个元素时计算要扩张多少空间。根据给定的集合初始化12345678910111213141516171819/** * Constructs a list containing the elements of the specified * collection, in the order they are returned by the collection's * iterator. * * @param c the collection whose elements are to be placed into this list * @throws NullPointerException if the specified collection is null */public ArrayList(Collection&lt;? extends E&gt; c) &#123; elementData = c.toArray(); if ((size = elementData.length) != 0) &#123; // c.toArray might (incorrectly) not return Object[] (see 6260652) if (elementData.getClass() != Object[].class) elementData = Arrays.copyOf(elementData, size, Object[].class); &#125; else &#123; // replace with empty array. this.elementData = EMPTY_ELEMENTDATA; &#125;&#125;程序首先试图调用给定集合的Collection#toArray()方法，将集合转换成一个Object[]数组。当数组中有元素时，检查elementData的数据类型是否为Object[]类型，如果不是则使用Arrays.copyOf()方法重新复制元素到一个Object[]对象中；而当数组中没有元素时，则重新使elementData指向EMPTY_ELEMENTDATA。添加元素当添加元素时，首先会调用ensureCapacityInternal()方法，来保证空间足够。保证有足够空间后，就会向elementData[size]处放置被添加的元素，并且使size加一。1234567891011/** * Appends the specified element to the end of this list. * * @param e element to be appended to this list * @return &lt;tt&gt;true&lt;/tt&gt; (as specified by &#123;@link Collection#add&#125;) */public boolean add(E e) &#123; ensureCapacityInternal(size + 1); // Increments modCount!! elementData[size++] = e; return true;&#125;扩容ensureCapacityInternal()方法用于确保在添加元素时有足够的空间。如果空间不足，则会调用grow()方法扩容。grow()方法会将elementData扩张为当前的1.5倍空间，并使用Arrays.copyOf()方法将元素放入新的数组。12345678910111213141516171819202122232425262728293031323334353637383940414243444546/** * 确保空间 */private void ensureCapacityInternal(int minCapacity) &#123; ensureExplicitCapacity(calculateCapacity(elementData, minCapacity));&#125;/** * 计算扩容目标 */private static int calculateCapacity(Object[] elementData, int minCapacity) &#123; if (elementData == DEFAULTCAPACITY_EMPTY_ELEMENTDATA) &#123; return Math.max(DEFAULT_CAPACITY, minCapacity); &#125; return minCapacity;&#125;private void ensureExplicitCapacity(int minCapacity) &#123; modCount++; // overflow-conscious code // 检查目标容量是否大于当前已有容量 if (minCapacity - elementData.length &gt; 0) grow(minCapacity);&#125;/** * Increases the capacity to ensure that it can hold at least the * number of elements specified by the minimum capacity argument. * * 增加容量，以确保至少可以容纳minCapacity所指定个数的元素 * * @param minCapacity the desired minimum capacity 目标最小容量 */private void grow(int minCapacity) &#123; // overflow-conscious code int oldCapacity = elementData.length; // newCapacity = olcCapacity + (oldCapacity / 2) int newCapacity = oldCapacity + (oldCapacity &gt;&gt; 1); if (newCapacity - minCapacity &lt; 0) newCapacity = minCapacity; if (newCapacity - MAX_ARRAY_SIZE &gt; 0) newCapacity = hugeCapacity(minCapacity); // minCapacity is usually close to size, so this is a win: elementData = Arrays.copyOf(elementData, newCapacity);&#125;删除元素ArrayList提供了两种方式来删除一个元素：根据元素位置(index)删除，和匹配元素删除。根据位置删除根据位置删除时，首先会检查给定的位置是否越界。如果没有越界，就会先取出被删除的元素，用来向调用方返回。删除元素的方法是将index+1后面的元素重新放在index起始的位置上。可以看出，删除操作的消耗是比较高的。在重新排列元素后，数组中最后一个元素将与倒数第二个元素重复。所以还需要将最后一个元素置为null，并将size减一。12345678910111213141516171819202122232425262728293031/** * Removes the element at the specified position in this list. * Shifts any subsequent elements to the left (subtracts one from their * indices). * * @param index the index of the element to be removed * @return the element that was removed from the list * @throws IndexOutOfBoundsException &#123;@inheritDoc&#125; */public E remove(int index) &#123; rangeCheck(index); modCount++; E oldValue = elementData(index); // 计算要移动的元素数量 int numMoved = size - index - 1; if (numMoved &gt; 0) System.arraycopy( // 源 elementData, // 源位置 index+1, // 目标 elementData, // 目标位置 index, // 要复制的个数 numMoved); elementData[--size] = null; // clear to let GC do its work return oldValue;&#125;匹配元素删除如果向remove()方法提供了一个对象，那么ArrayList会遍历elementData，并会删除第一个与给定对象匹配的元素。123456789101112131415161718192021222324252627282930313233343536373839404142/** * Removes the first occurrence of the specified element from this list, * if it is present. If the list does not contain the element, it is * unchanged. More formally, removes the element with the lowest index * &lt;tt&gt;i&lt;/tt&gt; such that * &lt;tt&gt;(o==null&amp;nbsp;?&amp;nbsp;get(i)==null&amp;nbsp;:&amp;nbsp;o.equals(get(i)))&lt;/tt&gt; * (if such an element exists). Returns &lt;tt&gt;true&lt;/tt&gt; if this list * contained the specified element (or equivalently, if this list * changed as a result of the call). * * @param o element to be removed from this list, if present * @return &lt;tt&gt;true&lt;/tt&gt; if this list contained the specified element */public boolean remove(Object o) &#123; if (o == null) &#123; for (int index = 0; index &lt; size; index++) if (elementData[index] == null) &#123; fastRemove(index); return true; &#125; &#125; else &#123; for (int index = 0; index &lt; size; index++) if (o.equals(elementData[index])) &#123; fastRemove(index); return true; &#125; &#125; return false;&#125;/* * Private remove method that skips bounds checking and does not * return the value removed. */private void fastRemove(int index) &#123; modCount++; int numMoved = size - index - 1; if (numMoved &gt; 0) System.arraycopy(elementData, index+1, elementData, index, numMoved); elementData[--size] = null; // clear to let GC do its work&#125;缩减容量ArrayList#trimToSize()方法可以将ArrayList的容量缩减至当前元素个数。这个操作需要通过Arrays.copyOf()方法进行，所以成本也是比较高的。12345678910111213/** * Trims the capacity of this &lt;tt&gt;ArrayList&lt;/tt&gt; instance to be the * list's current size. An application can use this operation to minimize * the storage of an &lt;tt&gt;ArrayList&lt;/tt&gt; instance. */public void trimToSize() &#123; modCount++; if (size &lt; elementData.length) &#123; elementData = (size == 0) ? EMPTY_ELEMENTDATA : Arrays.copyOf(elementData, size); &#125;&#125;Fail fast在会改变elementData大小的方法中，经常会看到类似modCount++这样的操作。那么这个操作的目的是什么呢？首先来看看modCount成员变量的JavaDoc是怎么说的。123456789101112131415161718192021222324252627/** * The number of times this list has been &lt;i&gt;structurally modified&lt;/i&gt;. * Structural modifications are those that change the size of the * list, or otherwise perturb it in such a fashion that iterations in * progress may yield incorrect results. * * &lt;p&gt;This field is used by the iterator and list iterator implementation * returned by the &#123;@code iterator&#125; and &#123;@code listIterator&#125; methods. * If the value of this field changes unexpectedly, the iterator (or list * iterator) will throw a &#123;@code ConcurrentModificationException&#125; in * response to the &#123;@code next&#125;, &#123;@code remove&#125;, &#123;@code previous&#125;, * &#123;@code set&#125; or &#123;@code add&#125; operations. This provides * &lt;i&gt;fail-fast&lt;/i&gt; behavior, rather than non-deterministic behavior in * the face of concurrent modification during iteration. * * &lt;p&gt;&lt;b&gt;Use of this field by subclasses is optional.&lt;/b&gt; If a subclass * wishes to provide fail-fast iterators (and list iterators), then it * merely has to increment this field in its &#123;@code add(int, E)&#125; and * &#123;@code remove(int)&#125; methods (and any other methods that it overrides * that result in structural modifications to the list). A single call to * &#123;@code add(int, E)&#125; or &#123;@code remove(int)&#125; must add no more than * one to this field, or the iterators (and list iterators) will throw * bogus &#123;@code ConcurrentModificationExceptions&#125;. If an implementation * does not wish to provide fail-fast iterators, this field may be * ignored. */protected transient int modCount = 0;也就是说，modCount记录了一个List的结构被修改的次数，并且提到了如果在迭代过程中修改了List的结构，那么可能会导致得到错误的结果。在迭代或者序列化的过程中，程序会检查modCount的值是否被修改过，如果被修改，就会抛出ConcurrentModificationException异常。比如ArrayList.Itr#next()方法：1234567891011121314151617@SuppressWarnings("unchecked")public E next() &#123; checkForComodification(); int i = cursor; if (i &gt;= size) throw new NoSuchElementException(); Object[] elementData = ArrayList.this.elementData; if (i &gt;= elementData.length) throw new ConcurrentModificationException(); cursor = i + 1; return (E) elementData[lastRet = i];&#125;final void checkForComodification() &#123; if (modCount != expectedModCount) throw new ConcurrentModificationException();&#125;序列化与反序列化如上文所说，ArrayList实现了自己的序列化与反序列化方法，所以elementData使用transient修饰。在序列化时，程序并不是直接序列化elementData这个数组，而是只取出数组中有效的元素(包括null元素)，并逐个序列化每个元素的对象。1234567891011121314151617181920212223/** * Save the state of the &lt;tt&gt;ArrayList&lt;/tt&gt; instance to a stream (that * is, serialize it). * * @serialData The length of the array backing the &lt;tt&gt;ArrayList&lt;/tt&gt; * instance is emitted (int), followed by all of its elements * (each an &lt;tt&gt;Object&lt;/tt&gt;) in the proper order. */private void writeObject(java.io.ObjectOutputStream s) throws java.io.IOException&#123; // Write out element count, and any hidden stuff int expectedModCount = modCount; s.defaultWriteObject(); // Write out size as capacity for behavioural compatibility with clone() s.writeInt(size); // Write out all elements in the proper order. for (int i=0; i&lt;size; i++) &#123; s.writeObject(elementData[i]); &#125; if (modCount != expectedModCount) &#123; throw new ConcurrentModificationException(); &#125;&#125;在反序列化时，首先会使elementData指向EMPTY_ELEMENTDATA，只在有元素会被反序列化时，才会为elementData扩容并逐个反序列化对应的对象。1234567891011121314151617181920212223/** * Reconstitute the &lt;tt&gt;ArrayList&lt;/tt&gt; instance from a stream (that is, * deserialize it). */private void readObject(java.io.ObjectInputStream s) throws java.io.IOException, ClassNotFoundException &#123; elementData = EMPTY_ELEMENTDATA; // Read in size, and any hidden stuff s.defaultReadObject(); // Read in capacity s.readInt(); // ignored if (size &gt; 0) &#123; // be like clone(), allocate array based upon size not capacity int capacity = calculateCapacity(elementData, size); SharedSecrets.getJavaOISAccess().checkArray(s, Object[].class, capacity); ensureCapacityInternal(size); Object[] a = elementData; // Read in all elements in the proper order. for (int i=0; i&lt;size; i++) &#123; a[i] = s.readObject(); &#125; &#125;&#125;]]></content>
      <categories>
        <category>学习记录</category>
        <category>Java</category>
        <category>源码阅读</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>ArrayList</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java自定义注解]]></title>
    <url>%2Fprojects%2Fjava%2Ffundamentals%2Fjava-customized-annotations.html</url>
    <content type="text"><![CDATA[注解是Java 5引入的一个新特性，它提供了一个用来将信息和元数据与程序元素相关联的能力，其作用如同一个修饰符，本身并不包含任何程序逻辑。本文将介绍如何创建和使用自定义的注解。元注解Java自带了四个作用于注解上的注解，即元注解，分别是：@Documented，用于注明该注解是否包含于JavaDoc中@Retention，用于注明这个注解将保留到什么时候@Target，用于注明这个注解将作用于哪些元素上@Inherit，用于注明该注解是否会被子类继承@Retention@Retention元注解定义了这个注解的生命周期，即这个注解将保留到什么时候。注解的生命周期有这三种：RetentionPolicy.SOURCE：仅在源码中保留，在编译期就会被丢弃。比如@Override和@SuppressWarnings就属于这类注解RetentionPolicy.CLASS：注解将会被写入到字节码中，但是在运行时会被丢弃。这个是默认的生命周期。RetentionPolicy.RUNTIME：该注解将保留至运行时。这意味着在运行时可以通过反射机制读取到注解的信息。@Target@Target元注解指定了该注解将可用于哪些元素上。可用的参数有如下几种：ElementType.ANNOTATION_TYPE，用于描述注解。@Target(ElementType.ANNOTATION_TYPE)标注的注解将成为一个元注解。ElementType.CONSTRUCTOR，用于描述构造方法ElementType.FIELD，用于描述成员变量、对象、属性（包括enum实例）ElementType.LOCAL_VARIABLE，用于描述局部变量ElementType.METHOD，用于描述方法ElementType.PACKAGE，用于描述包ElementType.PARAMETER，用于描述参数ElementType.TYPE，用于描述类、接口（包括注解）、enum生命声明Java 8中又新增了两个参数：ElementType.TYPE_PARAMETER，可以用在Type的声明前ElementType.TYPE_USE，可以用在使用Type的地方编写自定义注解及相关方法自定义注解的类型为@interface，注解中可以包含方法，方法名将作为注解的属性。注解中的方法不可以有参数，也不可以抛出异常，同时方法只能返回原始类型、String、Class、enums、注解类型，以及上述类型的数组。方法的默认值不可以是null。下面将通过一个示例演示如何编写和使用自定义注解相关的方法。示例将分别创建两个名为@JsonSerializable和@JsonElement的注解，以及一个名为JsonUtils的工具类。@JsonSerializable标记一个类可以被序列化成JSON，@JsonElement标记一个成员变量将会被包含在这个JSON中；JsonUtils工具类包含将对象序列化为JSON的方法。@JsonSerializable1234567891011/** * 标记一个类可以被序列化成JSON * * 因为这个注解要在运行时通过反射获取，所以retention为runtime * * 因为这个注解作用于一个类，所以target为type */@Retention(RetentionPolicy.RUNTIME)@Target(ElementType.TYPE)public @interface JsonSerializable &#123;&#125;@JsonElement12345678910111213141516/** * 标记一个成员变量将会被包含在这个JSON中 * * 因为这个注解要在运行时通过反射获取，所以retention为runtime * * 因为这个注解作用于成员变量，所以target为field */@Retention(RetentionPolicy.RUNTIME)@Target(ElementType.FIELD)public @interface JsonElement &#123; /** * 指定该成员变量在JSON中的key值 */ public String key() default "";&#125;JsonUtils123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293public class JsonUtils &#123; /** * 将对象序列化为JSON * * @param object 要序列化的对象，需要有&#123;@link JsonSerializable&#125;注解 * @return 序列化后的JSON字符串，如果不可序列化则是null * @throws InvocationTargetException * @throws IllegalAccessException * @throws NoSuchMethodException */ public static String serializeToJson(Object object) throws InvocationTargetException, IllegalAccessException, NoSuchMethodException &#123; // 检查对象是否可以被序列化 if (!isSerializable(object)) &#123; return null; &#125; // 取得对象所属的类 Class clazz = object.getClass(); // 取得类中的所有方法 Method[] methods = clazz.getMethods(); // 取得所有方法的方法名，后面用于搜索 List&lt;String&gt; methodNames = Arrays.stream(methods).map(Method::getName).collect(Collectors.toList()); // 取得类中所有成员变量，包括public、protected、private、和默认访问权限的 Field[] fields = clazz.getDeclaredFields(); // 创建一个空的HashMap，用于存放要序列化的属性的名字和值 Map&lt;String, String&gt; elements = new HashMap&lt;&gt;(fields.length); // 遍历所有成员变量 for (Field field : fields) &#123; // 如果有JsonElement注解 if (field.isAnnotationPresent(JsonElement.class)) &#123; // 取得变量名 String fieldName = field.getName(); // 拼接其对应getter方法名 // 不直接使用setAccessible()方法是因为我不喜欢这么干，这会破坏封装性 String getterName = "get" + fieldName.substring(0, 1).toUpperCase() + fieldName.substring(1); // 检查这个变量是否有getter方法 if (methodNames.contains(getterName)) &#123; // 如果有getter方法，则根据方法名取得对应的方法实例 Method method = clazz.getMethod(getterName); // 取得JsonElement注解中设定的key值 String keyName = field.getAnnotation(JsonElement.class).key(); // 如果key的值为空字符串，则使用属性名作为JSON中的key名 // 否则取指定的key名 // 并调用变量对应的getter方法取得变量的值 // 最后放入HashMap中 elements.put("".equals(keyName) ? field.getName() : keyName, String.valueOf(method.invoke(object))); &#125; &#125; &#125; // 遍历HashMap，构造JSON内容 String jsonBody = elements.entrySet() .stream() // 取得每个元素的key名和值，拼接成 \t"key":"value" 的形式 .map(entry -&gt; "\t\"" + entry.getKey() + "\":\"" + entry.getValue() + "\"") // 每行元素间插入分隔符，逗号分隔每行数据，\n实现换行 .collect(Collectors.joining(",\n")); // 最后拼接JSON首尾的大括号 return "&#123;\n" + jsonBody + "\n&#125;"; &#125; /** * 检查对象是否可被序列化成JSON * @param object 将被序列化的对象 * @return 是否可被序列化 */ private static boolean isSerializable(Object object) &#123; // null不可被序列化 if (object == null) &#123; return false; &#125; Class clazz = object.getClass(); // 如果有JsonSerializable注解，即可被序列化 return clazz.isAnnotationPresent(JsonSerializable.class); &#125;&#125;使用自定义注解首先创建一个BookModel类：12345678910111213141516171819202122232425262728293031323334353637/** * 书籍信息 */@JsonSerializablepublic class BookModel &#123; /** * 书名 */ @JsonElement(key = "bookname") // 在JSON中将bookName重命名为bookname private String bookName; /** * 分类 */ @JsonElement private String category; /** * 价格 */ @JsonElement private int price; @Override public String toString() &#123; return "BookModel&#123;" + "bookName='" + bookName + '\'' + ", category='" + category + '\'' + ", price=" + price + '&#125;'; &#125; /** * getter，setter和构造方法略 */&#125;接下来在main方法里构造对象，并将其序列化成JSON：12345678910public static void main(String[] args) &#123; BookModel book = new BookModel("Head First Java", "Java", 55); try &#123; System.out.println(JsonUtils.serializeToJson(book)); &#125; catch (InvocationTargetException | IllegalAccessException | NoSuchMethodException e) &#123; e.printStackTrace(); &#125;&#125;序列化后的结果将是这样：12345&#123; "bookname":"Head First Java", "category":"Java", "price":"55"&#125;]]></content>
      <categories>
        <category>学习记录</category>
        <category>Java</category>
        <category>基础知识</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>注解</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[循序渐进写一个Servlet(5) - Filter]]></title>
    <url>%2Fprojects%2Fjava%2FServlet%2Fjava-servlet-5-filter.html</url>
    <content type="text"><![CDATA[Servlet（Server Applet），全称Java Servlet，是用Java编写的服务器端程序。其主要功能在于交互式地浏览和修改数据，生成动态Web内容。本系列将一步步地写出一个Servlet程序。这篇博文将演示如何创建和使用filter。什么是Filter当客户端向servlet容器发送请求时，请求通常会直接发送到servlet进行处理，就像下图这样：但是，如果希望在请求被servlet处理之前和之后，再进行一些附加的处理，就可以使用Filter完成。一个常见的使用场景是，在filter中定义如何检查请求是否合法，比如请求头中是否携带了有效的认证和鉴权信息；或者可以在filter中针对请求和响应记录日志。怎么使用Filterjavax.servlet.Filter接口定义了一个filter的生命周期，要创建一个filter，就要实现Filter接口。Filter接口包含下列方法声明：init()，用于定义在初始化这个filter时要执行的操作，该方法在filter的生命周期内只会执行一次；doFilter()，用于定义这个filter要进行的操作，每当有请求被发送到与该filter绑定的资源时，该方法都会被执行一次；destroy()，用于定义在停止这个filter时要执行的操作，只会在一个filter被销毁时执行。创建一个实现Filter接口的类12345678910111213141516public class Filter1 implements Filter &#123; @Override public void init(FilterConfig filterConfig) throws ServletException &#123; &#125; @Override public void doFilter(ServletRequest request, ServletResponse response, FilterChain chain) throws IOException, ServletException &#123; &#125; @Override public void destroy() &#123; &#125;&#125;定义这个filter的行为在doFilter()方法内定义这个filter的行为。123456789101112@Overridepublic void doFilter(ServletRequest request, ServletResponse response, FilterChain chain) throws IOException, ServletException &#123; // 在处理请求前打印信息 System.out.println("Request passing through Filter 1"); // 交由FilterChain将请求交给下一个filter或交给servlet处理 chain.doFilter(request, response); // servlet发送响应后打印信息 System.out.println("Response passing througe Filter 1");&#125;在容器中注册filter与servlet一样，filter也需要在容器中注册之后才能发挥作用。注册filter也有两种方式：通过web.xml，或者通过@WebFilter注解。这里有一点需要注意，虽然filter之间没有依赖关系，但是如果要保证filter的执行顺序，那么必须使用web.xml来注册。Servlet 3.0 规范的8.2.3节中有如下说明：If the order in which the listeners, servlets, filters are invoked is important to an application then a deployment descriptor must be used.因为使用注解注册的filter，其调用顺序没有在规范中指定。As described above, when using annotations to define the listeners, servlets and filters, the order in which they are invoked is unspecified.如果一定要使用注解并保证filter的执行顺序，那么可以参考Stack Overflow中这篇回答。为了演示filter的执行顺序，这里再增加一个名为Filter2的filter，内容与Filter1类似。web.xml在web.xml中增加如下配置：1234567891011121314151617&lt;filter&gt; &lt;filter-name&gt;filter1&lt;/filter-name&gt; &lt;filter-class&gt;com.boris.tomcatlistener.filter.Filter1&lt;/filter-class&gt;&lt;/filter&gt;&lt;filter-mapping&gt; &lt;filter-name&gt;filter1&lt;/filter-name&gt; &lt;url-pattern&gt;/demoServlet&lt;/url-pattern&gt;&lt;/filter-mapping&gt;&lt;filter&gt; &lt;filter-name&gt;filter2&lt;/filter-name&gt; &lt;filter-class&gt;com.boris.tomcatlistener.filter.Filter2&lt;/filter-class&gt;&lt;/filter&gt;&lt;filter-mapping&gt; &lt;filter-name&gt;filter2&lt;/filter-name&gt; &lt;url-pattern&gt;/demoServlet&lt;/url-pattern&gt;&lt;/filter-mapping&gt;filter标签描述了一个filter的基本信息，其中filter名称(filter-name)和filter所在类(filter-class)为必填项。filter-mapping标签描述了一个filter将与哪个URL或者与哪个servlet绑定，filter-name指定使用哪个filter处理请求，url-pattern指定发往哪个URL的请求会触发这个filter，servlet-name指定发往哪个servlet的请求会触发这个filter。url-pattern和servlet-name可以同时存在，也可以同时存在多个。filter-mapping标签的先后顺序，将决定filter链中各个filter被调用的先后顺序。如上文中先配置了filter1后配置了filter2，那么在请求到达时，会先执行filter1然后再执行filter2。配置完毕后部署并运行该项目，向http://localhost:8080/servletdemo/DemoServlet发送一个请求，在控制台可以看到如下输出：1234Request passing through Filter 1Request passing through Filter 2Response passing througe Filter 2Response passing througe Filter 1@WebFilter注解@WebFilter是Servlet 3.0中新增的特性，在Tomcat 7及以前版本中将无法工作。以Filter1为例，为其添加如下注解：1234@WebFilter( filterName = "filter1", urlPatterns = "/demoServlet")filter-name属性指定了这个filter的名称。有三个属性可以指定filter的触发条件：valueurlPatternsservletNames以上三个属性都可以接受一个字符串，或者用大括号包括起来的多个字符串。在注解只有一个参数，并且该参数是指定要匹配的URL时，建议使用value属性，比如这样：12345// value为默认的属性@WebFilter("/demoServlet")// 显式指定value属性@WebFilter(value = "/demoServlet")否则，建议使用urlPatterns属性和servletNames属性。不允许value和urlPatterns同时出现。Servlet 3.0 规范的8.1.2 @WebFilter节中说明原文如下：It is recommended to use value when the only attribute on the annotation is the url pattern and to use the urlPatterns attribute when the other attributes are also used. It is illegal to have both value and urlPatterns attribute used together on the same annotation.配置完毕后部署并运行该项目，向http://localhost:8080/servletdemo/DemoServlet发送一个请求，在控制台可以看到如下输出：12Request passing through Filter 1Response passing througe Filter 1系列博文循序渐进写一个Servlet(1) - 介绍相关的接口和类循序渐进写一个Servlet(2) - 第一个servlet循序渐进写一个Servlet(3) - 分别处理GET和POST循序渐进写一个Servlet(4) - 会话追踪循序渐进写一个Servlet(5) - Filter]]></content>
      <categories>
        <category>学习记录</category>
        <category>Java</category>
        <category>Servlet</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Servlet</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[循序渐进写一个Servlet(4) - 会话追踪]]></title>
    <url>%2Fprojects%2Fjava%2FServlet%2Fjava-servlet-4-session-tracking.html</url>
    <content type="text"><![CDATA[Servlet（Server Applet），全称Java Servlet，是用Java编写的服务器端程序。其主要功能在于交互式地浏览和修改数据，生成动态Web内容。本系列将一步步地写出一个Servlet程序。这篇博文将演示如何使用cookie和session进行会话追踪。HTTP协议是一个无状态的协议，也就是说，在服务器眼中，每一个HTTP请求都是一个全新的请求，每个请求之间没有关联。所以我们需要一个可以管理请求中携带的用户信息的方法。而会话追踪就是一个可以管理用户信息的方法。会话追踪可以通过下列几个方式实现：Cookie表单隐藏域URL改写HttpSession本文将主要演示Cookie和HttpSession的用法。Cookie什么是cookieCookie是一串可以持久化于各个请求之间的信息片段。每个cookie都有一个名字，并有一个值，同时可以包含备注、路径、域名、过期时间、版本等附加信息。Cookie有两种：非持久cookie，这种cookie只在会话中存留，并且不具有过期时间属性，一旦用户关闭浏览器(或者标签页)，也就是使这个会话失效，这个cookie就会丢失。持久化cookie，这种cookie可以被用于多个会话中，而且只会在到达过期时间，或者用户主动使该cookie失效后，才会被删除。可以使用HttpServletResponse#addCookie(Cookie)方法在HTTP响应中携带cookie。保存cookie首先修改前文中的doPost()方法，将请求中的参数取出来，并存入cookie。12345678910111213141516171819202122232425262728293031323334353637@Overridepublic void doPost(HttpServletRequest request, HttpServletResponse response) throws IOException &#123; // 设定返回内容的MIME类型 response.setContentType("text/html"); // 设定内容以UTF-8编码 response.setCharacterEncoding("utf-8"); // 取出所有参数，得到一个Map Map parameterMap = request.getParameterMap(); try (PrintWriter writer = response.getWriter()) &#123; // 开始输出HTML文本 writer.print("&lt;html lang=\"en\"&gt;"); writer.print("&lt;body&gt;"); writer.print("&lt;b&gt;Response from DemoServlet&lt;/b&gt;"); writer.print("&lt;br&gt;"); writer.print("&lt;b&gt;Handled by &lt;code&gt;doPost()&lt;/code&gt;&lt;/b&gt;"); writer.print("&lt;br&gt;"); // 输出当前session的ID writer.print("&lt;b&gt;Session ID: " + request.getSession().getId() + "&lt;/b&gt;"); writer.print("&lt;br&gt;"); // 遍历parameterMap parameterMap.forEach((k, v) -&gt; &#123; // 将参数以 key = value 形式输出 writer.print(k + " = " + ((String[]) v)[0] + "&lt;br&gt;"); // 将参数的key作为cookie的name，参数的value作为cookie的value response.addCookie(new Cookie(String.valueOf(k), ((String[]) v)[0])); &#125;); writer.print("&lt;/body&gt;"); writer.print("&lt;/html&gt;"); &#125;&#125;然后发送一个POST请求，在返回中可以看到请求中的参数已经被放到cookie中，并返回到了客户端。使用cookie一旦cookie被保存到了客户端，那么在下次访问这个cookie所对应的地址时，客户端就会自动将相关的cookie带入请求一并发送到服务端。所以客户端不需要对cookie主动做任何操作。修改前文中的doGet()方法，使其可以取出cookie的值，并输出到页面上。12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758@Overridepublic void doGet(HttpServletRequest request, HttpServletResponse response) throws IOException &#123; // 设定返回内容的MIME类型 response.setContentType("text/html"); // 设定内容以UTF-8编码 response.setCharacterEncoding("utf-8"); // 使用Optional类简化null判断 Optional&lt;String&gt; optionalQueryString = Optional.ofNullable(request.getQueryString()); // 取出每个参数 String[] queryStrings = optionalQueryString.isPresent() ? optionalQueryString.get().split("&amp;") : new String[]&#123;&#125;; try (PrintWriter writer = response.getWriter()) &#123; // 开始输出HTML文本 writer.print("&lt;html lang=\"en\"&gt;"); writer.print("&lt;body&gt;"); writer.print("&lt;b&gt;Response from DemoServlet&lt;/b&gt;"); writer.print("&lt;br&gt;"); writer.print("&lt;b&gt;Handled by &lt;code&gt;doGet()&lt;/code&gt;&lt;/b&gt;"); writer.print("&lt;br&gt;"); // 输出当前session的ID writer.print("&lt;b&gt;Session ID: " + request.getSession().getId() + "&lt;/b&gt;"); writer.print("&lt;br&gt;"); writer.print("&lt;br&gt;"); writer.print("&lt;b&gt;Parameters: &lt;/b&gt;"); writer.print("&lt;br&gt;"); // 遍历每个参数 for (String query : queryStrings) &#123; // 取出参数的key和value String[] q = query.split("="); writer.print(q[0] + " = " + q[1] + "&lt;br&gt;"); &#125; writer.print("&lt;br&gt;"); writer.print("&lt;b&gt;Cookies:&lt;/b&gt;"); writer.print("&lt;br&gt;"); // 从request中取出cookie Cookie[] cookies = request.getCookies(); // 遍历各个cookie for (Cookie cookie : cookies) &#123; // 输出其name和value writer.print(cookie.getName() + " = " + cookie.getValue()); writer.print("&lt;br&gt;"); &#125; writer.print("&lt;/body&gt;"); writer.print("&lt;/html&gt;"); &#125;&#125;然后发送一个GET请求，在返回中可以看到cookie中的内容已经被输出到页面上。删除cookie将cookie的存活时间设为0，并返回到客户端，即可从客户端中删除这个cookie。123456789101112131415161718192021222324@Overrideprotected void doDelete(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException &#123; Cookie[] cookies = req.getCookies(); for (Cookie cookie : cookies) &#123; // JSESSIONID存放的是当前session的ID // 如果删掉这个cookie，那么当前的session也会被丢弃 if (!"JSESSIONID".equalsIgnoreCase(cookie.getName())) &#123; // 设定存活时间为0秒 cookie.setMaxAge(0); // 将修改过的cookie放入响应中返回到客户端 resp.addCookie(cookie); &#125; &#125; try (PrintWriter writer = resp.getWriter()) &#123; // 因为response需要输出到客户端，才可以使新的cookie被送到客户端 // 但是又懒得输出那么多东西了 // 所以就输出了一个空字符串 // 实际上输出内容不影响对cookie的操作 writer.print(""); &#125;&#125;HttpSession什么是sessionSession记录着一次会话相关的信息。当一个请求到达服务器后，服务器会检查请求中是否包含session ID信息，比如在Tomcat中就是检查有无JSESSIONID这个cookie，或者URL中有无JSESSIONID这个查询字符串。如果找到了对应的session，则服务器会将这个session检索出来使用；请求中没有包含session ID，或者对应的session已经被销毁，则服务器会创建一个新的session并返回其ID。Session ID通常以cookie的形式返回到客户端，如果客户端禁用了cookie，那么服务端则会使用URL重写技术将session ID写到URL中。Session中可以键值对的形式保存附加数据，称为attributes。与cookie不同，session保存于服务器端，而且它能保存的数据也不仅限于字符串。保存attribute修改doPost()方法，编写修改session的代码。修改完成后发送一个带有参数的POST请求，以向session中写入一些数据。123456789101112131415161718192021222324252627282930313233343536373839404142434445@Overridepublic void doPost(HttpServletRequest request, HttpServletResponse response) throws IOException &#123; // 设定返回内容的MIME类型 response.setContentType("text/html"); // 设定内容以UTF-8编码 response.setCharacterEncoding("utf-8"); // 取出所有参数，得到一个Map Map parameterMap = request.getParameterMap(); // 获取当前会话的session // 如果没有，则会新建一个session并返回其ID HttpSession session = request.getSession(); try (PrintWriter writer = response.getWriter()) &#123; // 开始输出HTML文本 writer.print("&lt;html lang=\"en\"&gt;"); writer.print("&lt;body&gt;"); writer.print("&lt;b&gt;Response from DemoServlet&lt;/b&gt;"); writer.print("&lt;br&gt;"); writer.print("&lt;b&gt;Handled by &lt;code&gt;doPost()&lt;/code&gt;&lt;/b&gt;"); writer.print("&lt;br&gt;"); // 输出当前session的ID writer.print("&lt;b&gt;Session ID: " + request.getSession().getId() + "&lt;/b&gt;"); writer.print("&lt;br&gt;"); // 遍历parameterMap parameterMap.forEach((k, v) -&gt; &#123; // 将参数以 key = value 形式输出 writer.print(k + " = " + ((String[]) v)[0] + "&lt;br&gt;"); // 将参数的key作为cookie的name，参数的value作为cookie的value Cookie cookie = new Cookie(String.valueOf(k), ((String[]) v)[0]); response.addCookie(cookie); // 将各个参数放到session的attributes中 session.setAttribute(String.valueOf(k), ((String[]) v)[0]); &#125;); writer.print("&lt;/body&gt;"); writer.print("&lt;/html&gt;"); &#125;&#125;取出attribute修改doGet()方法，使其可以从session中取出attributes并显示在页面上。12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879@Overridepublic void doGet(HttpServletRequest request, HttpServletResponse response) throws IOException &#123; // 设定返回内容的MIME类型 response.setContentType("text/html"); // 设定内容以UTF-8编码 response.setCharacterEncoding("utf-8"); // 使用Optional类简化null判断 Optional&lt;String&gt; optionalQueryString = Optional.ofNullable(request.getQueryString()); // 获取当前会话的session HttpSession session = request.getSession(); // 取出所有attribute的name Enumeration&lt;String&gt; attributeNames = session.getAttributeNames(); // 取出每个参数 String[] queryStrings = optionalQueryString.isPresent() ? optionalQueryString.get().split("&amp;") : new String[]&#123;&#125;; try (PrintWriter writer = response.getWriter()) &#123; // 开始输出HTML文本 writer.print("&lt;html lang=\"en\"&gt;"); writer.print("&lt;body&gt;"); writer.print("&lt;b&gt;Response from DemoServlet&lt;/b&gt;"); writer.print("&lt;br&gt;"); writer.print("&lt;b&gt;Handled by &lt;code&gt;doGet()&lt;/code&gt;&lt;/b&gt;"); writer.print("&lt;br&gt;"); // 输出当前session的ID writer.print("&lt;b&gt;Session ID: " + request.getSession().getId() + "&lt;/b&gt;"); writer.print("&lt;br&gt;"); writer.print("&lt;br&gt;"); writer.print("&lt;b&gt;Parameters: &lt;/b&gt;"); writer.print("&lt;br&gt;"); // 遍历每个参数 for (String query : queryStrings) &#123; // 取出参数的key和value String[] q = query.split("="); writer.print(q[0] + " = " + q[1] + "&lt;br&gt;"); &#125; writer.print("&lt;br&gt;"); writer.print("&lt;b&gt;Cookies:&lt;/b&gt;"); writer.print("&lt;br&gt;"); // 从request中取出cookie Cookie[] cookies = request.getCookies(); // 遍历各个cookie for (Cookie cookie : cookies) &#123; // 输出其name和value writer.print(cookie.getName() + " = " + cookie.getValue()); writer.print("&lt;br&gt;"); &#125; writer.print("&lt;br&gt;"); writer.print("&lt;b&gt;Attributes: &lt;/b&gt;"); writer.print("&lt;br&gt;"); // 遍历attribute的各个name while(attributeNames.hasMoreElements()) &#123; String key = attributeNames.nextElement(); // 取出attribute的值 String value = String.valueOf(session.getAttribute(key)); writer.print(key + " = " + value); writer.print("&lt;br&gt;"); &#125; writer.print("&lt;/body&gt;"); writer.print("&lt;/html&gt;"); &#125;&#125;然后发送一个GET请求，在返回中就可以看到刚才保存在session中的数据：删除attribute此外HttpSession类提供了removeAttribute()方法用于删除一个attribute。12345678910111213141516171819202122232425262728293031323334353637@Overrideprotected void doDelete(HttpServletRequest req, HttpServletResponse resp) throws ServletException, IOException &#123; Cookie[] cookies = req.getCookies(); // 获取当前会话的session HttpSession session = req.getSession(); Enumeration&lt;String&gt; attributeNames = session.getAttributeNames(); for (Cookie cookie : cookies) &#123; // JSESSIONID存放的是当前session的ID // 如果删掉这个cookie，那么当前的session也会被丢弃 if (!"JSESSIONID".equalsIgnoreCase(cookie.getName())) &#123; // 设定存活时间为0秒 cookie.setMaxAge(0); // 将修改过的cookie放入响应中返回到客户端 resp.addCookie(cookie); &#125; // 遍历attribute names while(attributeNames.hasMoreElements()) &#123; String key = attributeNames.nextElement(); // 将其从session中移除 session.removeAttribute(key); &#125; &#125; try (PrintWriter writer = resp.getWriter()) &#123; // 因为response需要输出到客户端，才可以使新的cookie被送到客户端 // 但是又懒得输出那么多东西了 // 所以就输出了一个空字符串 // 实际上输出内容不影响对cookie的操作 writer.print(""); &#125;&#125;系列博文循序渐进写一个Servlet(1) - 介绍相关的接口和类循序渐进写一个Servlet(2) - 第一个servlet循序渐进写一个Servlet(3) - 分别处理GET和POST循序渐进写一个Servlet(4) - 会话追踪循序渐进写一个Servlet(5) - Filter]]></content>
      <categories>
        <category>学习记录</category>
        <category>Java</category>
        <category>Servlet</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Servlet</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[生产者与消费者问题在Java中的实现]]></title>
    <url>%2Fprojects%2Fjava%2Ffundamentals%2Fjava-multi-threading-producer-consumer-problem.html</url>
    <content type="text"><![CDATA[生产者与消费者问题(Producer-consumer problem)，也叫有限缓冲问题(Bounded-buffer problem)，是一个经典的多线程同步问题案例。该问题中有两个线程共享一个固定大小的缓冲区，一个线程作为生产者，负责向缓冲区中放入数据；另一个线程作为消费者，负责从缓冲区中取出数据。该问题的重点在于，要保证当缓冲区满时，生产者不能继续向其中放入数据，而当缓冲区空时，消费者也不能从缓冲区中取出数据。那么要保证以上两点，需要在缓冲区空时休眠消费者线程，并当缓冲区有数据之后唤醒消费者线程；以及当缓冲区满时休眠生产者线程，在缓冲区有空闲空间后唤醒生产者线程，或者直接在缓冲区满时放弃未存入缓冲区的数据。这个问题的难点在于可能会产生死锁。当陷入死锁时，生产者和消费者都会处于休眠状态，并等待对方唤醒自己。使用同步锁实现产品类产品类代表将要被生产和消费的产品。12345678910111213141516171819202122232425/** * 生产者-消费者问题 -- 产品类 */public class Product &#123; private int productId; public Product(int productId) &#123; this.productId = productId; &#125; @Override public String toString() &#123; return "Product&#123;" + "productId=" + productId + '&#125;'; &#125; public int getProductId() &#123; return productId; &#125; public void setProductId(int productId) &#123; this.productId = productId; &#125;&#125;仓库类仓库类用来构造一个存放产品的数组，并带有存取数组的方法(pop/push)，本质上是一个栈。12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879/** * 生产者-消费者问题 -- 仓库类(缓冲区) */public class Warehouse &#123; private Product[] products; /** * 栈顶指针 */ private int top = 0; public Warehouse() &#123; products = new Product[10]; &#125; public Warehouse(int capacity) &#123; products = new Product[capacity]; &#125; /** * 生产产品 * * @param product 产品 */ public synchronized void push(Product product) &#123; // 如果仓库已满 if (top == products.length) &#123; try &#123; System.out.println("Warehouse full."); // 将生产者线程置于等待态 wait(); &#125; catch (InterruptedException e) &#123; System.out.println("Warehouse full but failed to wait. Reason:"); System.out.println(e.getMessage()); &#125; &#125; products[top++] = product; // 现在仓库已有产品 // 可以唤醒消费者线程 notifyAll(); &#125; /** * 消费产品 * * @return 取出的产品 */ public synchronized Product pop() &#123; Product product = null; // 如果仓库空 while (products[0] == null) &#123; System.out.println("Warehouse empty"); // 唤醒生产者线程 notifyAll(); try &#123; // 将消费者线程置于等待态 wait(); &#125; catch (InterruptedException e) &#123; System.out.println("Warehouse empty but failed to wait. Reason:"); System.out.println(e.getMessage()); &#125; &#125; product = products[--top]; products[top] = null; // 仓库非满，可以唤醒生产者线程 notifyAll(); return product; &#125;&#125;生产者123456789101112131415161718192021222324252627282930313233343536public class Producer implements Runnable &#123; private String producerName; private Warehouse warehouse; private Random random = new Random(); public Producer(String producerName, Warehouse warehouse) &#123; this.producerName = producerName; this.warehouse = warehouse; &#125; @Override public void run() &#123; produce(); &#125; /** * 生产产品并存入仓库 */ private void produce() &#123; int i = 0; while (true) &#123; Product product = new Product(i++); warehouse.push(product); System.out.println("[PRODUCED] Product " + product.getProductId()); try &#123; Thread.sleep(random.nextInt(20) * 100); &#125; catch (InterruptedException e) &#123; System.out.println("Exception occurred in producer thread. Reason: " + e.getMessage()); &#125; &#125; &#125;&#125;消费者1234567891011121314151617181920212223242526272829public class Consumer implements Runnable &#123; private String consumerName; private Warehouse warehouse; private Random random = new Random(); public Consumer(String consumerName, Warehouse warehouse) &#123; this.consumerName = consumerName; this.warehouse = warehouse; &#125; @Override public void run() &#123; consume(); &#125; private void consume() &#123; while (true) &#123; Product product = warehouse.pop(); System.out.println("[CONSUMED] Product " + product.getProductId()); try &#123; Thread.sleep(random.nextInt(20) * 100); &#125; catch (InterruptedException e) &#123; System.out.println("Exception occurred in consumer thread. Reason: " + e.getMessage()); &#125; &#125; &#125;&#125;Main类123456789101112131415161718192021public class Main &#123; public static void main(String[] args) &#123; Warehouse warehouse = new Warehouse(); Producer producer = new Producer("producer", warehouse); Consumer consumer = new Consumer("consumer", warehouse); ExecutorService executorService = Executors.newCachedThreadPool(); executorService.execute(consumer); executorService.execute(producer); executorService.shutdown(); while (!executorService.isTerminated()) &#123; &#125; System.out.println("Thread pool is down"); &#125;&#125;运行结果1234567891011121314151617181920212223Warehouse empty[PRODUCED] Product 0[CONSUMED] Product 0[PRODUCED] Product 1[CONSUMED] Product 1[PRODUCED] Product 2[PRODUCED] Product 3[PRODUCED] Product 4[PRODUCED] Product 5[CONSUMED] Product 5[PRODUCED] Product 6[CONSUMED] Product 6[CONSUMED] Product 4[CONSUMED] Product 3[CONSUMED] Product 2[PRODUCED] Product 7[CONSUMED] Product 7[PRODUCED] Product 8[CONSUMED] Product 8Warehouse empty[PRODUCED] Product 9[CONSUMED] Product 9Warehouse empty使用阻塞队列实现相比较于队列，阻塞队列(Blocking queue)可以在队列空时阻塞取值操作，并在队列满时阻塞存入操作。实际上根据调用不同的方法，可以实现在队列空/满时抛出异常、返回特殊值、阻塞操作、带超时的阻塞操作，具体请参考BlockingQueue文档产品类和仓库类产品类实现同上，仓库使用阻塞队列(ArrayBlockingQueue)实现。生产者12345678910111213141516171819202122232425262728293031323334353637383940public class Producer implements Runnable &#123; private String producerName; private BlockingQueue&lt;Product&gt; warehouse; private Random random = new Random(); public Producer(String producerName, BlockingQueue&lt;Product&gt; warehouse) &#123; this.producerName = producerName; this.warehouse = warehouse; &#125; @Override public void run() &#123; produce(); &#125; /** * 生产产品并存入仓库 */ private void produce() &#123; int i = 0; while (true) &#123; Product product = new Product(i++); try &#123; warehouse.put(product); &#125; catch (InterruptedException e) &#123; System.out.println("Exception occurred when putting product in producer. Reason: " + e.getMessage()); &#125; System.out.println("[PRODUCED] Product " + product.getProductId()); try &#123; Thread.sleep(random.nextInt(20) * 100); &#125; catch (InterruptedException e) &#123; System.out.println("Exception occurred in producer thread. Reason: " + e.getMessage()); &#125; &#125; &#125;&#125;消费者12345678910111213141516171819202122232425262728293031323334public class Consumer implements Runnable &#123; private String consumerName; private BlockingQueue&lt;Product&gt; warehouse; private Random random = new Random(); public Consumer(String consumerName, BlockingQueue&lt;Product&gt; warehouse) &#123; this.consumerName = consumerName; this.warehouse = warehouse; &#125; @Override public void run() &#123; consume(); &#125; private void consume() &#123; while (true) &#123; Product product = null; try &#123; product = warehouse.take(); &#125; catch (InterruptedException e) &#123; System.out.println("Exception occurred when taking product in consumer. Reason: " + e.getMessage()); &#125; System.out.println("[CONSUMED] Product " + product.getProductId()); try &#123; Thread.sleep(random.nextInt(20) * 100); &#125; catch (InterruptedException e) &#123; System.out.println("Exception occurred in consumer thread. Reason: " + e.getMessage()); &#125; &#125; &#125;&#125;运行结果1234567891011121314151617[PRODUCED] Product 0[CONSUMED] Product 0[PRODUCED] Product 1[CONSUMED] Product 1[PRODUCED] Product 2[CONSUMED] Product 2[PRODUCED] Product 3[CONSUMED] Product 3[PRODUCED] Product 4[CONSUMED] Product 4[PRODUCED] Product 5[PRODUCED] Product 6[CONSUMED] Product 5[PRODUCED] Product 7[PRODUCED] Product 8[CONSUMED] Product 6[PRODUCED] Product 9]]></content>
      <categories>
        <category>学习记录</category>
        <category>Java</category>
        <category>基础知识</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>多线程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[循序渐进写一个Servlet(3) - 分别处理GET和POST]]></title>
    <url>%2Fprojects%2Fjava%2FServlet%2Fjava-servlet-3-handle-get-and-post.html</url>
    <content type="text"><![CDATA[Servlet（Server Applet），全称Java Servlet，是用Java编写的服务器端程序。其主要功能在于交互式地浏览和修改数据，生成动态Web内容。本系列将一步步地写出一个Servlet程序。这篇博文将演示如何分别处理GET和POST请求，以及处理请求中的参数。编写doGet()和doPost()方法首先把要实现的功能写好，后面才好调用不是。1234567891011121314151617public void doGet(HttpServletRequest request, HttpServletResponse response) throws IOException &#123; // 设定返回内容的MIME类型 response.setContentType("text/html"); // 设定内容以UTF-8编码 response.setCharacterEncoding("utf-8"); try (PrintWriter writer = response.getWriter()) &#123; // 开始输出HTML文本 writer.print("&lt;html lang=\"en\"&gt;"); writer.print("&lt;body&gt;"); writer.print("&lt;b&gt;Response from DemoServlet&lt;/b&gt;"); writer.print("&lt;b&gt;Handled by &lt;code&gt;doGet()&lt;/code&gt;&lt;/b&gt;"); writer.print("&lt;/body&gt;"); writer.print("&lt;/html&gt;"); &#125;&#125;1234567891011121314151617public void doPost(HttpServletRequest request, HttpServletResponse response) throws IOException &#123; // 设定返回内容的MIME类型 response.setContentType("text/html"); // 设定内容以UTF-8编码 response.setCharacterEncoding("utf-8"); try (PrintWriter writer = response.getWriter()) &#123; // 开始输出HTML文本 writer.print("&lt;html lang=\"en\"&gt;"); writer.print("&lt;body&gt;"); writer.print("&lt;b&gt;Response from DemoServlet&lt;/b&gt;"); writer.print("&lt;b&gt;Handled by &lt;code&gt;doPost()&lt;/code&gt;&lt;/b&gt;"); writer.print("&lt;/body&gt;"); writer.print("&lt;/html&gt;"); &#125;&#125;区分HTTP方法因为servlet是调用service()方法来处理请求的，所以对请求做区分也需要在service()方法中进行。1234567891011121314151617@Overridepublic void service(ServletRequest req, ServletResponse res) throws ServletException, IOException &#123; HttpServletRequest httpServletRequest = (HttpServletRequest) req; HttpServletResponse httpServletResponse = (HttpServletResponse) res; if ("GET".equalsIgnoreCase(httpServletRequest.getMethod())) &#123; doGet(httpServletRequest, httpServletResponse); &#125; else if ("POST".equalsIgnoreCase(httpServletRequest.getMethod())) &#123; doPost(httpServletRequest, httpServletResponse); &#125; else &#123; // 如果请求既不是GET也不是POST // 那么就返回HTTP 501 NOT IMPLEMENTED状态码 // 毕竟不能把请求直接扔了，总是要有个返回的 httpServletResponse.sendError(501); &#125;&#125;运行起来看看效果首先发个GET请求再发个POST请求为什么不用HttpServlet类呢没错，上面做的，就是自己实现了一个简陋的HttpServlet类，因为是循序渐进嘛，没头没脑的直接砸上来一个，算什么循序渐进。那么现在就让DemoServlet继承HttpServlet。同时，因为HttpServlet已经在service()方法中实现了判断请求类型，所以DemoServlet中不要覆盖service()方法，只覆盖doGet()和doPost()方法。12345678910111213141516171819202122232425262728293031323334353637383940public class DemoServlet extends HttpServlet &#123; @Override public void doGet(HttpServletRequest request, HttpServletResponse response) throws IOException &#123; // 设定返回内容的MIME类型 response.setContentType("text/html"); // 设定内容以UTF-8编码 response.setCharacterEncoding("utf-8"); try (PrintWriter writer = response.getWriter()) &#123; // 开始输出HTML文本 writer.print("&lt;html lang=\"en\"&gt;"); writer.print("&lt;body&gt;"); writer.print("&lt;b&gt;Response from DemoServlet&lt;/b&gt;"); writer.print("&lt;b&gt;Handled by &lt;code&gt;doGet()&lt;/code&gt;&lt;/b&gt;"); writer.print("&lt;/body&gt;"); writer.print("&lt;/html&gt;"); &#125; &#125; @Override public void doPost(HttpServletRequest request, HttpServletResponse response) throws IOException &#123; // 设定返回内容的MIME类型 response.setContentType("text/html"); // 设定内容以UTF-8编码 response.setCharacterEncoding("utf-8"); try (PrintWriter writer = response.getWriter()) &#123; // 开始输出HTML文本 writer.print("&lt;html lang=\"en\"&gt;"); writer.print("&lt;body&gt;"); writer.print("&lt;b&gt;Response from DemoServlet&lt;/b&gt;"); writer.print("&lt;b&gt;Handled by &lt;code&gt;doPost()&lt;/code&gt;&lt;/b&gt;"); writer.print("&lt;/body&gt;"); writer.print("&lt;/html&gt;"); &#125; &#125;&#125;处理请求中的参数HTTP请求是可以带参数的，有了参数，那就得处理。处理GET请求的参数GET请求里带的参数，名字叫查询字符串(query string)，是一组或多组key=value格式的键值对。Query string写在URL后面，以一个问号起头，用&amp;分隔各个键值对，即类似http://localhost:8080/appname/servlet?arg1=value1&amp;arg2=value2&amp;...&amp;argN=valueN。在代码里使用HttpServletRequest#getQueryString()方法，就可以获取到问号后面的query string，分别用&amp;和=分割字符串，就可以取到每个参数的key和value。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051@Overridepublic void doGet(HttpServletRequest request, HttpServletResponse response) throws IOException &#123; // 设定返回内容的MIME类型 response.setContentType("text/html"); // 设定内容以UTF-8编码 response.setCharacterEncoding("utf-8"); /* String queryString = request.getQueryString(); String[] queryStrings; if (queryString != null) &#123; queryStrings = queryString.split("&amp;"); &#125; else &#123; queryStrings = new String[]&#123;&#125;; &#125; */ // 使用Optional类简化null判断 Optional&lt;String&gt; optionalQueryString = Optional.ofNullable(request.getQueryString()); // 如果有query string则取出每个参数 // 如果没有则返回一个空的String数组 String[] queryStrings = optionalQueryString.isPresent() ? optionalQueryString.get().split("&amp;") : new String[]&#123;&#125;; try (PrintWriter writer = response.getWriter()) &#123; // 开始输出HTML文本 writer.print("&lt;html lang=\"en\"&gt;"); writer.print("&lt;body&gt;"); writer.print("&lt;b&gt;Response from DemoServlet&lt;/b&gt;"); writer.print("&lt;b&gt;Handled by &lt;code&gt;doGet()&lt;/code&gt;&lt;/b&gt;"); writer.print("&lt;br&gt;"); // 遍历每个参数 for (String query : queryStrings) &#123; // 取出参数的key和value String[] q = query.split("="); writer.print(q[0] + " = " + q[1] + "&lt;br&gt;"); &#125; writer.print("&lt;br&gt;"); writer.print("&lt;/body&gt;"); writer.print("&lt;/html&gt;"); &#125;&#125;运行一下，结果是这样子的：处理POST请求的参数POST请求的参数就叫参数(parameter)，位于请求体(body)里，格式由Content-Type请求头决定。详细介绍可以参考这篇MDN文档。HttpServletRequest#getParameterMap()方法可以取出请求中的所有参数，并放到一个Map中。123456789101112131415161718192021222324252627@Overridepublic void doPost(HttpServletRequest request, HttpServletResponse response) throws IOException &#123; // 设定返回内容的MIME类型 response.setContentType("text/html"); // 设定内容以UTF-8编码 response.setCharacterEncoding("utf-8"); // 取出所有参数，得到一个Map Map parameterMap = request.getParameterMap(); try (PrintWriter writer = response.getWriter()) &#123; // 开始输出HTML文本 writer.print("&lt;html lang=\"en\"&gt;"); writer.print("&lt;body&gt;"); writer.print("&lt;b&gt;Response from DemoServlet&lt;/b&gt;"); writer.print("&lt;b&gt;Handled by &lt;code&gt;doPost()&lt;/code&gt;&lt;/b&gt;"); writer.print("&lt;br&gt;"); // 遍历parameterMap parameterMap.forEach((k, v) -&gt; writer.print(k + " = " + ((String[]) v)[0] + "&lt;br&gt;")); writer.print("&lt;/body&gt;"); writer.print("&lt;/html&gt;"); &#125;&#125;本文中将使用application/x-www-form-urlencoded格式做示例。系列博文循序渐进写一个Servlet(1) - 介绍相关的接口和类循序渐进写一个Servlet(2) - 第一个servlet循序渐进写一个Servlet(3) - 分别处理GET和POST循序渐进写一个Servlet(4) - 会话追踪循序渐进写一个Servlet(5) - Filter]]></content>
      <categories>
        <category>学习记录</category>
        <category>Java</category>
        <category>Servlet</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Servlet</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[循序渐进写一个Servlet(2) - 第一个servlet]]></title>
    <url>%2Fprojects%2Fjava%2FServlet%2Fjava-servlet-2-first-servlet.html</url>
    <content type="text"><![CDATA[Servlet（Server Applet），全称Java Servlet，是用Java编写的服务器端程序。其主要功能在于交互式地浏览和修改数据，生成动态Web内容。本系列将一步步地写出一个Servlet程序。这篇博文将演示如何创建一个servlet。新建项目首先，使用Maven的maven-archetype-webapp创建一个Java Webapp项目。这样就可以得到一个Java Webapp项目的基本骨架。将项目命名为servletdemo。创建Servlet对象新建一个名为DemoServlet的类。因为GenericServlet已经实现了一个servlet的生命周期方法，而且这里也不需要对生命周期方法做定制化，所以直接继承一个GenericServlet就可以。1234567public class DemoServlet extends GenericServlet &#123; @Override public void service(ServletRequest req, ServletResponse res) throws ServletException, IOException &#123; &#125;&#125;实现这个servlet的功能service()方法定义了这个servlet的具体实现，这里先让它返回一个HTML。123456789101112131415161718192021@Overridepublic void service(ServletRequest req, ServletResponse res) throws ServletException, IOException &#123; // 设定返回内容的MIME类型 res.setContentType("text/html"); // 设定内容以UTF-8编码 res.setCharacterEncoding("utf-8"); // Java 8 新特性 - try with resources // 该特性优点在于，try代码块执行完毕后，会自动close相关资源 // 要求资源所属的类必须实现了 AutoCloseable 或 Closeable 接口 try (PrintWriter writer = res.getWriter()) &#123; // 开始输出HTML文本 writer.print("&lt;html lang=\"en\"&gt;"); writer.print("&lt;body&gt;"); writer.print("&lt;b&gt;Response from DemoServlet&lt;/b&gt;"); writer.print("&lt;/body&gt;"); writer.print("&lt;/html&gt;"); &#125;&#125;注册到容器光有servlet还不够，下面还需要让容器知道有这个servlet，以及知道要把哪些请求发往这个servlet。这里可以通过修改web.xml的方式，也可以通过注解的方式完成注册。web.xmlweb.xml位于src/main/webapp/WEB_INF/web.xml。向其中添加如下内容：12345678910111213&lt;!-- servlet属性定义了一个servlet的名字和对应的类 --&gt;&lt;servlet&gt; &lt;servlet-name&gt;DemoServlet&lt;/servlet-name&gt; &lt;servlet-class&gt;com.boris.tomcatlistener.servlet.DemoServlet&lt;/servlet-class&gt;&lt;/servlet&gt;&lt;!-- servlet-mapping属性定义了匹配某个URL的请求应该发往哪个servlet --&gt;&lt;servlet-mapping&gt; &lt;!-- 目标servlet的servlet-name --&gt; &lt;servlet-name&gt;DemoServlet&lt;/servlet-name&gt; &lt;!-- 匹配的URL --&gt; &lt;url-pattern&gt;/demoServlet&lt;/url-pattern&gt;&lt;/servlet-mapping&gt;注解WebServlet(String value)注解表明了这个类是一个servlet，其中value的值等同于web.xml中url-patterm参数。在项目部署时，容器会处理WebServlet注解，并将这个servlet与指定的URL pattern绑定。12345678910111213141516171819202122232425@WebServlet(value = "/demoServlet")public class DemoServlet extends GenericServlet &#123; @Override public void service(ServletRequest req, ServletResponse res) throws ServletException, IOException &#123; // 设定返回内容的MIME类型 res.setContentType("text/html"); // 设定内容以UTF-8编码 res.setCharacterEncoding("utf-8"); // Java 8 新特性 - try with resources // 该特性优点在于，try代码块执行完毕后，会自动close相关资源 // 要求资源所属的类必须实现了 AutoCloseable 或 Closeable 接口 try (PrintWriter writer = res.getWriter()) &#123; // 开始输出HTML文本 writer.print("&lt;html lang=\"en\"&gt;"); writer.print("&lt;body&gt;"); writer.print("&lt;b&gt;Response from DemoServlet&lt;/b&gt;"); writer.print("&lt;/body&gt;"); writer.print("&lt;/html&gt;"); &#125; &#125;&#125;运行起来吧，servlet哟！在上面步骤中，创建一个servlet的所有步骤就完成了，尽管这个servlet的功能及其有限，它甚至不能区分发来的HTTP请求。那么，就将这个servlet部署到容器中，让它开始工作吧。启动成功后，使用浏览器，或者HTTP请求构造工具，向http://localhost:8080/servletdemo/DemoServlet（假设Tomcat在监听8080端口）发一条请求。如果一切正常的话，就可以看到服务器返回了上面service()方法中指定的内容。系列博文循序渐进写一个Servlet(1) - 介绍相关的接口和类循序渐进写一个Servlet(2) - 第一个servlet循序渐进写一个Servlet(3) - 分别处理GET和POST循序渐进写一个Servlet(4) - 会话追踪循序渐进写一个Servlet(5) - Filter]]></content>
      <categories>
        <category>学习记录</category>
        <category>Java</category>
        <category>Servlet</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Servlet</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[循序渐进写一个Servlet(1) - 介绍相关的接口和类]]></title>
    <url>%2Fprojects%2Fjava%2FServlet%2Fjava-servlet-1-introducing-classes-and-interfaces.html</url>
    <content type="text"><![CDATA[Servlet（Server Applet），全称Java Servlet，是用Java编写的服务器端程序。其主要功能在于交互式地浏览和修改数据，生成动态Web内容。本系列将一步步地写出一个Servlet程序。这篇博文将介绍一些后面会用到的接口和类。常用的类和接口javax.servlet.Servletjavax.servlet.Servlet是一个接口，它定义了一个servlet必须要实现的方法，包括如何初始化一个servlet，如何让这个servlet处理请求，以及如何将这个servlet从容器中移除，即“生命周期方法”。它们被调用的顺序，即servlet的生命周期，是这样的：容器生成这个servlet的对象，然后调用其init()方法完成初始化步骤当收到请求之后，会调用其service()方法来处理请求当这个servlet停止服务时，destroy()方法会被调用并准备销毁Servlet的启动时间由web.xml中load-on-startup属性决定，当值为负数或未设定该属性时，容器可以自由决定何时初始化该servlet；当值为零或正整数时，容器需要在启动时就初始化该servlet，此时该属性的值代表初始化的优先级，值越小优先级越高，对于有相同优先级的servlet，容器可以自行决定加载顺序。当应用被重新部署，或者在容器停机时，servlet会被销毁，同时servet无法被手动销毁。除了生命周期方法外，Servlet接口还有两个方法：getServletConfig()可以让servlet取到启动相关的信息getServletInfo()用来获取servlet相关的信息，如作者、版本号、版权信息等javax.servlet.GenericServletGenericServlet类是一个抽象类，定义了一个协议无关的，通用的servlet实现。它预置了ServletConfig接口的实现，并且简易实现了Servlet接口中的init()方法和destroy()方法，开发人员只需要覆盖service()方法。javax.servlet.http.HttpServletHttpServlet类提供了一个用于处理HTTP请求的servlet基类。一个HttpServlet的子类至少需要覆盖一个方法，而且通常是覆盖如下几个方法：doGet()，以实现对HTTP GET请求的处理doPost()，以实现对HTTP POST请求的处理doPut()，以实现对HTTP PUT请求的处理doDelete()，以实现对HTTP DELETE请求的处理init()和destroy()，以管理servlet生命周期内所需的资源getServletInfo()，可以用来自定义servlet返回哪些关于自身的信息此外，不建议直接覆盖service()方法，因为HttpServlet#service()方法中已经实现了根据HTTP请求类型调用对应的doXXX()方法。如果某个HTTP方法对应的doXXX()方法没有被覆盖，则视为该servlet不支持这个HTTP方法。如在没有覆盖doGet()时收到HTTP GET请求，则会返回HTTP 405 METHOD NOT ALLOWED (对应HTTP 1.1)错误码，或HTTP 400 BAD REQUEST (对应其他HTTP版本)错误码。需要注意的是，HttpServlet类并没有实现HTTP CONNECT和HTTP PATCH方法。当请求这两个方法，或其他非标准方法时，将会返回HTTP 501 NOT IMPLEMENTED错误码。常用的常量HTTP方法相关的常量位于HttpServlet类中，是String类型，命名规则为METHOD_方法，如METHOD_GETHTTP状态码相关的常量位于HttpServletResponse类中，是int类型，命名规则为SC_状态码名，如SC_OK、SC_NOT_FOUND系列博文循序渐进写一个Servlet(1) - 介绍相关的接口和类循序渐进写一个Servlet(2) - 第一个servlet循序渐进写一个Servlet(3) - 分别处理GET和POST循序渐进写一个Servlet(4) - 会话追踪循序渐进写一个Servlet(5) - Filter]]></content>
      <categories>
        <category>学习记录</category>
        <category>Java</category>
        <category>Servlet</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Servlet</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java线程池]]></title>
    <url>%2Fprojects%2Fjava%2Ffundamentals%2Fjava-multi-threading-thread-pool.html</url>
    <content type="text"><![CDATA[就像数据库连接可以使用连接池管理一样，Java中的线程也可以使用线程池来管理。本文介绍在Java中如何使用线程池，以及有哪些线程池。为什么需要线程池每个线程的创建和销毁，都会消耗一定的系统资源，尤其在高并发的系统中，频繁创建和销毁线程会造成大量的资源浪费。那么，为了避免频繁的创建和销毁线程，就可以在系统启动时，预先创建好一定数量的线程，并将其交由线程调度器管理，这就是线程池。怎么使用线程池依旧是用一个示例来演示。123456789101112131415161718192021222324252627public class MyRunnable implements Runnable &#123; private int ticketCount = 20; @Override public void run() &#123; System.out.println(Thread.currentThread().getName() + " started."); while (ticketCount &gt; 0) &#123; try &#123; Thread.sleep(500); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; synchronized (this) &#123; if (ticketCount &gt; 0) &#123; System.out.println(Thread.currentThread().getName() + " has " + ticketCount-- + " tickets"); &#125; else &#123; break; &#125; &#125; &#125; System.out.println(Thread.currentThread().getName() + " stopped."); &#125;&#125;12345678910111213141516171819202122232425public class Main &#123; public static void main(String[] args) &#123; // 创建一个线程池 ExecutorService executorService = Executors.newCachedThreadPool(); System.out.println("Thread pool created"); MyRunnable myRunnable = new MyRunnable(); System.out.println("Assigning jobs to thread pool"); // 向线程池提交任务 executorService.execute(myRunnable); executorService.execute(myRunnable); // 在所有线程都完成工作后，线程池会继续等待新的工作任务 // 所以如果需要程序在完成后退出，需要显式关闭线程池 executorService.shutdown(); while (!executorService.isTerminated()) &#123; &#125; System.out.println("Thread pool is down"); &#125;&#125;运行后得到如下结果：123456789101112131415161718192021222324252627Thread pool createdAssigning jobs to thread poolpool-1-thread-2 started.pool-1-thread-1 started.pool-1-thread-1 has 20 ticketspool-1-thread-2 has 19 ticketspool-1-thread-1 has 18 ticketspool-1-thread-2 has 17 ticketspool-1-thread-1 has 16 ticketspool-1-thread-2 has 15 ticketspool-1-thread-1 has 14 ticketspool-1-thread-2 has 13 ticketspool-1-thread-2 has 12 ticketspool-1-thread-1 has 11 ticketspool-1-thread-1 has 10 ticketspool-1-thread-2 has 9 ticketspool-1-thread-1 has 8 ticketspool-1-thread-2 has 7 ticketspool-1-thread-2 has 6 ticketspool-1-thread-1 has 5 ticketspool-1-thread-2 has 4 ticketspool-1-thread-1 has 3 ticketspool-1-thread-2 has 2 ticketspool-1-thread-1 has 1 ticketspool-1-thread-1 stopped.pool-1-thread-2 stopped.Thread pool is down几种线程池的简介固定线程池(Fixed thread pool)使用Executors.newFixedThreadPool(int nThreads)创建。该线程池维护着固定数量的线程(nThreads个)，在任何时间只允许最多nThreads个线程执行任务，多出来的任务将会在队列中等待，直到有空闲的线程出现。如果其中一个线程在执行过程中因为错误而异常退出，则线程池会立刻创建一个新的线程并执行后续的任务。该线程池在显式关闭(ExecutorService#shutdown)前将一直存在。工作窃取线程池(Work stealing pool)使用Executors.newWorkStealingPool(int parallelism)或Executors.newWorkStealingPool()创建。该线程池无法保证各个被提交的任务将会以何种顺序执行。newWorkStealingPool(int parallelism)该方法将根据给定的“并行量(parallelism)”，来创建一个包含足够数量线程的线程池，并会使用多个队列来减少线程与队列的争抢。“并行量”的值对应于最多允许参与执行任务的线程数量。但实际存在的线程数可能会动态的增减。Executors.newWorkStealingPool()将所有的“可用的处理器”的数目作为“并行量”来创建线程池。可用的处理器数量使用Runtime.getRuntime().availableProcessors()获取，其值等同于CPU中逻辑处理器的数量。有缓存的线程池(Cached thread pool)使用Executors.newCachedThreadPool()创建。当接收到新的任务后，线程池会根据有无可用线程，来决定使用线程池中的空闲线程，或者在线程池中创建新的线程。如果线程池中有线程空置超过60秒，则该线程就会被终止并从线程池中移除。可计划的线程池(Scheduled thread pool)使用Executors.newScheduledThreadPool(int corePoolSize)创建。corePoolSize为线程池中保持的线程数。该线程池可以指定一个延迟，或指定一个周期，并按照这个计划执行任务。参考文章Thread pools and work queues]]></content>
      <categories>
        <category>学习记录</category>
        <category>Java</category>
        <category>基础知识</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>多线程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java多线程概念]]></title>
    <url>%2Fprojects%2Fjava%2Ffundamentals%2Fjava-multi-threading-concepts.html</url>
    <content type="text"><![CDATA[本文记录一些Java多线程相关的概念性的知识。线程的状态新建(New)线程已被创建，但是尚未启动可运行(Runnable)此线程在JVM中正在运行阻塞(Blocked)此线程正在等待获取一个监视锁(monitor lock)，需要其他线程显式唤醒等待(Waiting)此线程正在无限期等待另一个线程完成某些工作进入方法退出方法Object#wait()Object#notify()或Object#notifyAll()Thread#join()被调用的线程执行完毕限期等待(Timed waiting)此线程正在有限期等待另一个线程完成某些工作进入方法退出方法Thread.sleep()设定的休眠时间结束Object#wait(long timeout)时间结束 / Object#notify() / Object#notifyAll()Thread#join(long millis)时间结束 / 被调用的线程执行完毕终止(Terminated)线程结束使用线程见Java 如何创建和运行多线程互斥同步synchronized同步一个代码块只作用于同一个对象，如多个Thread使用同一个Runnable时。一个线程若要使用此方法，则必须获得obj对象的锁。12345public void something() &#123; synchronized (obj) &#123; // do something &#125;&#125;同步一个方法12345// 只作用于同一个对象。// 一个线程若要使用此方法，则必须获得该方法所在对象的锁public void synchronized something() &#123; // do something&#125;12345// 作用于整个类// 一个线程若要使用此方法，则必须获得该方法所在类的锁public void static synchronized aStaticMethod() &#123; // do something&#125;同步一个类作用于整个类，即使两个线程使用同一个类的不同对象，也会进行同步。一个线程若要使用此方法，则必须获得该类的锁。12345public void something() &#123; synchronized (SynchronizationExample.class) &#123; // do something &#125;&#125;ReentrantLockReentrantLock是java.util.concurrent包中的锁123456789101112131415public class LockDemo implements Runnable &#123; private Lock lock = new ReentrantLock(); @Override public void run() &#123; try &#123; lock.lock(); for (int i = 0; i &lt; 10; i++) &#123; System.out.println(i + " "); &#125; &#125; finally &#123; lock.unlock(); &#125; &#125;&#125;123456789101112public class Main &#123; public static void main(String[] args) &#123; LockDemo lockDemo = new LockDemo(); ExecutorService executorService = Executors.newCachedThreadPool(); executorService.execute(lockDemo); executorService.execute(lockDemo); &#125;&#125;线程协作Thread#join()在A线程中调用B线程的join()方法，会将当前线程挂起，直到目标线程结束。12345678910111213141516171819202122232425public class MyRunnable implements Runnable &#123; private AtomicInteger ticketCount = new AtomicInteger(5); @Override public void run() &#123; System.out.println(Thread.currentThread().getName() + " started."); while (true) &#123; try &#123; Thread.sleep(500); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; if (ticketCount.get() &gt; 0) &#123; System.out.println(Thread.currentThread().getName() + " has " + ticketCount.getAndDecrement() + " tickets"); &#125; else &#123; break; &#125; &#125; System.out.println(Thread.currentThread().getName() + " stopped."); &#125;&#125;12345678910111213141516public class Main &#123; public static void main(String[] args) throws InterruptedException &#123; Thread t1 = new Thread(new MyRunnable()); Thread t2 = new Thread(new MyRunnable()); Thread t3 = new Thread(new MyRunnable()); t1.start(); // 主线程等待 t1 执行完毕 t1.join(); t2.start(); t3.start(); &#125;&#125;执行结果如下：123456789101112131415161718192021Thread-0 started.Thread-0 has 5 ticketsThread-0 has 4 ticketsThread-0 has 3 ticketsThread-0 has 2 ticketsThread-0 has 1 ticketsThread-0 stopped.Thread-1 started.Thread-2 started.Thread-1 has 5 ticketsThread-2 has 5 ticketsThread-2 has 4 ticketsThread-1 has 4 ticketsThread-2 has 3 ticketsThread-1 has 3 ticketsThread-2 has 2 ticketsThread-1 has 2 ticketsThread-1 has 1 ticketsThread-2 has 1 ticketsThread-1 stopped.Thread-2 stopped.wait()，notify()，和notifyAll()wait()将当前线程变为等待状态，notify()和notifyAll()将等待状态的线程唤醒。wait()方法必须在有锁(即synchronized)的代码块中执行。当有多个线程处于等待状态时，notify()会任意选择一个线程来唤醒，选择的方式由JVM的实现来决定；而notifyAll()则会唤醒所有等待中的线程。因为线程唤醒后，程序将会从wait()的下一条语句中开始执行，所以wait()方法应当总在while循环中调用，通过循环条件控制线程是否继续等待。123456789101112131415public class WaitNotifyDemo &#123; public synchronized void before() &#123; System.out.println("before"); notifyAll(); &#125; public synchronized void after() &#123; try &#123; wait(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println("after"); &#125;&#125;12345678910111213public class Main &#123; public static void main(String[] args) throws InterruptedException &#123; ExecutorService executorService = Executors.newCachedThreadPool(); WaitNotifyDemo waitNotifyDemo = new WaitNotifyDemo(); // 调用after()后，遇到wait()进入等待状态 executorService.execute(waitNotifyDemo::after); // 调用before()后，遇到`notifyAll()`，唤醒所有线程 executorService.execute(waitNotifyDemo::before); &#125;&#125;执行结果：12beforeafter]]></content>
      <categories>
        <category>学习记录</category>
        <category>Java</category>
        <category>基础知识</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>多线程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[为webapp设定单独的context.xml]]></title>
    <url>%2Ftools%2Ftomcat%2Fcustomize-context-xml-for-individual-webapp.html</url>
    <content type="text"><![CDATA[要给某个webapp设定单独的context.xml，只需要在${WEBAPP_ROOT}/webapp目录下新建一个META-INF目录，并将context.xml放进去，就可以了。]]></content>
      <categories>
        <category>工具</category>
        <category>Tomcat</category>
      </categories>
      <tags>
        <tag>Tomcat</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[配置Tomcat监控class和lib变更并自动重新加载]]></title>
    <url>%2Ftools%2Ftomcat%2Ftomcat-monitor-classes-and-auto-reload.html</url>
    <content type="text"><![CDATA[在context.xml的Context标签中，设定reloadable=&quot;true&quot;即可。123&lt;Context reloadable="true"&gt; &lt;!-- Other configurations --&gt;&lt;/Context&gt;配置完毕后重启Tomcat使配置生效，然后Tomcat在监控到项目的class或lib有变化后，就会自动重新加载这个webapp。但是这个功能会显著增加Tomcat的性能消耗，故不建议在生产环境中使用。]]></content>
      <categories>
        <category>工具</category>
        <category>Tomcat</category>
      </categories>
      <tags>
        <tag>Tomcat</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java如何创建和运行多线程]]></title>
    <url>%2Fprojects%2Fjava%2Ffundamentals%2Fjava-multi-threading-how-to.html</url>
    <content type="text"><![CDATA[本文通过一个简单的示例，介绍一下在Java中如何创建和运行多线程，以及我在学习过程中遇到的问题。包括：如何实现多线程如何在线程间共享资源共享资源时可能出现的问题多线程的实现方法多线程有三种实现方式：继承Thread类，并实现其run()方法；实现Runnable接口，并实现其run()方法；和实现Callable接口，并实现其run()方法。通常来说，我们会通过实现Runnable接口来实现多线程，因为继承Thread类可能会有多继承的问题，而实现接口则没有这方面的影响。下面示例会创建一个MyThread的类来实现，然后在main()中运行。继承Thread类12345678910111213141516public class MyThread extends Thread &#123; private int ticketCount = 5; private String threadName; public MyThread(String threadName) &#123; this.threadName = threadName; &#125; @Override public void run() &#123; while (ticketCount &gt; 0) &#123; System.out.println(threadName + " has " + ticketCount-- + " tickets"); &#125; &#125;&#125;12345678public class Main &#123; public static void main(String[] args) &#123; new MyThread("thread1").start(); new MyThread("thread2").start(); new MyThread("thread3").start(); &#125;&#125;实现Runnable接口12345678910111213141516public class MyThread implements Runnable &#123; private int ticketCount = 5; private String threadName; public MyThread(String threadName) &#123; this.threadName = threadName; &#125; @Override public void run() &#123; while (ticketCount &gt; 0) &#123; System.out.println(threadName + " has " + ticketCount-- + " tickets"); &#125; &#125;&#125;123456789public class Main &#123; public static void main(String[] args) &#123; new Thread(new MyThread("thread1")).start(); new Thread(new MyThread("thread2")).start(); new Thread(new MyThread("thread3")).start(); &#125;&#125;实现Callable接口TODO: 这东西看起来好像有点复杂，在这里先占个坑，改日单开一篇记录学习过程执行start()方法与执行run()方法的区别实际上，唯一合法的运行多线程的方式，是调用start()方法，但是为什么不能调用run()方法呢？因为start()方法会开辟一个新的线程，并且在新的线程中调用目标的run()方法。但是直接调用run()则不会创建新的线程，而是像调用其他任何一个方法那样，他将会在当前线程中执行。这么说可能有些生涩，那么还是通过上面的例子来帮助理解。在调用了start()方法后，程序的输出是这样子的，注意观察每行输出是由哪个线程写出来的：123456789101112131415thread1 has 5 ticketsthread3 has 5 ticketsthread2 has 5 ticketsthread3 has 4 ticketsthread1 has 4 ticketsthread3 has 3 ticketsthread2 has 4 ticketsthread3 has 2 ticketsthread1 has 3 ticketsthread3 has 1 ticketsthread2 has 3 ticketsthread1 has 2 ticketsthread2 has 2 ticketsthread1 has 1 ticketsthread2 has 1 tickets可见输出是乱序的。然而调用run()方法之后，输出变成了这样：123456789101112131415thread1 has 5 ticketsthread1 has 4 ticketsthread1 has 3 ticketsthread1 has 2 ticketsthread1 has 1 ticketsthread2 has 5 ticketsthread2 has 4 ticketsthread2 has 3 ticketsthread2 has 2 ticketsthread2 has 1 ticketsthread3 has 5 ticketsthread3 has 4 ticketsthread3 has 3 ticketsthread3 has 2 ticketsthread3 has 1 tickets看起来像是三个线程按照创建的顺序依次执行，但实际上只是先后调用了它们三个的run()方法而已，并没有新的线程被创建出来。多线程共享资源上文中卖票这个例子，都是开了三个线程，各卖各的票，但是实际上它们应该是从同一组票池中卖票。接下来，就把例子修改一下，让这三个线程共享资源。1234567891011121314151617public class MyThread implements Runnable &#123; private int ticketCount = 20; private String threadName; public MyThread(String threadName) &#123; this.threadName = threadName; &#125; @Override public void run() &#123; while (ticketCount &gt; 0) &#123; // Thread.currentThread().getName() 打印出正在执行的线程的名字 System.out.println(Thread.currentThread().getName() + " has " + ticketCount-- + " tickets"); &#125; &#125;&#125;123456789101112131415public class Main &#123; public static void main(String[] args) &#123; MyThread myThread = new MyThread("MyThread"); Thread t1 = new Thread(myThread); Thread t2 = new Thread(myThread); Thread t3 = new Thread(myThread); t1.start(); t2.start(); t3.start(); &#125;&#125;为什么用Runnable而不用ThreadThread(Runnable target)的JavaDoc中，target参数的描述是这么写的：the object whose run method is invoked when this thread is started以及Thread#run()是这样写的：12345public void run() &#123; if (target != null) &#123; target.run(); &#125;&#125;同时run()的JavaDoc有如下描述：If this thread was constructed using a separate Runnable run object, then that Runnable object’s run method is called.说明，在将一个Runnable对象赋给一个或多个Thread后，这些Thread调用的都是这一个Runnable对象的run()方法，所操作的数据也是这一个Runnable对象里面的数据。依旧用例子说话。在上一节的代码的t1.start()这一行打个断点，看看这三个线程的信息。根据上面的JavaDoc，这里特别关注线程的target属性。可见，这三个Thread都使用了MyThread@534这个对象。也就是说，这三个线程都调用了MyThread@534的run()方法，并且在操作MyThread@534这个对象的成员变量。然后，换成继承Thread的形式：123456789101112131415public class MyThread extends Thread &#123; private int ticketCount = 20; private String threadName; public MyThread(String threadName) &#123; this.threadName = threadName; &#125; @Override public void run() &#123; while (ticketCount &gt; 0) &#123; System.out.println(Thread.currentThread().getName() + " has " + ticketCount-- + " tickets"); &#125; &#125;&#125;123456789101112public class Main &#123; public static void main(String[] args) &#123; MyThread t1 = new MyThread("MyThread1"); MyThread t2 = new MyThread("MyThread2"); MyThread t3 = new MyThread("MyThread3"); t1.start(); t2.start(); t3.start(); &#125;&#125;同样，在t1.start()上打断点，得到结果如下：可以发现，这三个Thread不止没有target，甚至它们的成员变量都是各自有一份，何谈线程之间共享。多线程的同步问题将多线程共享资源这一节的代码执行，得到了这样的输出：123456789101112131415161718192021Thread-0 has 20 ticketsThread-2 has 19 ticketsThread-1 has 19 ticketsThread-2 has 17 ticketsThread-0 has 18 ticketsThread-2 has 15 ticketsThread-1 has 16 ticketsThread-2 has 13 ticketsThread-0 has 14 ticketsThread-2 has 11 ticketsThread-1 has 12 ticketsThread-0 has 10 ticketsThread-2 has 9 ticketsThread-0 has 7 ticketsThread-1 has 8 ticketsThread-0 has 5 ticketsThread-2 has 6 ticketsThread-0 has 3 ticketsThread-1 has 4 ticketsThread-0 has 1 ticketsThread-2 has 2 tickets鞥？第二行和第三行好像不太对劲？线程1和线程2把同一张票重复卖了两次？果然出现了线程的同步问题了。发生这个问题的原因是，Java中的自增、自减不是线程安全的。一个自增自减操作，实际上包含了三步：获取变量当前的值为该值加1或减1写回新值那么要解决这个问题，就需要加锁，来保证“读-算-写”这个操作具有原子性，或者使用AtomicInteger类提供的原子操作。使用synchronized关键字加锁尝试使用synchronized关键字给run()方法加锁，代码修改如下：12345678910111213141516171819202122232425public class MyRunnable implements Runnable &#123; private int ticketCount = 20; @Override public synchronized void run() &#123; System.out.println(Thread.currentThread().getName() + " started."); while (true) &#123; try &#123; Thread.sleep(500); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; if (ticketCount &gt; 0) &#123; System.out.println(Thread.currentThread().getName() + " has " + ticketCount-- + " tickets"); &#125; else &#123; break; &#125; &#125; System.out.println(Thread.currentThread().getName() + " stopped."); &#125;&#125;运行后得到如下结果：1234567891011121314151617181920212223242526Thread-0 started.Thread-0 has 20 ticketsThread-0 has 19 ticketsThread-0 has 18 ticketsThread-0 has 17 ticketsThread-0 has 16 ticketsThread-0 has 15 ticketsThread-0 has 14 ticketsThread-0 has 13 ticketsThread-0 has 12 ticketsThread-0 has 11 ticketsThread-0 has 10 ticketsThread-0 has 9 ticketsThread-0 has 8 ticketsThread-0 has 7 ticketsThread-0 has 6 ticketsThread-0 has 5 ticketsThread-0 has 4 ticketsThread-0 has 3 ticketsThread-0 has 2 ticketsThread-0 has 1 ticketsThread-0 stopped.Thread-2 started.Thread-2 stopped.Thread-1 started.Thread-1 stopped.可见run()方法被Thread-0上锁，被上锁的方法在释放锁前只能被一个线程所访问，Thread-1和Thread-2都在Thread-0执行结束并释放锁后才开始运行，并且也都进行了一次对run()的上锁-释放过程。如果只对ticketCount--操作上锁呢？12345678910111213141516171819202122232425262728public class MyRunnable implements Runnable &#123; private int ticketCount = 20; @Override public void run() &#123; System.out.println(Thread.currentThread().getName() + " started."); while (true) &#123; try &#123; Thread.sleep(500); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; // 拿到了这里，而不是对run方法上锁 synchronized (this) &#123; if (ticketCount &gt; 0) &#123; System.out.println(Thread.currentThread().getName() + " has " + ticketCount-- + " tickets"); &#125; else &#123; break; &#125; &#125; &#125; System.out.println(Thread.currentThread().getName() + " stopped."); &#125;&#125;执行之后得到了这样的结果：1234567891011121314151617181920212223242526Thread-0 started.Thread-2 started.Thread-1 started.Thread-0 has 20 ticketsThread-2 has 19 ticketsThread-1 has 18 ticketsThread-0 has 17 ticketsThread-1 has 16 ticketsThread-2 has 15 ticketsThread-0 has 14 ticketsThread-1 has 13 ticketsThread-2 has 12 ticketsThread-1 has 11 ticketsThread-0 has 10 ticketsThread-2 has 9 ticketsThread-1 has 8 ticketsThread-0 has 7 ticketsThread-2 has 6 ticketsThread-2 has 5 ticketsThread-0 has 4 ticketsThread-1 has 3 ticketsThread-2 has 2 ticketsThread-1 has 1 ticketsThread-0 stopped.Thread-2 stopped.Thread-1 stopped.三个线程在结束休眠后开始竞争锁，得到锁的线程操作了ticketCount，然后释放了锁。原子操作这次尝试将ticketCount换成AtomicInteger类型，并且使用AtomicInteger#getAndDecrement()方法进行原子的自减计算，修改后的代码如下：12345678910111213141516171819202122232425public class MyRunnable implements Runnable &#123; private AtomicInteger ticketCount = new AtomicInteger(20); @Override public void run() &#123; System.out.println(Thread.currentThread().getName() + " started."); while (true) &#123; try &#123; Thread.sleep(500); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; if (ticketCount.get() &gt; 0) &#123; System.out.println(Thread.currentThread().getName() + " has " + ticketCount.getAndDecrement() + " tickets"); &#125; else &#123; break; &#125; &#125; System.out.println(Thread.currentThread().getName() + " stopped."); &#125;&#125;main()方法内容依旧不变，运行之后出现了这样的结果：1234567891011121314151617181920212223242526Thread-1 started.Thread-2 started.Thread-0 started.Thread-1 has 19 ticketsThread-0 has 18 ticketsThread-2 has 20 ticketsThread-1 has 17 ticketsThread-0 has 16 ticketsThread-2 has 15 ticketsThread-1 has 13 ticketsThread-2 has 12 ticketsThread-0 has 14 ticketsThread-0 has 11 ticketsThread-2 has 10 ticketsThread-1 has 9 ticketsThread-1 has 8 ticketsThread-0 has 6 ticketsThread-2 has 7 ticketsThread-2 has 4 ticketsThread-0 has 3 ticketsThread-1 has 5 ticketsThread-2 has 2 ticketsThread-0 has 1 ticketsThread-1 stopped.Thread-2 stopped.Thread-0 stopped.虽然没有了脏读，但是线程的执行顺序也无法保证，如果要求线程定序执行，这样就不行了。]]></content>
      <categories>
        <category>学习记录</category>
        <category>Java</category>
        <category>基础知识</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>多线程</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[JDBC的事务和隔离级别]]></title>
    <url>%2Fdatabase%2Fjdbc-transaction-and-isolation-level.html</url>
    <content type="text"><![CDATA[这里简单写一下我对JDBC的事务和隔离级别的理解。名词解释事务数据库事务是DBMS执行过程中的一个逻辑单位，由一个有限的数据库操作序列构成。一个事务一定是具有原子性(atomic)、一致性(consistency)、隔离性(isolation)、持久性(durability)，即ACID。一个事务会包含一个或多个数据操作语句(data-manipulation statements)和查询语句。通常来说，事务会依照如下的流程执行：开始一个事务执行一系列操作或查询语句如果没有发生错误，则提交这个事务，并将其结束如果发生了错误，则回滚这个事务，并将其结束。ACIDAtomic原子性，即一个事务内的所有操作都被作为一个整体看待，要么全部成功，要么全部失败Consistency一致性，即事务中有操作失败时，这个事务所更改的数据都必须回滚至操作前的状态。Isolation隔离性，即事务所查看到的数据，要么是一个事务提交前的状态，要么是一个事务提交后的状态，而不可能是事务在执行中的状态。Durability持久性，即事务对系统的影响是永久的。读现象脏读当一个事务允许读取另一个事务修改但尚未提交的数据时，就有可能发生脏读。不可重复读在一次事务中，对一行数据的两次读取获得了不同的结果。该现象发生于在执行SELECT时没有获得读锁，或者在读取完毕后立刻释放了读锁。幻读在事务执行过程中，两个完全一样的查询得到了不同的结果集，即是幻读。它是不可重复读的一个特殊场景。当事务1在执行两次SELECT ... WHERE操作中间，事务2在这个表中生成了一行新数据，而这条新数据正好满足事务1的WHERE条件，导致事务1的两次查询得到了不同的结果集。隔离级别NONENONE是一个特殊的级别，代表JDBC驱动不支持事务。未提交读(READ UNCOMMITED)这个是最低的隔离级别。这个隔离级别允许事务读取到其他事务尚未提交(commit)的数据，即允许脏读。提交读(READ COMMITED)这个隔离级别中，DBMS需要选定对象的写锁一直保持到事务结束，但是读锁会在SELECT操作完成后马上释放，所以有可能会发生“不可重复读”。可重复读(REPEATABLE READ)在这个隔离级别下，DBMS需要对选定对象的读锁和写锁一直保持到事务结束，但是不要求范围锁，所以有可能发生幻读。可串行化(SERIALIZABLE)这是最高的隔离级别。在这个隔离级别下，要求DBMS在选定对象上的读锁和写锁一直保持到事务结束，如果使用了WHERE来描述范围时，则应当获取一个范围锁。这个隔离级别可以防止幻读。隔离级别与读现象隔离级别脏读不可重复读幻读未提交读可能发生可能发生可能发生提交读不会发生可能发生可能发生可重复读不会发生不会发生可能发生可串行化不会发生不会发生不会发生隔离级别与锁持续时间隔离级别写操作读操作范围操作未提交读当前语句执行完毕当前语句执行完毕当前语句执行完毕提交读当前事务提交当前语句执行完毕当前语句执行完毕可重复读当前事务提交当前事务提交当前语句执行完毕可串行化当前事务提交当前事务提交当前事务提交]]></content>
      <categories>
        <category>数据库</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>JDBC</tag>
        <tag>Transaction</tag>
        <tag>Isolation level</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Shell脚本中 set -ex 命令的作用]]></title>
    <url>%2Flinux%2Fshell-set-ex.html</url>
    <content type="text"><![CDATA[刚刚学会了一个很实用的shell命令set -ex，在这里分享一下。稍有常识的人都能看出，这是set命令加上了-e和-x两个参数(废话么这不是)。那么，我就把这两个参数拆开，分别说一下它在脚本中的用处。set -e先说说set -e，这个参数的含义是，当命令发生错误的时候，停止脚本的执行。通常来说，我们会习惯于使用&amp;&amp;来实现这样的功能，比如：123#!/bin/bashecho 1 &amp;&amp; rm non-existent-file &amp;&amp; echo 2但是，写成一行呢，可读性有点差，分成多行的话，也得注意换行符\和&amp;&amp;号，我就有过好几次忘了加这俩东西，还是挺麻烦的是吧。更麻烦的是，&amp;&amp;连接的命令之间不能写注释，也就是说，下面这个示例是不能用的：12345#!/bin/bashecho 1 \ &amp;&amp; rm non-existent-file \ # which will fail &amp;&amp; echo 2运行之后会是这个德行：123456781rm: non-existent-file: No such file or directoryrm: #: No such file or directoryrm: which: No such file or directoryrm: will: No such file or directoryrm: fail: No such file or directory./test1.sh: line 5: syntax error near unexpected token `&amp;&amp;&apos;./test1.sh: line 5: ` &amp;&amp; echo 2&apos;现在，就可以写成下面这样了：123456#!/bin/bashset -eecho 1rm non-existent-file # which will failecho 2猜猜最后输出里面会不会把2打印出来？set -x说完了-e，继续说说-x。-x参数的作用，是把将要运行的命令用一个+标记之后显示出来。还是拿上面这个脚本举个例子，这次加上-x：123456#!/bin/bashset -execho 1rm non-existent-file # which will failecho 2然后它的输出就变成了：1234+ echo 11+ rm non-existent-filerm: non-existent-file: No such file or directory注意第一行和第三行前面那个+，这就是-x参数的作用。One more thing……需要注意，这条命令需要放到整个shell脚本的开头，才会起作用。毕竟用脑子想想就知道，这是俩开关，不论放在中间还是结尾，都不会起到预期的作用。Credit感谢这篇文章set -ex - The most useful bash trick of the year为我提供了这条命令的解释，和写作的思路。]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Shell</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[搭建Spring MVC + MyBatis项目笔记(一) 框架搭建]]></title>
    <url>%2Fprojects%2Fjava%2Fbuilding-ssm-project-1-env-prep.html</url>
    <content type="text"><![CDATA[最近开始着手做一个基于Spring MVC和MyBatis的项目，把搭建过程记录于此备忘项目架构简介目前暂定本项目使用Spring MVC+MyBatis框架，数据库使用MySQL编排项目目录项目目录按照标准的webapp目录编排12345678910111213141516171819src|-main |-java &lt;-- 源码 |-resources &lt;-- 配置文件等资源 |-mapper &lt;-- MyBatis mapper |-log4j2.xml |-mybatis-config.xml |-spring-aop.xml |-spring-dao.xml |-spring-service.xml |-spring-web.xml |-webapp &lt;-- 本项目仅提供RESTful接口，不提供页面 |-WEB-INF |-web.xml |-index.jsp|-test |-java &lt;-- 测试源码 |-resources &lt;-- 测试用的资源 |-sql &lt;-- 单元测试准备测试数据使用的SQL编写POM123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123&lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;maven.compiler.source&gt;1.8&lt;/maven.compiler.source&gt; &lt;maven.compiler.target&gt;1.8&lt;/maven.compiler.target&gt; &lt;!-- Version of dependencies --&gt; &lt;junit.version&gt;4.12&lt;/junit.version&gt; &lt;h2.version&gt;1.4.197&lt;/h2.version&gt; &lt;spring.version&gt;5.0.8.RELEASE&lt;/spring.version&gt; &lt;mybatis.version&gt;3.4.6&lt;/mybatis.version&gt; &lt;mybatis-spring.version&gt;1.3.2&lt;/mybatis-spring.version&gt; &lt;mysql-connector.version&gt;8.0.12&lt;/mysql-connector.version&gt; &lt;log4j.version&gt;2.11.1&lt;/log4j.version&gt; &lt;hikaricp.version&gt;3.2.0&lt;/hikaricp.version&gt; &lt;fastjson.version&gt;1.2.49&lt;/fastjson.version&gt; &lt;lombok.version&gt;1.18.2&lt;/lombok.version&gt; &lt;aspectj.version&gt;1.9.1&lt;/aspectj.version&gt;&lt;/properties&gt;&lt;dependencies&gt; &lt;!-- JUnit --&gt; &lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;$&#123;junit.version&#125;&lt;/version&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;!-- H2 Database --&gt; &lt;dependency&gt; &lt;groupId&gt;com.h2database&lt;/groupId&gt; &lt;artifactId&gt;h2&lt;/artifactId&gt; &lt;version&gt;$&#123;h2.version&#125;&lt;/version&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;!-- Spring MVC --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-webmvc&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;!-- Spring JDBC --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-jdbc&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;!-- Spring unit test --&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-test&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt; &lt;scope&gt;test&lt;/scope&gt; &lt;/dependency&gt; &lt;!-- MySQL Connector/J --&gt; &lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;$&#123;mysql-connector.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;!-- MyBatis --&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis&lt;/groupId&gt; &lt;artifactId&gt;mybatis&lt;/artifactId&gt; &lt;version&gt;$&#123;mybatis.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;!-- MyBatis Spring integration --&gt; &lt;dependency&gt; &lt;groupId&gt;org.mybatis&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring&lt;/artifactId&gt; &lt;version&gt;$&#123;mybatis-spring.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;!-- Hikari connection pool --&gt; &lt;dependency&gt; &lt;groupId&gt;com.zaxxer&lt;/groupId&gt; &lt;artifactId&gt;HikariCP&lt;/artifactId&gt; &lt;version&gt;$&#123;hikaricp.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;!-- Fastjson --&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;fastjson&lt;/artifactId&gt; &lt;version&gt;$&#123;fastjson.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;!-- Logging --&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.logging.log4j&lt;/groupId&gt; &lt;artifactId&gt;log4j-slf4j-impl&lt;/artifactId&gt; &lt;version&gt;$&#123;log4j.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;!-- Lombok --&gt; &lt;dependency&gt; &lt;groupId&gt;org.projectlombok&lt;/groupId&gt; &lt;artifactId&gt;lombok&lt;/artifactId&gt; &lt;version&gt;$&#123;lombok.version&#125;&lt;/version&gt; &lt;scope&gt;provided&lt;/scope&gt; &lt;/dependency&gt; &lt;!-- AspectJ --&gt; &lt;dependency&gt; &lt;groupId&gt;org.aspectj&lt;/groupId&gt; &lt;artifactId&gt;aspectjrt&lt;/artifactId&gt; &lt;version&gt;$&#123;aspectj.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.aspectj&lt;/groupId&gt; &lt;artifactId&gt;aspectjweaver&lt;/artifactId&gt; &lt;version&gt;$&#123;aspectj.version&#125;&lt;/version&gt; &lt;/dependency&gt;&lt;/dependencies&gt;编写MyBatis配置文件可以参考MyBatis配置文档的Settings部分1234567891011121314151617&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;!DOCTYPE configuration PUBLIC "-//mybatis.org//DTD Config 3.0//EN" "http://mybatis.org/dtd/mybatis-3-config.dtd"&gt;&lt;configuration&gt; &lt;settings&gt; &lt;!-- Globally enables or disables any caches configured in any mapper under this configuration --&gt; &lt;setting name="cacheEnabled" value="false"/&gt; &lt;!-- 设定驱动程序等待数据库返回数据的时间，单位为秒 --&gt; &lt;setting name="defaultStatementTimeout" value="5"/&gt; &lt;!-- 启用该项后，MyBatis 将会自动完成"大写下划线分割命名"与"驼峰式命名"的互相转换 --&gt; &lt;setting name="mapUnderscoreToCamelCase" value="true"/&gt; &lt;!-- 允许JDBC使用自动生成的 Key --&gt; &lt;setting name="useGeneratedKeys" value="true"/&gt; &lt;/settings&gt; &lt;!-- Continue editing here --&gt;&lt;/configuration&gt;编写Spring配置文件Spring配置文件我将根据其用途，分为数据源配置、service配置、web配置、切面配置四部分数据源配置1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:context="http://www.springframework.org/schema/context" xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd"&gt; &lt;context:component-scan base-package="com.boris1993.tiebacheckin.model"/&gt; &lt;!-- 这部分配置数据库链接信息 我在这里使用了一个名为“光(Hikari)”的数据库连接池 GitHub repo在：https://github.com/brettwooldridge/HikariCP --&gt; &lt;bean id="dataSource" class="com.zaxxer.hikari.HikariDataSource"&gt; &lt;property name="jdbcUrl" value="jdbc:mysql://localhost:3306/cloudcheckin?useSSL=false"/&gt; &lt;property name="username" value="tieba"/&gt; &lt;property name="password" value="tieba"/&gt; &lt;/bean&gt; &lt;!-- MyBatis-Spring 需要至少定义两样东西：sqlSessionFactory 和至少一个 mapper 接口 文档地址：http://www.mybatis.org/spring/getting-started.html --&gt; &lt;!-- 配置 sqlSessionFactory bean 因为这里使用的是 Mybatis-Spring，所以 class 指定为 SqlSessionFactoryBean 而不是 SqlSessionFactoryBuilder 文档地址：http://www.mybatis.org/spring/factorybean.html --&gt; &lt;bean id="sqlSessionFactory" class="org.mybatis.spring.SqlSessionFactoryBean"&gt; &lt;property name="dataSource" ref="dataSource"/&gt; &lt;!-- 指定 MyBatis 的 XML 配置文件所在位置 --&gt; &lt;property name="configLocation" value="classpath:mybatis-config.xml"/&gt; &lt;!-- 配置 MyBatis 到哪里去寻找 type aliases 即通过 model 类的类名自动配置其对应的 type alias 此后在 mapper 中就可以使用其 alias 而不用写 model 类的全限定名 --&gt; &lt;property name="typeAliasesPackage" value="com.boris1993.tiebacheckin.model"/&gt; &lt;!-- 配置 mapper 文件的位置 --&gt; &lt;property name="mapperLocations" value="classpath:mapper/*.xml"/&gt; &lt;/bean&gt; &lt;!-- 配置自动扫描 mapper 在 Quick Start 中，教程提到了使用 MapperFactoryBean 来指明 mapper 对应的各个接口 但实际上，并不需要手动来一个个指定所有的 mapper MyBatis可以通过 MapperScannerConfigurer 来自动扫描指定包下面所有的接口 文档地址：http://www.mybatis.org/spring/mappers.html#scan 的 MapperScannerConfigurer 部分 --&gt; &lt;bean class="org.mybatis.spring.mapper.MapperScannerConfigurer"&gt; &lt;property name="sqlSessionFactoryBeanName" value="sqlSessionFactory"/&gt; &lt;property name="basePackage" value="com.boris1993.tiebacheckin.dao"/&gt; &lt;/bean&gt; &lt;!-- 启用由 Spring 管理的事务 MyBatis-Spring 允许 MyBatis 参与到 Spring 的事务中 文档地址：http://www.mybatis.org/spring/transactions.html#configuration --&gt; &lt;bean id="transactionManager" class="org.springframework.jdbc.datasource.DataSourceTransactionManager"&gt; &lt;property name="dataSource" ref="dataSource"/&gt; &lt;/bean&gt;&lt;/beans&gt;service配置service的配置很简单，一个是配置要扫描的包，一个是启用基于注解的配置，启用后就可以使用Spring的@Transactional配置事务1234567891011&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:context="http://www.springframework.org/schema/context" xmlns:tx="http://www.springframework.org/schema/tx" xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd http://www.springframework.org/schema/tx http://www.springframework.org/schema/tx/spring-tx.xsd"&gt; &lt;context:component-scan base-package="com.boris1993.tiebacheckin.service"/&gt; &lt;tx:annotation-driven/&gt;&lt;/beans&gt;web配置web的配置也很简单，一个是启用基于注解的配置，一个是启用default-servlet-handler，一个是配置要扫描的包1234567891011121314151617&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:mvc="http://www.springframework.org/schema/mvc" xmlns:context="http://www.springframework.org/schema/context" xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/mvc http://www.springframework.org/schema/mvc/spring-mvc.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd"&gt; &lt;mvc:annotation-driven/&gt; &lt;!-- 启用该配置后，Spring会将静态文件的请求转发到容器的默认 servlet 这样配置后，就可以在 web.xml 中给 DispatcherServlet 指定 mapping 为 "/" --&gt; &lt;mvc:default-servlet-handler/&gt; &lt;context:component-scan base-package="com.boris1993.tiebacheckin.controller"/&gt;&lt;/beans&gt;切面配置这里先暂时放上来不完整的配置文件内容，后续内容将随着文章的继续而补全123456789&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:aop="http://www.springframework.org/schema/aop" xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/aop http://www.springframework.org/schema/aop/spring-aop.xsd"&gt; &lt;!-- 在 Spring 中使用基于 AspectJ 的 AOP --&gt; &lt;aop:aspectj-autoproxy/&gt;&lt;/beans&gt;编写Log4j2配置文件123456789101112131415161718192021222324252627282930&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;Configuration status="error" name="LoggerConfig" dest="err"&gt; &lt;Properties&gt; &lt;!-- 创建一个名为 filename 的属性，用于给后文的文件输出指定输出位置 $&#123;sys:catalina.home&#125; 取到的即是系统变量 $CATALINA_HOME的值 所以当 $CATALINA_HOME 存在时，日志会被写到 $CATALINA_HOME/logs/tiebacheckin.log 否则将写到 /tmp/logs/tiebacheckin.log --&gt; &lt;Property name="filename"&gt;$&#123;sys:catalina.home:-/tmp&#125;/logs/tiebacheckin.log&lt;/Property&gt; &lt;/Properties&gt; &lt;Appenders&gt; &lt;!-- 创建一个名为 STDOUT 的控制台输出，输出目标为标准输出(stdout) --&gt; &lt;Console name="STDOUT" target="SYSTEM_OUT"&gt; &lt;PatternLayout charset="UTF-8" pattern="[%-5p] %d %c - %m%n"/&gt; &lt;/Console&gt; &lt;!-- 创建一个名为 FILE 的文件输出，文件位置使用上文的 filename 属性 --&gt; &lt;File name="FILE" filename="$&#123;filename&#125;" createOnDemand="true"&gt; &lt;PatternLayout charset="UTF-8" pattern="[%-5p] %d %c - %m%n"/&gt; &lt;/File&gt; &lt;/Appenders&gt; &lt;Loggers&gt; &lt;Root level="error"&gt; &lt;AppenderRef ref="STDOUT"/&gt; &lt;/Root&gt; &lt;Logger name="com.boris1993.tiebacheckin" level="info"&gt; &lt;AppenderRef ref="FILE"/&gt; &lt;/Logger&gt; &lt;/Loggers&gt;&lt;/Configuration&gt;编写web.xml最后完成web.xml的编写12345678910111213141516171819202122232425&lt;web-app&gt; &lt;display-name&gt;Tieba Cloud Check-in&lt;/display-name&gt; &lt;servlet&gt; &lt;servlet-name&gt;springmvc&lt;/servlet-name&gt; &lt;servlet-class&gt; org.springframework.web.servlet.DispatcherServlet &lt;/servlet-class&gt; &lt;init-param&gt; &lt;!-- 按照规范，各 servlet 的配置文件默认以 $&#123;servlet-name&#125;-servlet.xml 命名 但是因为本项目中 Spring 的配置文件被分成了4个，并没有遵守默认的约定 所以需要显式指定配置文件的位置 --&gt; &lt;param-name&gt;contextConfigLocation&lt;/param-name&gt; &lt;param-value&gt;classpath:spring-*.xml&lt;/param-value&gt; &lt;/init-param&gt; &lt;load-on-startup&gt;1&lt;/load-on-startup&gt; &lt;/servlet&gt; &lt;servlet-mapping&gt; &lt;servlet-name&gt;springmvc&lt;/servlet-name&gt; &lt;url-pattern&gt;/&lt;/url-pattern&gt; &lt;/servlet-mapping&gt;&lt;/web-app&gt;至此，本项目的骨架搭建完成系列链接搭建Spring MVC + MyBatis项目笔记(一) 框架搭建]]></content>
      <categories>
        <category>学习记录</category>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
        <tag>Spring MVC</tag>
        <tag>Spring</tag>
        <tag>MyBatis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring MVC学习笔记]]></title>
    <url>%2Fprojects%2Fjava%2Fspring%2Flearning-spring-mvc.html</url>
    <content type="text"><![CDATA[本文记录学习Spring和Spring MVC过程中的笔记。基于Java的配置方式123456// Marks this is a configuration class@Configuration// Enables scanning components in current and sub packages@ComponentScanpublic class SpringConfig &#123;&#125;分profile的配置开发环境的配置类12345@Configuration@Profile("dev")public class SpringDevConfig &#123; // Configurations&#125;生产环境的配置类1234@Configuration@Profile("prod")public class SpringProdConfig &#123;&#125;最外层配置类中引入各环境配置12345678// Marks this is a configuration class@Configuration// Enables scanning components in current and sub packages@ComponentScan// Imports configuration classes@Import(&#123;SpringDevConfig.class, SpringProdConfig.class&#125;)public class SpringConfig &#123;&#125;web.xml中配置默认环境1234567891011121314151617&lt;servlet&gt; &lt;servlet-name&gt;springmvc&lt;/servlet-name&gt; &lt;servlet-class&gt; org.springframework.web.servlet.DispatcherServlet &lt;/servlet-class&gt; &lt;init-param&gt; &lt;!-- The default profile will be the development profile. You can add following code to tomcat's context.xml to enable the production environment: &lt;Environment name="spring.profiles.active" type="java.lang.String" value="prod" /&gt; --&gt; &lt;param-name&gt;spring.profiles.default&lt;/param-name&gt; &lt;param-value&gt;dev&lt;/param-value&gt; &lt;/init-param&gt; &lt;load-on-startup&gt;1&lt;/load-on-startup&gt;&lt;/servlet&gt;生产环境的Tomcat的context.xml中配置启用生产环境配置(JNDI方式)123456789&lt;Context&gt; &lt;!-- Other configurations --&gt; &lt;Environment name="spring.profiles.active" type="java.lang.String" value="prod" /&gt;&lt;/Context&gt;]]></content>
      <categories>
        <category>学习记录</category>
        <category>Java</category>
        <category>Spring</category>
      </categories>
      <tags>
        <tag>Spring MVC</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[购买新的Linux服务器后需要做的安全措施]]></title>
    <url>%2Flinux%2Flinux-server-security-measures.html</url>
    <content type="text"><![CDATA[在购买了一台安装Linux系统的VPS之后，首先要做好一定的安全防护措施，来尽可能地保证你的VPS不会沦为某些人的肉鸡。修改SSH默认端口这个世界上，总有不少无聊的人做着SSH弱口令扫描这种事情，相信我，你的IP一定是在被扫描的IP段里的，所以，更换掉SSH的默认端口会是个好主意。用你喜欢的文本编辑器，编辑 /etc/ssh/sshd_config ，修改如下内容：123# SSH默认端口号为22# 将其修改为一个自定义的端口号，比如15Port 15保存配置文件，并重启SSH服务端进程，使新的配置生效。注意此时不要退出现在的SSH会话，因为一旦出现问题，我们还可以使用这个会话来修复，否则就只能通过虚拟控制台来登陆了接下来新开一个SSH会话，记得通过新指定的端口号来连接，以检查配置是否正确无误。没问题之后，就可以关掉其中一个SSH会话了，毕竟还是不要浪费资源，注意环保不是。启用防火墙一台放在公网上的，没有防火墙的服务器，那就是一台公交车。那么怎么变成私家车呢？废话，开防火墙啊！目前已经有一些iptables的前端工具，来简化防火墙的配置了，所以不建议直接操作iptables。当然如果您有信心，那就当我没说。不同发行版所使用的iptables前端可能是不一样的，比如CentOS使用的是 firewalld ，而Ubuntu使用的是 ufw 。由于我使用的是Ubuntu，所以下面就以 ufw 来举例了，使用 firewalld 的同学，可以参考这篇文章来学习。1234567891011121314151617181920212223# 首先检查防火墙是否在运行$ sudo ufw statusStatus: inactive # 说明目前ufw并没有启动# 启动ufw$ sudo ufw enable# 防火墙已激活，并会跟随系统自动启动Firewall is active and enabled on system startup# 把SSH的端口加入到开放的列表中# 否则这个会话断掉之后，你就再也别想用SSH登陆了$ ufw allow 15Rule addedRule added (v6)# 看一下是不是成功加进去了$ sudo ufw statusStatus: activeTo Action From-- ------ ----15 ALLOW Anywhere15 (v6) ALLOW Anywhere (v6)这样防火墙就启动了，并且仅接受来自15端口的入站请求。在配置放行列表的时候，注意仅添加必要的端口。乱开一气，或者直接允许所有端口，那就跟没有防火墙一样了。禁止root用户通过SSH登陆地球人都知道，root是Linux系统中权限最高的用户，同时也是最危险的用户。所以当然不能开放root远程登录的权限。在此之前，你需要先创建一个自己的用户，并且设置好密码，保证可以正常登陆到系统中。至于创建用户的方法我这里就不赘述了。有了自己的用户之后，编辑 /etc/ssh/sshd_config ，修改如下内容：12# 允许使用root用户登陆PermitRootLogin no保存并重启SSH服务，就可以阻止root用户通过SSH登陆了。使用RSA密钥对登陆SSH在防止被破解的角度上，光是换端口和开防火墙，是远远不够的。还记得上文提到的SSH弱口令扫描吗？相信我，你绞尽脑汁想出来的密码，还真不一定打得过字典，而VPS提供商给你的默认密码，你确定你能记得住？但是RSA密钥对不仅能抵抗字典攻击，还不需要你记忆什么登陆信息，何乐而不为？生成密钥对Windows下生成密钥对如果你用的是Windows，那么可以参考这篇文章来生成你的密钥对，并将其上传至服务器。Linux下生成密钥对如果你用的是Linux，那么可以使用 ssh-keygen 命令生成密钥对。首先在本地电脑上生成密钥对123456789101112131415161718192021$ ssh-keygen -b 2048Generating public/private rsa key pair.Enter file in which to save the key (/Users/boris/.ssh/id_rsa): 密钥文件的位置，回车使用默认值Enter passphrase (empty for no passphrase): 密钥的密码，留空表示没有密码Enter same passphrase again: 确认密码Your identification has been saved in /Users/boris/.ssh/id_rsa.Your public key has been saved in /Users/boris/.ssh/id_rsa.pub.The key fingerprint is:SHA256:K23EGsTSYVod8LbR/6MRHm3XHJbAlTxCbewMUXmfaOo boris@Boris-MacBook-Pro.localThe key&apos;s randomart image is:+---[RSA 2048]----+| =o.. o+Boo|| * o.. +.Oo|| o + + . B+=|| o o o . +.=+|| . S * o +|| = . o = . || . o + . o o || o E o . || + . |+----[SHA256]-----+生成好了之后，就可以使用 ssh-copy-id 来传输公钥到远程服务器了：1ssh-copy-id -i ~/.ssh/id_rsa &lt;USERNAME&gt;@&lt;HOST&gt;然后就可以使用密钥登陆来测试了，方法很简单，只需要为 ssh 命令添加 -i 参数并指定私钥文件即可，如果私钥文件名为 id_rsa 的话， -i 参数也可以省略了。如果觉得使用密钥登陆的命令过长，那么可以参考我的另一篇博客使用 SSH config 简化 SSH 连接来简化SSH客户端的操作。配置SSH仅接受密钥登陆在服务器上编辑 /etc/ssh/sshd_config 修改如下内容：123456# 启用公钥认证PubkeyAuthentication yes# 禁用密码认证PasswordAuthentication no# 不允许空密码登陆PermitEmptyPasswords no保存文件并重启SSH服务，然后服务器就只会接受通过密钥认证的登陆请求了，在密钥错误或者未提供密钥的时候，服务器会直接拒绝请求。做完以上几步之后，通常的端口扫描和弱口令攻击基本上就免疫了，但是安全没有终点，在日常维护中还是需要时常检查鉴权日志和防火墙日志，以保证系统仍处于安全的状态下。在配置其他应用的时候，也要考虑到应用的安全相关的配置。]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
        <tag>VPS</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[如何允许非root进程绑定低位端口]]></title>
    <url>%2Flinux%2Fallow-non-root-process-to-bind-low-numbered-ports.html</url>
    <content type="text"><![CDATA[众所周知，在Linux中，要想绑定端口号在1024以下的低位端口，是需要root权限的。但是，如果我又想绑定低位端口，又不想以root身份运行程序，该怎么办？答案是，setcap命令。怎么做TL;DR，使用如下命令给这个程序赋予CAP_NET_BIND_SERVICE能力即可。注意，这条命令需要以root身份执行。1$ sudo setcap CAP_NET_BIND_SERVICE=+eip /path/to/binary这到底在干嘛接下来，我就把上面这条命令一点点拆开，解释清楚它到底干了什么。Capabilities首先介绍一下capabilities(能力)这个东西。在Linux内核版本2.2开始，Linux将一系列的超级管理员权限细分成了一个个可以单独开启关闭的单元，以提供更细粒度的权限控制，这些单元，就被称之为capabilities。详细的capabilities列表可以参考Man Page Capabilities(7)。CAP_NET_BIND_SERVICE拥有这个capability的程序，就可以绑定端口号在1024以下的特权端口。setcap那么，该如何控制每个capability呢？答案就是setcap命令。上文所提到的命令，就是给指定的这个二进制程序增加CAP_NET_BIND_SERVICE这个capability。在capability名后面，用加号相连接的，则是开启这个capability的模式。模式有如下三种：e: Effective，意为这个capability是启用的。p: Permitted，意为这个capability是允许被使用的。i: inherited，意为这个capability可以被其子进程继承。在setcap命令中，使用加号来开启这个模式，或者使用减号来关闭这个模式。有什么副作用这个方法确实有一些副作用，或者说是限制：这个方法对脚本无效。如果要使某个脚本拥有这个能力，则需要为其解释器赋予这个能力，而这明显是一个巨大的安全隐患。Linux会为使用了setcap或suid的程序禁用掉LD_LIBRARY_PATH。除了手动指定，还有没有其他办法Systemd也支持在service的配置文件中指定capabilities，其用法示例如下：1234567[Service]# 该服务仅可以使用哪些capabilitiesCapabilityBoundingSet=CAP_NET_BIND_SERVICE# 以非特权用户运行程序时需要设定此参数AmbientCapabilities=CAP_NET_BIND_SERVICE参考资料Man Page Capabilities(7)Man Page setcap(8)Man Page cap_from_text(3)getcap, setcap and file capabilities - insecure.wsIs there a way for non-root processes to bind to “privileged” ports on Linux? - Stack OverflowLinux的capabilities机制]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>setcap</tag>
        <tag>low numbered ports</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[卸载Oracle Database 12c]]></title>
    <url>%2Fdatabase%2Foracle%2Funinstall-oracle-12c.html</url>
    <content type="text"><![CDATA[与繁琐复杂的安装过程正相反，Oracle Database 12c的卸载过程非常简单，只需要执行一个shell脚本，就可以完成卸载过程。1234567# 首先以oracle用户登陆到服务器上# 进入卸载脚本所在目录$ cd $ORACLE_HOME/deinstall# 执行卸载脚本$ ./deinstall接下来按照脚本提示进行卸载过程123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182Checking for required files and bootstrapping ...Please wait ...Location of logs /opt/oracle/app/oraInventory/logs/############ ORACLE DECONFIG TOOL START ##################################### DECONFIG CHECK OPERATION START ########################### [START] Install check configuration ##Checking for existence of the Oracle home location /opt/oracle/app/oracle/product/12.2.0_2/dbhome_1Oracle Home type selected for deinstall is: Oracle Single Instance DatabaseOracle Base selected for deinstall is: /opt/oracle/app/oracleChecking for existence of central inventory location /opt/oracle/app/oraInventory## [END] Install check configuration ##Network Configuration check config STARTNetwork de-configuration trace file location: /opt/oracle/app/oraInventory/logs/netdc_check2018-08-22_04-12-12-PM.log# 输入要卸载的监听器名Specify all Single Instance listeners that are to be de-configured. Enter .(dot) to deselect all. [LISTENER]: &lt;回车&gt;Network Configuration check config ENDDatabase Check Configuration STARTDatabase de-configuration trace file location: /opt/oracle/app/oraInventory/logs/databasedc_check2018-08-22_04-16-17-PM.logUse comma as separator when specifying list of values as input# 输入在当前Oracle home下配置的数据库名Specify the list of database names that are configured in this Oracle home [orcldb]: &lt;回车&gt;###### For Database &apos;orcldb&apos; ####### 自动检测到的这个数据库的信息Single Instance DatabaseThe diagnostic destination location of the database: /opt/oracle/app/oracle/diag/rdbms/orcldbStorage type used by the Database: FSDatabase file location: /opt/oracle/app/oracle/oradata/orcldbFast recovery area location: Does not existdatabase spfile location: /opt/oracle/app/oracle/product/12.2.0_2/dbhome_1/dbs/spfileorcldb.ora# 询问是否要修改以上信息The details of database(s) orcldb have been discovered automatically. Do you still want to modify the details of orcldb database(s)? [n]:Database Check Configuration ENDOracle Configuration Manager check STARTOCM check log file location : /opt/oracle/app/oraInventory/logs//ocm_check2396.logOracle Configuration Manager check END######################### DECONFIG CHECK OPERATION END ################################################ DECONFIG CHECK OPERATION SUMMARY #######################Oracle Home selected for deinstall is: /opt/oracle/app/oracle/product/12.2.0_2/dbhome_1Inventory Location where the Oracle home registered is: /opt/oracle/app/oraInventoryFollowing Single Instance listener(s) will be de-configured: LISTENERThe following databases were selected for de-configuration : orcldbDatabase unique name : orcldbStorage used : FSChecking the config status for CCROracle Home exists with CCR directory, but CCR is not configuredCCR check is finished# 输入&quot;y&quot;继续Do you want to continue (y - yes, n - no)? [n]: yA log of this session will be written to: &apos;/opt/oracle/app/oraInventory/logs/deinstall_deconfig2018-08-22_04-12-09-PM.out&apos;Any error messages from this session will be written to: &apos;/opt/oracle/app/oraInventory/logs/deinstall_deconfig2018-08-22_04-12-09-PM.err&apos;######################## DECONFIG CLEAN OPERATION START ########################Database de-configuration trace file location: /opt/oracle/app/oraInventory/logs/databasedc_clean2018-08-22_04-22-04-PM.logDatabase Clean Configuration START orcldbThis operation may take few minutes.Database Clean Configuration END orcldbNetwork Configuration clean config STARTNetwork de-configuration trace file location: /opt/oracle/app/oraInventory/logs/netdc_clean2018-08-22_04-26-53-PM.logDe-configuring Single Instance listener(s): LISTENERDe-configuring listener: LISTENER Stopping listener: LISTENER Warning: Failed to stop listener. Listener may not be running. Deleting listener: LISTENER Listener deleted successfully.Listener de-configured successfully.De-configuring Naming Methods configuration file...Naming Methods configuration file de-configured successfully.De-configuring Local Net Service Names configuration file...Local Net Service Names configuration file de-configured successfully.De-configuring backup files...Backup files de-configured successfully.The network configuration has been cleaned up successfully.Network Configuration clean config ENDOracle Configuration Manager clean STARTOCM clean log file location : /opt/oracle/app/oraInventory/logs//ocm_clean2396.logOracle Configuration Manager clean END######################### DECONFIG CLEAN OPERATION END ################################################ DECONFIG CLEAN OPERATION SUMMARY #######################Successfully de-configured the following database instances : orcldbFollowing Single Instance listener(s) were de-configured successfully: LISTENERCleaning the config for CCRAs CCR is not configured, so skipping the cleaning of CCR configurationCCR clean is finished#################################################################################### ORACLE DECONFIG TOOL END #############Using properties file /tmp/deinstall2018-08-22_04-10-49PM/response/deinstall_2018-08-22_04-12-09-PM.rspLocation of logs /opt/oracle/app/oraInventory/logs/############ ORACLE DEINSTALL TOOL START ################################### DEINSTALL CHECK OPERATION SUMMARY #######################A log of this session will be written to: &apos;/opt/oracle/app/oraInventory/logs/deinstall_deconfig2018-08-22_04-12-09-PM.out&apos;Any error messages from this session will be written to: &apos;/opt/oracle/app/oraInventory/logs/deinstall_deconfig2018-08-22_04-12-09-PM.err&apos;######################## DEINSTALL CLEAN OPERATION START ########################## [START] Preparing for Deinstall ##Setting LOCAL_NODE to boris-x200Setting CRS_HOME to falseSetting oracle.installer.invPtrLoc to /tmp/deinstall2018-08-22_04-10-49PM/oraInst.locSetting oracle.installer.local to false## [END] Preparing for Deinstall ##Setting the force flag to falseSetting the force flag to cleanup the Oracle BaseOracle Universal Installer clean STARTDetach Oracle home &apos;/opt/oracle/app/oracle/product/12.2.0_2/dbhome_1&apos; from the central inventory on the local node : DoneDelete directory &apos;/opt/oracle/app/oracle/product/12.2.0_2/dbhome_1&apos; on the local node : DoneThe Oracle Base directory &apos;/opt/oracle/app/oracle&apos; will not be removed on local node. The directory is in use by Oracle Home &apos;/opt/oracle/app/oracle/product/12.2.0/dbhome_1&apos;.Oracle Universal Installer cleanup was successful.Oracle Universal Installer clean END## [START] Oracle install clean #### [END] Oracle install clean ########################### DEINSTALL CLEAN OPERATION END ################################################ DEINSTALL CLEAN OPERATION SUMMARY #######################Successfully detached Oracle home &apos;/opt/oracle/app/oracle/product/12.2.0_2/dbhome_1&apos; from the central inventory on the local node.Successfully deleted directory &apos;/opt/oracle/app/oracle/product/12.2.0_2/dbhome_1&apos; on the local node.Oracle Universal Installer cleanup was successful.Review the permissions and contents of &apos;/opt/oracle/app/oracle&apos; on nodes(s) &apos;boris-x200&apos;.If there are no Oracle home(s) associated with &apos;/opt/oracle/app/oracle&apos;, manually delete &apos;/opt/oracle/app/oracle&apos; and its contents.Oracle deinstall tool successfully cleaned up temporary directories.#################################################################################### ORACLE DEINSTALL TOOL END #############最后根据上面DEINSTALL CLEAN OPERATION SUMMARY段的提示，删除相关目录。至此Oracle Database 12c的卸载过程完成。]]></content>
      <categories>
        <category>数据库</category>
        <category>Oracle</category>
      </categories>
      <tags>
        <tag>Database</tag>
        <tag>Oracle 12c</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[在macOS中通过SSH进行X11转发]]></title>
    <url>%2Ftools%2Fssh%2Fmacos-install-x11-client.html</url>
    <content type="text"><![CDATA[本文记录如何在macOS中安装X11客户端，并通过SSH进行X11转发。安装X11客户端在macOS中，可以使用XQuartz作为X11客户端。可以到XQuartz Releases下载安装包手动安装，也可使用Homebrew安装。使用Homebrew安装XQuartz的命令如下：1$ brew cask install xquartz注意安装期间需要提供管理员密码以完成安装。安装完成之后需要完全退出并重启终端模拟器。检查远程服务器配置编辑/etc/ssh/sshd_config，设定如下条目：12X11Forwarding yesX11DisplayOffset 10然后重启sshd使配置生效：1sudo systemctl restart sshd转发远程X11程序使用ssh -X连接到远程服务器，执行任意X11程序，然后程序的窗口就会在本机显示。]]></content>
      <categories>
        <category>工具</category>
        <category>SSH</category>
      </categories>
      <tags>
        <tag>XQuartz</tag>
        <tag>X11</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[监听Tomcat的启动、停止事件]]></title>
    <url>%2Ftools%2Ftomcat%2Ftomcat-servlet-context-listener.html</url>
    <content type="text"><![CDATA[当Servlet容器启动或终止Web应用时，会触发ServletContextEvent事件，该事件由ServletContextListener来处理。在Servlet API中有一个ServletContextListener接口，接口中定义了处理ServletContextEvent事件的两个方法，它能够监听ServletContext对象的生命周期，实际上就是监听Web应用的生命周期。我们可以通过实现这两个方法，来实现在Tomcat启动和停止时执行一定的操作。监听器类编写新建一个监听器类TomcatListener并实现ServletContextListener接口1234567891011public class DemoListener implements ServletContextListener &#123; @Override public void contextInitialized(ServletContextEvent servletContextEvent) &#123; System.out.println("Tomcat Started"); &#125; @Override public void contextDestroyed(ServletContextEvent servletContextEvent) &#123; System.out.println("Tomcat Destroyed"); &#125;&#125;配置web.xml在web.xml中添加listener条目123&lt;listener&gt; &lt;listener-class&gt;com.project.name.listener.DemoListener&lt;/listener-class&gt;&lt;/listener&gt;验证将WAR包部署到Tomcat并启动，检查catalina.out在Tomcat启动时看到如下日志：1215-Aug-2018 15:58:44.632 INFO [localhost-startStop-1] org.apache.catalina.startup.HostConfig.deployWAR Deploying web application archive [/usr/local/Cellar/tomcat@8/8.5.28/libexec/webapps/tomcatlistener.war]Tomcat Started在Tomcat停止时看到如下日志：1215-Aug-2018 16:02:22.582 INFO [main] org.apache.catalina.core.StandardService.stopInternal Stopping service [Catalina]Tomcat Destroyed输出内容与TomcatListener所写内容一致，Q.E.D.]]></content>
      <categories>
        <category>工具</category>
        <category>Tomcat</category>
      </categories>
      <tags>
        <tag>Tomcat</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[在SuSE Linux上安装Oracle Database 12c手记]]></title>
    <url>%2Fdatabase%2Foracle%2Finstall-oracle-12c-on-suse-linux.html</url>
    <content type="text"><![CDATA[最近开始学习Oracle数据库，在这里记录一下在openSuSE Leap 15上安装Oracle Database 12c的过程。本文内容目前仅仅是一个大致的安装步骤的介绍，可能会在将来持续补充完善。安装前准备检查物理内存空间及swap空间Oracle 12c要求最低1GB物理内存，建议安装2GB物理内存。1234$ free -m total used free shared buff/cache availableMem: 3833 945 919 156 1968 2449Swap: 8472 0 8472可见本机物理内存总计4GB，满足需求。Oracle 12c要求当物理内存在2GB~16GB之间时，swap空间需等同于物理内存大小。如上结果可见swap空间约为8GB，大于需求值。检查软件配置检查操作系统内核版本本机操作系统为openSuSE Leap 15，套用安装文档关于SUSE Linux Enterprise Server 12 SP1的要求3.12.49-11.1 or later。12$ uname -r4.12.14-lp150.12.13-default可见内核版本满足需求。检查服务器配置1234567891011121314151617181920212223# 检查 /tmp 目录空间$ df -h | grep /tmp/dev/sda1 40G 11G 29G 28% /tmp# 检查硬盘空间是否大于7.5GB$ df -hFilesystem Size Used Avail Use% Mounted ondevtmpfs 1.9G 0 1.9G 0% /devtmpfs 1.9G 4.0K 1.9G 1% /dev/shmtmpfs 1.9G 18M 1.9G 1% /runtmpfs 1.9G 0 1.9G 0% /sys/fs/cgroup/dev/sda1 40G 11G 29G 28% //dev/sda1 40G 11G 29G 28% /.snapshots/dev/sda1 40G 11G 29G 28% /boot/grub2/x86_64-efi/dev/sda1 40G 11G 29G 28% /boot/grub2/i386-pc/dev/sda1 40G 11G 29G 28% /opt/dev/sda1 40G 11G 29G 28% /tmp/dev/sda1 40G 11G 29G 28% /var/dev/sda1 40G 11G 29G 28% /root/dev/sda1 40G 11G 29G 28% /srv/dev/sda1 40G 11G 29G 28% /usr/local/dev/sda3 250G 1.6G 249G 1% /hometmpfs 384M 8.0K 384M 1% /run/user/1000配置X11转发编辑/etc/ssh/sshd_config，修改如下内容：12X11Forwarding yesX11UseLocalhost yes并在操作机上安装X11客户端，如macOS中的xquartz。配置hosts文件编辑hosts文件，写入本机的IP地址和机器名：1192.168.2.12 boris-x200检查用户和组检查Oracle Inventory和Oracle Inventory Group12345$ more /etc/oraInst.locmore: stat of /etc/oraInst.loc failed: No such file or directory$ grep oinstall /etc/group&lt;NOTHING&gt;说明Oracle Inventory Group不存在。创建这个组。1$ sudo /usr/sbin/groupadd -g 54321 oinstall创建一系列特权组1234567891011121314151617181920212223# Oracle Automatic Storage Management特权组$ sudo /usr/sbin/groupadd -g 54327 asmdba# Oracle Automatic Storage Management启动、停止特权组$ sudo /usr/sbin/groupadd -g 54328 asmoper# 数据库SYSDBA特权组$ sudo /usr/sbin/groupadd -g 54322 dba# 数据库SYSOPER特权组(有限的数据库管理权限)$ sudo /usr/sbin/groupadd -g 54323 oper# 数据库备份、恢复特权组$ sudo /usr/sbin/groupadd -g 54324 backupdba# Data Guard操作特权组$ sudo /usr/sbin/groupadd -g 54325 dgdba# Transparent Data Encryption keystore操作特权组$ sudo /usr/sbin/groupadd -g 54326 kmdba# Oracle RAC cluster日常管理特权组$ sudo /usr/sbin/groupadd -g 54330 racdba创建Oracle Software Owner User12345678# 创建用户$ sudo /usr/sbin/useradd -u 54321 -g oinstall -G dba,asmdba,backupdba,dgdba,kmdba,racdba oracle# 为该用户创建家目录，并设定umask$ sudo /sbin/mkhomedir_helper oracle 022# 为该用户设定密码$ sudo passwd oracle检查ulimit在/etc/security/limits.conf配置如下内容1234567# Resource limits for user oracleoracle soft nofile 1024oracle hard nofile 65536oracle soft nproc 2047oracle hard nproc 16384oracle soft stack 10240oracle hard stack 32768创建安装目录12345678# 创建应用安装目录$ sudo mkdir -p /opt/oracle/app/oracle# 创建存放安装程序的目录$ sudo mkdir -p /opt/oracle/oracinstall# 修改所有者和权限$ sudo chown -R oracle:oinstall /opt/oracle安装准备安装程序访问Oracle下载页面下载Oracle 12c安装程序，并解压到/opt/oracle/oracinstall。解压完成后注意修改其所有者到oracle:oinstall。开始安装以下截图因为X11客户端的问题，图片色彩会有失真，还请读者见谅。准备X11转发首先启动X11客户端并完成连接配置。使用ssh连接至服务器，以oracle用户登陆，并开启X11转发：1$ ssh -Y &lt;其他参数&gt; oracle@&lt;地址&gt;然后检查DISPLAY环境变量：1234567$ echo $DISPLAY# 如没有返回则需要配置DISPLAY环境变量$ export DISPLAY=localhost:10.0# 然后开启一个X11应用程序检查是否成功转发$ xclock &amp;如果成功开启转发，则结果应类似下图：启动安装程序接下来启动安装程序：1234# 进入安装程序所在位置并启动安装程序$ cd /opt/oracle/oracinstall$ ./runInstaller# 监控日志输出并等待安装程序启动配置邮箱地址第一步中可以配置一个用于接收安全通知的邮箱地址，如果不需要则可以留空。选择安装模式安装程序提供了三种安装模式：创建并配置数据库、仅安装数据库软件、升级已有数据库。我们这里选择仅安装数据库软件，配置将放到安装结束后进行。选择如何安装数据库安装程序提供了三种安装类型，我们这次将安装一个单实例数据库。选择要安装的版本安装程序提供了两种版本可供安装：企业版和标准版。我们这里选择安装企业版。设定安装位置这一步中需要指定安装过程中的两个路径：Oracle base: 指定数据库软件及其相关配置文件所存放的位置Software location: 指定数据库软件的安装位置此处需要确认该路径是否与Software location的路径匹配。配置Oracle组所对应的操作系统用户组这一步可以指定各个Oracle组所对应的操作系统用户组，检查并确认与上文所配置的组匹配。总览这一步可以检查前面每一步骤的配置是否正确。如检查无误则可继续。开始安装接下来就是等待安装完成。点击Details按钮可以看到目前详细的进度。期间需要用户以root权限执行脚本，根据弹窗给出的提示操作即可。完成安装安装成功结束后点击Close关闭安装程序。首次启动配置开放防火墙相关端口如果需要使数据库可以接受来自外部的连接，则需要开放监听器所指定的端口。创建数据库使用dbca命令启动数据库配置向导(DBCA)，跟随向导创建数据库。选择向导类型DBCA首先会询问本次要进行什么操作，选择Create a database来创建一个数据库。选择如何配置数据库DBCA提供两种配置方式：标准模式和高级模式。我们这里选择高级模式。选择部署模式因为我们是要创建一个单机实例，所以Database type中选择Oracle Single Instance Database。在下方的模版选择中，我们使用General Purpose or Transaction Processing。设定数据库标识符Global database name根据提示，需要遵循name.domain这样的格式，所以此处按照SID.主机名的方式填写。SID按需修改，本例中设定为orcldb。Create as Container Database保持不变。配置存储设定这一步如有定制的需要则选择自定义配置，否则选择套用选定模版。配置快速恢复设定在这一步按需配置快速恢复的设定。网络配置这一步中我们需要新建一个监听器来监听数据库的连接。选择Create a new listener来创建一个新的监听器，监听器名自行设定，端口保持1521不变。注意如果需要使数据库可以接受来自外部的连接，则需要配置防火墙放行监听器的端口。Data Vault设定这一步根据需要来设定是否开启Database Vault和Label Security。资源和属性配置这一步用于配置内存、字符集等等属性。MemoryMemory页用来选择内存管理方案。SizingSizing页用于配置 块大小 和 最大并发连接数 。这里需要注意，并发连接数一定要根据实际应用场景调整至适合的数值。本例由于是个人的测试环境，所以300完全满足这个场景的需要。Character setsCharacter sets页用于配置数据库所使用的字符集。数据库字符集选择AL32UTF8来使用Unicode。National character set即国际化字符集，按需选择UTF-16或者UTF-8；Default language即默认语言，根据实际使用场景选择；Default territory即默认地区，同样根据实际使用场景选择。Connection modeConnection mode页配置该实例是以独立服务器模式运行还是以共享服务器模式运行。本例中是独立服务器模式。Sample schemasSample schemas页可以选择是否安装演示数据库。全部完成后继续管理选项Management options中可以配置是否启用Enterprise Manager(EM)，以及可以注册到已有的EM cloud control中。用户密码User credentials用于配置特权用户的密码，可以为SYS，SYSTEM，PDBADMIN分别指定密码，也可以为其指定统一的密码。数据库创建配置Creation option中可以配置数据库创建过程中以及创建结束后的操作。Create database勾选后即可创建这个数据库。如果需要在创建结束后运行SQL脚本，则可以在Post DB creation scripts中填写各个脚本的路径，配置程序会按照先后顺序执行。Save as a database template勾选后，将会根据本次向导所设定的值，创建一个数据库模版。Generate database creation scripts勾选后，将会根据本次向导所设定的值，生成一个数据库创建脚本。以后使用此脚本即可创建出一个一模一样的数据库。总览这一步可以最后回顾前面步骤中所设定的值。如确认无误即可继续。开始创建在Progress page中可以看到当前数据库创建的进度。耐心等待数据库创建完成。创建成功在创建成功后，在最后一页会再次显示一些关键的连接信息。检查数据库连通性打开适用于Oracle数据库的连接工具，比如Oracle SQL Developer，新建连接并填写连接信息，点击Test，如果Status为Success则说明以上配置全部成功，可以开始使用。]]></content>
      <categories>
        <category>数据库</category>
        <category>Oracle</category>
      </categories>
      <tags>
        <tag>Database</tag>
        <tag>Oracle 12c</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[记一个Caddy和GitHub自定义域名的坑]]></title>
    <url>%2Ftools%2Fcaddy%2Fcaddy-and-github-custom-domain.html</url>
    <content type="text"><![CDATA[最近心血来潮，想给这个博客在GitHub上面的页面绑个自定义域名，结果无意中发现了一个坑。前情提要如关于页面所见，这个博客是同时放在GitHub Pages和我的服务器上面的。我的服务器上面呢，是用Caddy的git插件监听了一个WebHook来实现同步更新的。在我绑定Custom domain之前，Caddy的自动更新一直在默默正常工作着。但就在我绑了Custom domain之后，我发现，Caddy没能成功拉取最新版本的仓库。追踪线索首先使用排除法，肯定不是GitHub的问题。那就看一下Caddy的日志里面有没有什么线索吧。123456789101112Aug 09 14:44:42 vps caddy[4516]: 2018/08/09 14:44:42 Received pull notification for the tracking branch, updating...Aug 09 14:44:43 vps caddy[4516]: From https://github.com/boris1993/boris1993.github.ioAug 09 14:44:43 vps caddy[4516]: * branch master -&gt; FETCH_HEADAug 09 14:44:43 vps caddy[4516]: + 3d5ecea...204143b master -&gt; origin/master (forced update)Aug 09 14:44:43 vps caddy[4516]: *** Please tell me who you are.Aug 09 14:44:43 vps caddy[4516]: RunAug 09 14:44:43 vps caddy[4516]: git config --global user.email &quot;you@example.com&quot;Aug 09 14:44:43 vps caddy[4516]: git config --global user.name &quot;Your Name&quot;Aug 09 14:44:43 vps caddy[4516]: to set your account&apos;s default identity.Aug 09 14:44:43 vps caddy[4516]: Omit --global to set the identity only in this repository.Aug 09 14:44:43 vps caddy[4516]: fatal: unable to auto-detect email address (got &apos;www-data@vps.(none)&apos;)Aug 09 14:44:43 vps caddy[4516]: 2018/08/09 14:44:43 exit status 128鞥？啥时候git pull也要提供用户名和邮箱了？随手往上面翻了翻，看见了点更有意思的东西：12345678910Aug 10 16:45:46 vps caddy[11022]: 2018/08/10 16:45:46 Received pull notification for the tracking branch, updating...Aug 10 16:45:47 vps caddy[11022]: From https://github.com/boris1993/boris1993.github.ioAug 10 16:45:47 vps caddy[11022]: * branch master -&gt; FETCH_HEADAug 10 16:45:47 vps caddy[11022]: 3a305c6..b57b257 master -&gt; origin/masterAug 10 16:45:47 vps caddy[11022]: Updating 3a305c6..b57b257Aug 10 16:45:47 vps caddy[11022]: Fast-forwardAug 10 16:45:47 vps caddy[11022]: CNAME | 1 +Aug 10 16:45:47 vps caddy[11022]: 1 file changed, 1 insertion(+)Aug 10 16:45:47 vps caddy[11022]: create mode 100644 CNAMEAug 10 16:45:47 vps caddy[11022]: 2018/08/10 16:45:47 https://github.com/boris1993/boris1993.github.io.git pulled.新增了个叫CNAME的文件？这是啥玩意？得，看看里面写了啥。123$ cat CNAMEblog2.boris1993.tk$这……不是我刚绑的那个自定义域名么……原来是这么实现的……好吧，这样一来，问题就清楚了。结案其实这个问题，是这么回事：在配置了自定义域名之后，GitHub会往仓库里放一个名为CNAME的文件，而我在用hexo提交的时候，我本地完全没有关于这个文件的任何记录，导致远端仓库的CNAME文件又丢了，而在Caddy更新的时候，怀疑Caddy在进行merge操作，merge操作需要用户提供用户名和邮箱，但是运行Caddy的www-data用户下没有这两个配置，于是就导致了上面的错误。至于解决方案嘛，要么就往博客的源码里面放一个名为CNAME文件并且保证内容正确，要么就干脆不配置自定义域名了。]]></content>
      <categories>
        <category>工具</category>
        <category>Caddy</category>
      </categories>
      <tags>
        <tag>Caddy</tag>
        <tag>GitHub</tag>
        <tag>Custom domain</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[微信小程序scroll-view填满剩余可用高度]]></title>
    <url>%2Fprojects%2Fwxapp%2Fscroll-view-auto-fit-height.html</url>
    <content type="text"><![CDATA[根据微信小程序scroll-view文档所述，scroll-view必须给定一个固定高度。那么如果我们想要让它自动填充剩余高度，该怎么办呢？前言在说出我的解决方案之前，先来看一下我的页面设计，以便于理解。如图所示，我将这个页面分成了三部分：最顶部的导航栏navbar，用于显示概要信息的header，以及本文的主角scroll-view。可见，scroll-view位于页面的最下方，如果我直接给它设定一个固定的高度，那么在不同尺寸的屏幕上，就可能会有高度过小而在下方留白，或者高度过大超出屏幕下边界的可能。那么，自动计算scroll-view的高度，看起来是一个可行的办法。思路有了，接下来就开始挑趁手的工具吧！需要的API首先，在计算过程中，整个页面的高度是必须要有的。而小程序的wx.getSystemInfo API正好可以提供这样的功能。其次，我们还得想办法拿到scroll-view上面各个组件的高度。小程序虽然没有DOM操作，但也提供WXML节点信息的API。撸起袖子开始干既然工具有了，那么，talk is cheap, I’ll show you the code!当然，简洁起见，我只会写出相关的代码，其余的代码我将直接略掉。12345678910111213141516171819202122232425262728293031323334353637383940414243444546Page(&#123; data: &#123; // 页面总高度将会放在这里 windowHeight: 0, // navbar的高度 navbarHeight: 0, // header的高度 headerHeight: 0, // scroll-view的高度 scrollViewHeight: 0 &#125;, onLoad: function(option) &#123; // 先取出页面高度 windowHeight wx.getSystemInfo(&#123; success: function(res) &#123; that.setData(&#123; windowHeight: res.windowHeight &#125;); &#125; &#125;); // 然后取出navbar和header的高度 // 根据文档，先创建一个SelectorQuery对象实例 let query = wx.createSelectorQuery().in(this); // 然后逐个取出navbar和header的节点信息 // 选择器的语法与jQuery语法相同 query.select('#navbar').boundingClientRect(); query.select('#header').boundingClientRect(); // 执行上面所指定的请求，结果会按照顺序存放于一个数组中，在callback的第一个参数中返回 query.exec((res) =&gt; &#123; // 分别取出navbar和header的高度 let navbarHeight = res[0].height; let headerHeight = res[1].height; // 然后就是做个减法 let scrollViewHeight = this.data.windowHeight - navbarHeight - headerHeight; // 算出来之后存到data对象里面 this.setData(&#123; scrollViewHeight: scrollViewHeight &#125;); &#125;); &#125;&#125;)至于WXML里面，就还是使用双大括号来将data部分的scrollViewHeight的值绑定到height属性上面就是了。需要注意的是，上面计算出来的值，单位是px而不是rpx。123&lt;scroll-view style="height: &#123;&#123;scrollViewHeight&#125;&#125;px" scroll-y="true"&gt; &lt;!-- scroll-view里面的内容 --&gt;&lt;/scroll-view&gt;这样，我们就得到了一个可以自动填满屏幕最下方剩余空间的scroll-view啦～]]></content>
      <categories>
        <category>学习记录</category>
        <category>小程序</category>
      </categories>
      <tags>
        <tag>小程序</tag>
        <tag>scroll-view</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[配置Caddy作为静态网站服务器和前置代理]]></title>
    <url>%2Ftools%2Fcaddy%2Fset-up-caddy-server.html</url>
    <content type="text"><![CDATA[之前听闻有个新的Web Server，名曰Caddy，其配置简单，还默认启用HTTP/2，并且可以自动申请Let’s Encrypt的HTTPS证书。试用了一番，觉得不错，便把这个博客的服务程序换成了Caddy。在这里呢，记录一下安装和配置的过程。安装万事第一步，先安装。下载页面概览打开Caddy的下载页面，页面的内容简洁明了，左侧是4个要配置的项，右侧是每个配置项实际的内容。选择运行平台首先，选择好Caddy要在哪个操作系统下运行。Caddy支持的平台还是足够多的，而且覆盖到了主流的操作系统，所以甭管您是Windows，还是Linux，抑或是BSD，都可以运行Caddy。因为我的服务器运行的是64位Ubuntu，所以选择Linux 64-bit。实话说，看到Plan 9的时候，心里还是被惊到了。选择插件接下来是选择要安装哪些插件，通常来说，根据自己的需要来选择就可以了。如果后期要安装更多的插件的话，重新来下载页面勾选需要的插件并重新安装就可以了。毕竟是用Go写的，最后就一个可执行文件，替换掉原来的，就算重装好了。我的需求有这么几点：我需要Caddy可以作为一个反向代理，所以选择了http.forwardproxy插件我的博客的源文件放置于我的GitHub中，我希望Caddy可以直接clone这个仓库，并且能通过WebHook监听这个仓库的更新事件，所以选择了http.git插件我在使用Cloudflare的DNS服务，并且Caddy可以通过DNS验证的方式申请HTTPS证书，所以需要tls.dns.cloudflare插件我想要Caddy作为一个系统服务，并且可以随系统自动启动，但是我又懒得自己写配置文件，所以使用hook.service插件来为我提供已经写好并经过了测试的配置文件选择是否开启遥测功能Caddy提供了一个叫做“遥测”的功能，可以监控您的Caddy实例的状态。具体针对该功能的描述，可以到其文档页面Telemetry阅读。这个功能开启与否与功能无关，开不开看您心情。选择适合您的许可证接下来，就是选择您要使用哪一种许可证来运行Caddy。像在下的博客是个人项目，不涉及商业应用，所以当然选择个人许可证。下载终于，到了下载这一步了。Caddy提供了多种下载的方式，您可以在浏览器中将可执行文件下载到本地，或者通过命令行来下载，还可以直接使用一句话脚本来安装。如果使用自动安装脚本的话，Caddy会被安装到/usr/local/bin/caddy中。如果选择手动安装，那么需要将Caddy的可执行文件放到PATH所包含的目录中，或者将Caddy所在的位置加入到PATH中。检查安装是否成功完成安装后，可以直接使用caddy命令启动一个Caddy服务器，它会开始监听本机的2015端口，并列出当前工作目录的内容。使用http://localhost:2015即可访问。如果能成功打开，或者可以看到一个404页面，那么说明Caddy安装成功了。配置Caddy的所有配置都将被写到一个名为Caddyfile的文件中。点击这里阅读Caddy官方提供的入门指导，以及Caddy官方文档。在以下实例中，我们假定Caddyfile的位置是/etc/caddy/Caddyfile，并且所有与Caddy相关的文件、目录，都存放于/etc/caddy下。配置网站的地址首先要配置Caddy所服务的网站的地址，如果只有一个地址的话，那么可以将地址写到Caddyfile的第一行，同时Caddyfile的第一行也必须是网站的地址。比如下面这样：1www.boris1993.tk这样Caddy就会监听www.boris1993.tk所绑定的地址，并监听80端口提供HTTP服务，以及443端口提供HTTPS服务。在默认情况下，Caddy会自动将HTTP请求使用HTTP 301返回码重定向到HTTPS，除非显式配置禁用HTTPS服务。如果需要指定端口号，那么可以在地址后面跟上端口号，比如www.boris1993.tk:8080。因为我没有用到这项功能，所以没有测试过这样配置的效果。如果您有需要还请自行测试。如果要同时开启多个网站，那么各个网站的配置需要以大括号包围起来，比如下面这样：1234567www.boris1993.tk &#123; &#125;www2.boris1993.tk &#123;&#125;我们这里就只演示仅有一个地址的情况。多个地址的配置与单个地址的配置方式相同，故不再赘述。配置静态文件所在的位置并启用gzip压缩有了地址之后，我们需要告诉Caddy要提供的静态文件在什么位置，这个可以使用root指令来制定，如下面这样：123www.boris1993.tk &#123; root /var/www&#125;然后Caddy就会到/var/www目录寻找index.html等默认的主页文件。启用gzip压缩，可以使我们的网站打开的更快。在Caddy中启用gzip，也只需要一条指令：1234www.boris1993.tk &#123; root /var/www gzip&#125;提供申请HTTPS证书的信息在默认情况下，Caddy会自动搞定申请HTTPS证书的事情，不需要用户进行干预。如果需要覆盖默认的配置，可以参考Caddy文档的TLS部分。配置日志访问日志网站的访问日志可以使用log指令来配置，该指令的文档可以参考这里。在这里我先放出我的配置，然后再逐行来解释。简明起见，我就只写出日志的部分，其余无关内容就不在这里写出来了。123456log / /var/log/caddy/access.log &quot;&#123;combined&#125;&quot; &#123; rotate_size 1 rotate_age 7 rotate_keep 2 rotate_compress&#125;第一行中，我指定要记录所有对网站根目录/的访问，将日志写到/var/log/caddy/access.log中，记录的方式是combined。Caddy提供了两种日志格式，common和combined，common是默认的记录格式。common的格式是这样子的：{客户端IP地址} - {HTTP基础验证的用户名} [{访问时间}] \&quot;{HTTP方式} {请求的URI} {协议版本}\&quot; {HTTP状态码} {响应体的大小}而combined格式，则是在common格式的末尾，追加如下内容：\&quot;{&gt;Referer}\&quot; \&quot;{&gt;User-Agent}\&quot;第二行rotate_size指定了在日志到达1MB大小之前不进行日志翻转，这个指令的单位是MB。第三行rotate_age指定了保留7天的翻转日志。第四行rotate_keep指定了只保留最近2个翻转日志，之前的版本将被删除。第五行rotate_compress指定使用gzip压缩翻转日志。错误日志错误日志可以使用errors指令来配置，该指令的文档可以参考这里。同样，我将以我的配置作为范例来解释，如果需要其他的配置可以参考官方文档。123456errors /var/log/Caddy/error.log &#123; 404 /var/www/error/HTTP404.html rotate_age 7 rotate_keep 2 rotate_compress&#125;第一行配置了错误日志将被写入到/var/log/Caddy/error.log中。第二行配置了当发生404错误后显示的页面，这里还可以为其他错误码指定错误页面，语法参见官方文档。其余三行的含义与上文log指令中对应参数的含义一致，不再赘述。配置自动从Git拉取页面内容Caddy支持从一个指定的Git仓库克隆以及更新页面的内容到某个目录，并可以通过WebHook来监视仓库的更新，参考配置如下：12345git https://github.com/boris1993/boris1993.github.io.git &#123; path /var/www hook /hook hook.password hook_type github&#125;这里我配置Caddy从https://github.com/boris1993/boris1993.github.io.git这个仓库拉取静态页面文件，这就是本博客所在的GitHub仓库，拉去之后文件将被放到/var/www目录下。因为我要实现博客文件自动更新，所以这里的地址需要与root指令配置的位置相同。hook参数配置Caddy使用www.boris1993.tk/hook作为WebHook的监听地址，这个hook的访问密码是hook.password，并且使用下一行中的hook_type指令显式指定Hook的类型是github，也就是来自GitHub的hook。这样配置完毕后，还需要为远程Git仓库配置hook，然后才可以实现自动更新。具体配置方式请参考Git仓库服务商的文档。配置Caddy作为前置代理一部分代理工具，比如v2ray，支持使用一个HTTP服务器作为其前置代理，Caddy就可以实现这样的功能。本示例中我配置Caddy作为v2ray的WebSocket代理，配置文件片段如下：1234proxy /v2ray localhost:12345 &#123; websocket header_upstream -Origin&#125;这段配置指定了将/v2ray这个路径作为localhost:12345这个地址的前置代理，代理协议为websocket。具体的配置方法请参考被代理程序的文档。配置开机自启动hook.service插件可以一键生成systemd格式的自启动配置文件，只需要如下命令即可完成配置：1caddy -service install -conf /etc/caddy/Caddyfile注意将-conf参数的值指向实际的Caddyfile的路径。结束至此，一个可以正常提供服务的Caddy服务器就配置完成了，现在Caddy可以提供正常的HTTP和HTTPS访问，并且会自动申请和续订HTTPS证书，在远端Git仓库有更新之后，Caddy也会自动更新本地的文件，一切都变成了自动化操作，正常情况下完全可以实现无人值守运行。怎么样，是不是很方便？]]></content>
      <categories>
        <category>工具</category>
        <category>Caddy</category>
      </categories>
      <tags>
        <tag>Caddy</tag>
        <tag>WebServer</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[在macOS中搭建自己的DNS服务器]]></title>
    <url>%2Ftools%2Fdnsmasq%2Fbuild-dns-server-on-macos.html</url>
    <content type="text"><![CDATA[最近实验了一下配置nginx多站点，顺便也给自己跑在本机上的几个服务上了个域名(当然是直接用Hosts强行解析到127.0.0.1的……)。但是吧，用Hosts强行解析，总觉得有点别扭，所以试着在本机搭一个DNS服务器。前提条件一台安装有macOS的电脑(不过，本文使用的dnsmasq在任何一个UNIX-like操作系统上也可以使用，所以要说成”一台安装有UNIX-like操作系统的电脑”也可以。至于Windows？抱歉我懒得去试。)Homebrew或类似的包管理工具(或者您要是愿意，编译安装也不是不可以，只要您能解决一路上遇到的问题)一个终端模拟器安装安装过程很简单，使用包管理工具安装即可1brew install dnsmasq配置安装成功之后，编辑/usr/local/etc/dnsmasq.conf文件，修改如下内容：1234567891011121314# Never forward plain names (without a dot or domain part)domain-needed# Never forward addresses in the non-routed address spaces.bogus-priv# 将所有.local的域名全部解析到本机回环地址address=/local/127.0.0.1address=/local/::1# 不读入/etc/hostsno-hosts# 如果不想dnsmasq载入/etc/resolv.conf，则解除该行注释#no-resolv然后我这里希望仍然使用路由器作为主要的DNS服务器，dnsmasq仅用来解析.local域名，所以还需要配置系统的/etc/resolver。注意：这一步操作仅在macOS中测试通过，不保证其他操作系统下的可用性12345# 首先创建/etc/resolver目录sudo mkdir -p /etc/resolver# 然后配置local域名使用127.0.0.1上的DNS解析echo "nameserver 127.0.0.1" &gt; local测试在这之前，我已经在本机配置了nginx服务器，并将Aria2前端配置了域名aria.boris1993.local，所以我使用浏览器直接访问这个域名，打开成功，Q.E.D.注意：nslookup貌似不会读取/etc/resolver的配置，至少在我的电脑上，nslookup aria.boris1993.local的结果是NXDOMAIN后续果然，没文化真可怕。现在得知，macOS支持mDNS，系统会取电脑的主机名，将其转为全小写，并使用横线替换空格，最后在其后面附加.local，来作为本机的域名。比如我的主机名是Boris-MacBook Pro，那么系统生成的本机域名就是boris-macbook-pro.local，使用这个域名就可以访问本机的服务了。上面这一顿操作猛如虎，白干了，23333]]></content>
      <categories>
        <category>工具</category>
        <category>dnsmasq</category>
      </categories>
      <tags>
        <tag>DNS Server</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[搭建ELK日志平台 - 安装Kibana]]></title>
    <url>%2Ftools%2Felk%2Finstall-elk-part-kibana.html</url>
    <content type="text"><![CDATA[上一次我们安装好了Elastic Search和Logstash，本次我们继续安装Kibana。安装KibanaKibana也提供了RPM安装包，所以还是一样的套路：1sudo rpm -ivh kibana-6.2.2-x86_64.rpm配置Kibana及防火墙编辑/etc/kibana.yml这里比较关键的一点，是要指定Elastic Search的位置。如果Elastic Search是安装在本机，并监听默认的9200端口的话，则不需要修改该配置。12# The URL of the Elasticsearch instance to use for all your queries.#elasticsearch.url: "http://localhost:9200"另外Kibana默认仅能从本机访问，若要开放给局域网，还需要修改Kibana监听的地址和端口号，并配置防火墙允许该端口通信：12345678# Kibana is served by a back end server. This setting specifies the port to use.#server.port: 5601# Specifies the address to which the Kibana server will bind. IP addresses and host names are both valid values.# The default is 'localhost', which usually means remote machines will not be able to connect.# To allow connections from remote users, set this parameter to a non-loopback address.# 如果要绑定到特定的某一块网卡，那么就将这里的地址设为那块网卡的IP地址server.host: "0.0.0.0"Cent OS 7使用firewalld管理防火墙，所以使用如下命令开放Kibana的端口：12sudo firewall-cmd --zone=public --add-port=5601/tcp --permanentsudo firewall-cmd --reload启动Kibana我们这里同样使用systemd来管理Kibana的起停和自启动。12sudo systemctl enable kibanasudo systemctl start kibana然后即可使用浏览器访问Kibana配置index patternKibana启动后，会要求配置索引，根据提示步骤配置即可。配置过程结束后，可到Discover页检查是否读到数据。参考文档Kibana User Guide]]></content>
      <categories>
        <category>工具</category>
        <category>ELK</category>
      </categories>
      <tags>
        <tag>ELK</tag>
        <tag>Kibana</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[搭建ELK日志平台 - 安装Logstash]]></title>
    <url>%2Ftools%2Felk%2Finstall-elk-part-logstash.html</url>
    <content type="text"><![CDATA[上回书说道，我们已经安装好了Elastic Search。那么这次，我们继续安装Logstash。安装Logstash为了安装方便，本次依旧选择使用RPM包安装。1sudo rpm -ivh logstash-6.2.2.rpm安装结束后，运行Logstash以检查安装是否成功。使用如下命令启动Logstash，并配置输入源为基本输入(stdin)，以及输出到基本输出(stdout)：12# 因为使用RPM方式安装，导致/usr/share/logstash/data仅root才可写入，所以需要使用sudo环境sudo /usr/share/logstash/bin/logstash -e 'input&#123; stdin&#123;&#125; &#125; output&#123; stdout&#123;&#125; &#125;'在日志滚动停止后，随意输入一些字符串，比如”hello world”，并回车，检查输出：12hello world2018-02-26T07:18:07.904Z localhost.localdomain hello world可见Logstash成功从stdin读取到了输入，并打印到了stdout，证实安装成功。配置LogstashLogstash系统配置编辑/etc/logstash/logstash.yml，修改Logstash系统级配置。12# 配置节点名，若未配置则默认取本机主机名作为节点名node.name: elk-logstash-node-0其他配置项略，如有需要请参考Logstash Reference。日志输入输出配置这里我们配置让Logstash接收Cent OS的系统日志。1234567891011121314151617input &#123; file &#123; path =&gt; &quot;/var/log/messages*&quot; type =&gt; &quot;syslog&quot; &#125;&#125;# Filter not needed. Commented out.#filter &#123;##&#125;output &#123; elasticsearch &#123; hosts =&gt; &quot;localhost:9200&quot; &#125;&#125;另外，本例中还需要配置Logstash以root权限运行以读取系统日志(messages文件默认权限为600)，实际使用时需要按照实际需求配置。编辑/etc/systemd/system/logstash.service，修改user和group为root1234567891011121314151617181920[Unit]Description=logstash[Service]Type=simpleUser=rootGroup=root# Load env vars from /etc/default/ and /etc/sysconfig/ if they exist.# Prefixing the path with '-' makes it try to load, but if the file doesn't# exist, it continues onward.EnvironmentFile=-/etc/default/logstashEnvironmentFile=-/etc/sysconfig/logstashExecStart=/usr/share/logstash/bin/logstash "--path.settings" "/etc/logstash"Restart=alwaysWorkingDirectory=/Nice=19LimitNOFILE=16384[Install]WantedBy=multi-user.target然后使systemd重新加载配置文件并重新启动Logstash12sudo systemctl daemon-reloadsudo systemctl restart logstash使Logstash开机自启动由于RPM包安装时已经放好了自启动的配置文件，我们只需要在systemd中激活它就可以了。12sudo systemctl enable logstashsudo systemctl start logstash参考文档Logstash Reference]]></content>
      <categories>
        <category>工具</category>
        <category>ELK</category>
      </categories>
      <tags>
        <tag>ELK</tag>
        <tag>Logstash</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[搭建ELK日志平台 - 安装Elastic Search]]></title>
    <url>%2Ftools%2Felk%2Finstall-elk-part-es.html</url>
    <content type="text"><![CDATA[最近搭建了一次ELK日志平台，在此记录一下安装步骤。由于本次模拟的是服务器不能连接互联网的情况，所以全部安装步骤皆使用RPM或tar包的方式安装。本文主要记录安装Elastic Search的过程。安装JRE首先这套平台是基于Java的，所以Java运行环境当然是不能少。但因为这上面不涉及Java的开发，所以不需要装JDK，装JRE就够了，还能省下一些磁盘空间。我这里选择JRE8u161。我这次选择使用RPM包安装。1sudo rpm -ivh jre-8u161-linux-x64.rpm安装完毕后，验证安装是否成功：12345# 检验当前用户下是否安装成功java -version# 检验sudo环境下是否安装成功sudo java -version若都输出如下内容则说明安装成功：123java version &quot;1.8.0_161&quot;Java(TM) SE Runtime Environment (build 1.8.0_161-b12)Java HotSpot(TM) 64-Bit Server VM (build 25.161-b12, mixed mode)至此Java环境配置完成安装Elastic Search安装过程使用RPM包安装直接使用rpm命令安装该RPM包1sudo rpm --install elasticsearch-6.2.2.rpmCentOS 7使用systemd管理开机自启动项，而且安装过程已经配置好针对systemd的启动脚本，使用如下命令激活12sudo systemctl daemon-reloadsudo systemctl enable elasticsearch.service使用tar.gz包安装首先新建一个名为elk的用户，用于运行ELK平台1useradd -m elk下载好Elastic Search的安装包，将其复制到/opt并解压，然后试运行12345678910sudo cp elasticsearch-6.1.3.tar.gz /optcd /optsudo tar xvzf elasticsearch-6.1.3.tar.gz# 需要将Elastic Search目录的所有权设为将要运行该软件的用户# Elastic Search不允许以root用户运行，安全方面亦不建议以root权限运行程序sudo chown -R elk:elk elasticsearch-6.1.3cd elasticsearch-6.1.3/bin./elelasticsearch启动成功后，在另一终端使用curl尝试连接Elastic Search1curl http://127.0.0.1:9200若有如下返回，则说明Elastic Search启动成功123456789101112131415&#123; "name" : "LWmSd17", "cluster_name" : "elasticsearch", "cluster_uuid" : "lkbXufQpQuiLaE5kzVKAeA", "version" : &#123; "number" : "6.1.3", "build_hash" : "af51318", "build_date" : "2018-01-26T18:22:55.523Z", "build_snapshot" : false, "lucene_version" : "7.1.0", "minimum_wire_compatibility_version" : "5.6.0", "minimum_index_compatibility_version" : "5.0.0" &#125;, "tagline" : "You Know, for Search"&#125;安装后的配置系统配置文件修改Elastic Search需要调整文件描述符大于65535、最大线程数大于4096、以及vm.max_map_count大于262144。所以修改操作系统配置文件以满足此要求。在/etc/security/limits.conf插入如下内容1234* hard nofile 65536* soft nofile 65536* hard nproc 4096* soft nproc 4096在/etc/sysctl.conf中插入如下内容1vm.max_map_count=262144然后执行sysctl -p，并重新登录，使配置生效。若配置成功，则可见Elastic Search启动过程中相关的警告信息将不再出现。Elastic Search配置文件修改以下文件位置根据安装方法不同而不同若使用RPM包方式安装，则文件位于/etc/elasticsearch若使用tar包方式安装，则文件位于解压出来的目录的conf文件夹中修改cluster.name我们应当将集群名设置成一个能清晰地表明该集群的作用的名字，如logging-prod。修改node.name为每个Elastic Search节点起一个清晰易懂的名字绝不会是一件坏事。节点名字可以是一个自定义的名字，如prod-data-2，也可以使用${HOSTNAME}来把本机的主机名作为该节点的节点名。其他详细配置要想了解更多配置，可以参考Elasticsearch Reference 的Set up Elasticsearch部分。配置自动启动如果使用RPM包方式安装，则此步可忽略。若使用tar包方式安装，则进入Elastic Search的bin目录后运行1./elasticsearch -d -p ../logs/elasticsearch.pid使Elastic Search以daemon模式启动并监控启动过程。参考文献Elastic Search Installation Guide]]></content>
      <categories>
        <category>工具</category>
        <category>ELK</category>
      </categories>
      <tags>
        <tag>ELK</tag>
        <tag>Elastic Search</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[如何将项目部署至Tomcat的根下]]></title>
    <url>%2Ftools%2Ftomcat%2Ftomcat-deploy-to-root.html</url>
    <content type="text"><![CDATA[有两种方法可以实现将项目部署到Tomcat的根下。删掉自带的ROOT/目录，然后将项目的war包重命名为ROOT.war将项目正常部署(假设war包名为your_project.war)，然后修改conf/server.xml中的Context Root为如下内容：1&lt;Context path="" docBase="your_project" debug="0" reloadable="true"&gt;&lt;/Context&gt;参考文献：https://stackoverflow.com/questions/5328518/deploying-my-application-at-the-root-in-tomcat]]></content>
      <categories>
        <category>工具</category>
        <category>Tomcat</category>
      </categories>
      <tags>
        <tag>Tomcat</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用SSH config简化SSH连接]]></title>
    <url>%2Ftools%2Fssh%2Fssh-config-file.html</url>
    <content type="text"><![CDATA[如果你有很多的服务器要连接，如果对你来说记住那些服务器的地址、端口实在是一种痛苦，如果你一直在寻找一种能够简化在命令行下连接SSH服务器的办法，那么，本文将给你提供一种解决问题的思路，那就是，使用SSH的config文件。SSH config文件是什么Open SSH客户端配置文件，允许你以配置项的形式，记录各个服务器的连接信息，并允许你使用一个定义好的别名来代替其对应的ssh命令参数。SSH config文件该怎么用创建SSH config文件通常来说，该文件会出现在两个地方，一个是/etc/ssh/ssh_config，一个是~/.ssh/config。/etc/ssh/ssh_config文件通常用来定义全局范围上的SSH客户端参数，而~/.ssh/config则被用来定义每个用户自己的SSH客户端的配置。我们将要修改的，就是位于用户目录下的config文件。如果~/.ssh/config文件不存在，那么也不用着急，这是正常的，只需要执行如下命令，即可新建一个空白的config文件1touch ~/.ssh/config编写config条目假如说，我们想连接到一台服务器，它的地址是example.server.com，端口号是2222，以用户admin登陆，并使用~/.ssh/id_rsa这个私钥验证身份。那么，我们需要在命令行里输入：1ssh admin@example.server.com -p 2222 -i ~/.ssh/id_rsa嗯好吧，-i参数可以省略，但即使这样，命令还是很长，对吧？那么我们把这个服务器的连接参数写到config文件里，就变成了这个样子：1234567# 此处我为了美观起见，给每个子条目都缩进了一层，实际使用时缩进不影响文件的效果。Host sample Hostname example.server.com Port 2222 User admin Identityfile ~/.ssh/id_rsa嗯，在这里，它还有了一个新名字，叫sample。然后，我们只需要：1ssh sample就可以连接到这台主机了。这玩意有意思，我还想了解更多！好吧，为了满足你的好奇心，我这里为你提供了3篇博客供你参考。当然，这三篇博客也是我编写本文时的参考文档。多个 SSH KEY 的管理How To Configure Custom Connection Options for your SSH ClientSimplify Your Life With an SSH Config File另外，您也可以阅读ssh_config的手册页，来获得最原始的信息，阅读该手册的命令是：1man ssh_config]]></content>
      <categories>
        <category>工具</category>
        <category>SSH</category>
      </categories>
      <tags>
        <tag>Shell</tag>
        <tag>SSH</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[常用lsof命令备忘]]></title>
    <url>%2Flinux%2Fuseful-lsof-commands.html</url>
    <content type="text"><![CDATA[记录lsof命令常见用法备忘网络12# 显示所有网络连接lsof -i根据协议类型筛选1234567891011# 仅显示IPv4网络连接lsof -i 4# 仅显示IPv6网络连接lsof -i 6# 仅显示TCP连接lsof -iTCP# 仅显示UDP连接lsof -iUDP根据目标地址和端口号筛选12345678# 根据目标地址筛选lsof -i@$&#123;HOSTNAME_OR_IP_ADDRESS&#125;# 根据端口号筛选lsof -i :$&#123;PORT_NUMBER&#125;# 组合lsof -i@$&#123;HOSTNAME_OR_IP_ADDRESS&#125;:$&#123;PORT_NUMBER&#125;根据端口状态筛选12345lsof -i -sTCP:$&#123;STATE&#125;# 示例lsof -i -sTCP:LISTENlsof -i -sTCP:ESTABLISHED查看某进程端口占用1lsof -p $&#123;PID&#125;用户12345# 显示当前用户打开的文件lsof -u $&#123;USER&#125;# 显示除当前用户以外的用户打开的文件lsof -u ^$&#123;USER&#125;进程12345# 仅显示PID而不是所有输出信息lsof -t# 根据程序名筛选lsof -c $&#123;COMMAND&#125;]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Shell</tag>
        <tag>lsof</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Git连接多个远程仓库]]></title>
    <url>%2Ftools%2Fgit%2Fpush-to-multi-git-repo.html</url>
    <content type="text"><![CDATA[有时候我们可能会需要push到多个远程仓库，比如同时链接多个代码托管平台的账号，那么可以参考本文所述的方法配置。保险起见在操作之前请先做好备份工作，毕竟数据无价。方法1 - 添加多个远程仓库比如要链接两个 Github 仓库，分别是 github1 和 github2，那么：1234567891011121314151617# 添加 github1git remote add github1 https://github.com/username/github1.git# 添加 github2git remote add github2 https://github.com/username/github2.git# 提交到 github1git push github1 master# 提交到 github2git push github2 master# 从 github1 更新git pull github1 master# 从 github2 更新git pull github2 master方法2 - 添加同名多个远程仓库1234567891011121314# 添加一个远程仓库git remote add origin https://github.com/username/github1.git# 然后分别设定push URLgit remote set-url --add --push origin https://github.com/username/github1.gitgit remote set-url --add --push origin https://github.com/username/github2.git# 检查远程仓库配置git remote -v# 若配置正确，则结果应当包含一个fetch路径和两个push路径# 向所有远程仓库推送git push origin master方法3 - 直接修改.git/config文件用文本编辑器打开本地仓库的 .git/config 文件，然后修改其中的远程仓库配置123456# 假设当前的远程仓库名为 origin[remote "origin"] url = https://github.com/username/github1.git fetch = +refs/heads/*:refs/remotes/github/* pushurl = https://github.com/username/github1.git pushurl = https://github.com/username/github2.git然后直接使用1git push origin master即可提交至所有版本库]]></content>
      <categories>
        <category>工具</category>
        <category>Git</category>
      </categories>
      <tags>
        <tag>Git</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[为Maven配置阿里云镜像和代理服务器]]></title>
    <url>%2Ftools%2Fmaven%2Fmaven-configure-mirrors.html</url>
    <content type="text"><![CDATA[Maven中央仓库在国内的速度简直是感人，好在阿里云提供了Maven中央仓库的镜像，配置方法在此记录备用。打开Maven的用户配置文件(默认位置在 ~/.m2/settings.xml)，在mirrrors段加入如下内容：1234567891011&lt;mirror&gt; &lt;!-- 镜像ID，自行定义 --&gt; &lt;id&gt;nexus-aliyun&lt;/id&gt; &lt;!-- 该镜像对应的仓库名，central即中央仓库 --&gt; &lt;!-- 个人建议不要将其设为星号 [注] --&gt; &lt;mirrorOf&gt;central&lt;/mirrorOf&gt; &lt;!-- 镜像名，自行定义 --&gt; &lt;name&gt;Nexus aliyun&lt;/name&gt; &lt;!-- 镜像的地址 --&gt; &lt;url&gt;http://maven.aliyun.com/nexus/content/groups/public&lt;/url&gt; &lt;/mirror&gt;[注] 有些教程在 mirrorOf 字段中填写的是星号，但根据Using Mirrors for Repositories中 Using A Single Repository 一段的解释，这将会强制使用该镜像处理所有的仓库请求，而阿里云镜像并不能达到这样的效果，所以个人建议仅使用该镜像代理中央仓库的请求。]]></content>
      <categories>
        <category>工具</category>
        <category>Maven</category>
      </categories>
      <tags>
        <tag>Maven</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[在macOS中安装shadowsocks-libev和simple-obfs]]></title>
    <url>%2Ftools%2Fshadowsocks%2Finstall-shadowsocks-on-macosx.html</url>
    <content type="text"><![CDATA[最近入手了一台MacBook，自然必备的工具是不能少的。安装过程也遇到了些新的问题，在此记录以备不时之需。安装 HomeBrew1ruby -e "$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install)"安装 Shadowsocks1brew install shadowsocks-libev安装 simple-obfs1brew install simple-obfs创建配置文件12cd /usr/local/etcvim shadowsocks-libev.json然后将以下内容复制到shadowsocks-libev.json，其中参数根据实际情况修改，plugin位置需要写绝对路径，路径可以通过 which simple-obfs 得到123456789101112&#123; "server":"SERVER_ADDRESS", "server_port":3128, "local_address":"0.0.0.0", "local_port":1080, "password":"PASSWORD", "method":"chacha20-ietf-poly1305", "fast_open":true, "interface":"en0", "plugin":"/usr/local/bin/obfs-local", "plugin_opts":"obfs=http;obfs-host=cloudfront.net"&#125;修改自启动配置文件1vim /usr/local/opt/shadowsocks-libev/homebrew.mxcl.shadowsocks-libev.plist修改-c参数的值，将其设为配置文件所在的绝对路径，如/usr/local/etc/shadowsocks-libev.json12345678910111213141516171819&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;!DOCTYPE plist PUBLIC "-//Apple//DTD PLIST 1.0//EN" "http://www.apple.com/DTDs/PropertyList-1.0.dtd"&gt;&lt;plist version="1.0"&gt; &lt;dict&gt; &lt;key&gt;Label&lt;/key&gt; &lt;string&gt;homebrew.mxcl.shadowsocks-libev&lt;/string&gt; &lt;key&gt;ProgramArguments&lt;/key&gt; &lt;array&gt; &lt;string&gt;/usr/local/opt/shadowsocks-libev/bin/ss-local&lt;/string&gt; &lt;string&gt;-c&lt;/string&gt; &lt;string&gt;/usr/local/etc/shadowsocks-libev.json&lt;/string&gt; &lt;string&gt;-u&lt;/string&gt; &lt;/array&gt; &lt;key&gt;RunAtLoad&lt;/key&gt; &lt;true/&gt; &lt;key&gt;KeepAlive&lt;/key&gt; &lt;true/&gt; &lt;/dict&gt;&lt;/plist&gt;添加开机自启动首先安装 brew services1brew services然后启用 Shadowsocks 的自启动配置文件1brew services start shadowsocks-libev至此在macOS X上安装Shadowsocks和simple-obfs结束，接下来就可以使用SOCKS或HTTP代理客户端使用该代理。如果要配置系统使用PAC，可以继续进行下列步骤。安装 nginx因为macOS的PAC仅接受HTTP位置，所以需要安装nginx来将本机作为一个HTTP服务器。1brew install nginx使用 PAC 文件配置系统代理使用 ProxyOmega 生成PAC脚本使用Chrome插件SwitchyOmega生成PAC文件。同时，使用该插件配置Chrome浏览器的代理。具体生成方法为：进入SwitchyOmega中Shadowsocks的配置条目在配置好协议、服务器地址、端口、以及Bypass List后，点击右上角的“生成PAC”(Export PAC)将生成的 PAC 文件复制到nginx的html目录，如“html/pac/autoproxy.pac”配置系统代理将系统代理的代理自动配置(Automatic Proxy Configuration)启用，URL填写http://localhost:8080/pac/autoproxy.pac (此处的端口号需按照你实际的 nginx 配置填写，默认为 8080；服务器路径也需要按照 PAC 文件的实际位置修改，此处的位置与上一步的配置相对应。)检查是否成功生效打开Safari，访问一个测试站点，如Google，如能正常访问则说明配置成功。]]></content>
      <categories>
        <category>工具</category>
        <category>Shadowsocks</category>
      </categories>
      <tags>
        <tag>Shadowsocks</tag>
        <tag>Simple Obfs</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Ubuntu中安装ShadowSocks及混淆插件的脚本]]></title>
    <url>%2Ftools%2Fshadowsocks%2Finstall-shadowsocks-with-obfs.html</url>
    <content type="text"><![CDATA[以下脚本目的在于便利自己安装该工具，并不是一个成熟的版本，如要使用，本人不承担任何可能带来的后果。该脚本目前仅能用于Ubuntu Linux。在Ubuntu Server 17.04下测试通过。另外您可以在我的Gist中下载该脚本123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104#!/bin/bashif [[ `id -u` -ne 0 ]]; then echo "This script can only be run as root" exit 1fi# Installation of basic build dependenciesecho 'Prepare to install dependencies...'apt-get install --no-install-recommends --assume-yes gettext build-essential autoconf libtool libpcre3-dev asciidoc xmlto libev-dev libc-ares-dev automake# Installation of Libsodiumecho 'Prepare to install libsodium...'export LIBSODIUM_VER=1.0.13wget https://download.libsodium.org/libsodium/releases/libsodium-$LIBSODIUM_VER.tar.gztar xvf libsodium-$LIBSODIUM_VER.tar.gzpushd libsodium-$LIBSODIUM_VER./configure --prefix=/usr &amp;&amp; makemake installpopdldconfig# Installation of MbedTLSecho 'Prepare to install MbedTLS...'export MBEDTLS_VER=2.6.0wget https://tls.mbed.org/download/mbedtls-$MBEDTLS_VER-gpl.tgztar xvf mbedtls-$MBEDTLS_VER-gpl.tgzpushd mbedtls-$MBEDTLS_VERmake SHARED=1 CFLAGS=-fPICmake DESTDIR=/usr installpopdldconfig# Install Shadowsocksecho 'Prepare to install ShadowSocks...'git clone https://github.com/shadowsocks/shadowsocks-libev.gitpushd shadowsocks-libevgit submodule update --init --recursive./autogen.sh &amp;&amp; ./configure --prefix=/usr &amp;&amp; makemake installpushd debiancp shadowsocks-libev-server@.service /etc/systemd/systempopd# Install simple-obfsecho 'Prepare to install simple-obfs'apt-get install --no-install-recommends --assume-yes build-essential autoconf libtool libssl-dev libpcre3-dev libev-dev asciidoc xmlto automakegit clone https://github.com/shadowsocks/simple-obfs.gitpushd simple-obfsgit submodule update --init --recursive./autogen.sh./configure &amp;&amp; makemake installpopd# Install Apache2 for acting as a fallback serverecho "Installing Apache2"apt-get install --assume-yes apache2# Post installation process## Generate config.jsonecho "Generating config.json"if [ ! -d /etc/shadowsocks-libev ]; then mkdir /etc/shadowsocks-libevfipushd /etc/shadowsocks-libevread -p "Server address [0.0.0.0]: " SERVER_ADDRESSSERVER_ADDRESS=$&#123;SERVER_ADDRESS:-0.0.0.0&#125;read -p "Server port [8388]: " SERVER_PORTSERVER_PORT=$&#123;SERVER_PORT:-8388&#125;read -p "Local port [1080]: " LOCAL_PORTLOCAL_PORT=$&#123;LOCAL_PORT:-1080&#125;read -p "Password [password]: " PASSWORDPASSWORD=$&#123;PASSWORD:-password&#125;echo "&#123;" &gt; config.jsonecho -e "\t\"server\":\""$SERVER_ADDRESS"\"," &gt;&gt; config.jsonecho -e "\t\"server_port\":"$SERVER_PORT"," &gt;&gt; config.jsonecho -e "\t\"local_port\":"$LOCAL_PORT"," &gt;&gt; config.jsonecho -e "\t\"password\":\""$PASSWORD"\"," &gt;&gt; config.jsonecho -e "\t\"timeout\":60," &gt;&gt; config.jsonecho -e "\t\"method\":\"chacha20-ietf-poly1305\"," &gt;&gt; config.jsonecho -e "\t\"plugin\":\"obfs-server\"," &gt;&gt; config.jsonecho -e "\t\"plugin_opts\":\"obfs=http;failover=127.0.0.1:80\"" &gt;&gt; config.jsonecho "&#125;" &gt;&gt; config.jsonpopd## Enable systemd serviceecho "Enabling and starting service"systemctl enable shadowsocks-libev-server@config## Start servicesystemctl start shadowsocks-libev-server@configecho "Finished"]]></content>
      <categories>
        <category>工具</category>
        <category>Shadowsocks</category>
      </categories>
      <tags>
        <tag>Shadowsocks</tag>
        <tag>Simple Obfs</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[更改Google Play市场使用的区域]]></title>
    <url>%2Fothers%2Fchange-google-play-market-location.html</url>
    <content type="text"><![CDATA[首先需要注意的一点是，目前所谓Market Unlocker等伪装工具已经失效了，Google判定你商店区域的依据之一，是你登记在Google Payments中的当前住址。你登记的住址在哪，你的商店就在哪。那么事情就简单了，如果要转区的话，在保证你目前该账户 余额小于$10(或等额货币) 时，更改Google Payments中该账户当前住址为你想要的地区的住址即可，然后在手持设备上 删除这个账户 并 重新登录 ，然后就可以看到转区成功了。不过转区前区域的余额是无法在转区后的区域中使用的，比如你从美区转到日区，那么你账户里的美刀就冻在里面花不出去了，除非你再转回美区。参考资料：GOOGLE 帳戶的地區判定對使用者有哪些影響]]></content>
      <categories>
        <category>其他</category>
      </categories>
      <tags>
        <tag>Google</tag>
        <tag>Google Play</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用TRANSMIT和RECEIVE命令打包、解包文件]]></title>
    <url>%2Fothers%2Fzos-xmit.html</url>
    <content type="text"><![CDATA[当需要从z/OS中下载一个PS文件，或者下载一个Member时，我们可以简单地使用FTP或者IND$FILE将文件下载回来，但是如果想要下载一整个PDS呢？总不能一个个地去下载吧，此时，XMIT命令就派上用场了。TRANSMIT命令TRANSMIT命令用于将指定文件打包成XMIT档案以方便传输。语法使用一条命令前，必须要知道这条命令的语法。那么XMIT命令的语法如下：注：TRANSMIT命令可以简写为XMIT1XMIT (nodeid.username) DSNAME(&apos;input.dataset.name&apos;) [MEMBERS(member1, member2, ...)] OUTDSN(&apos;output.dataset.name&apos;)其中：(nodeid.username) 为目标机器的JES2 Node名，以及接收用户的TSOID，不过亲测在这里写自己的Node名和TSOID也能正常使用。通常来说，本机的Node name为N1DSNAME 为要打包的数据集名字如果只打包这个PDS中的一部分member，则可以在MEMBERS参数中指定。因为目前还没有用过，所以不知道可不可以指定通配符OUTDSN 为打包之后输出文件的数据集名字TRANSMIT命令的官方手册在 这里 ，完整的TRANSMIT命令的语法在 这里 ，参数的详细说明在 这里 。另外，根据IBM员工 Isabel Arnold 的建议，在打包之前最好先创建一个 DSORG=FB,LRECL=80,BLKSIZE=3120 的文件供TRANSMIT用作输出文件。示例如果我想要打包 IBMUSER.COBOL.SRC 这个PDS中的所有member，打包输出文件名为 IBMUSER.COBOL.SRC.XMIT 那么命令可以这样写：1XMIT (N1.IBMUSER) DSN(&apos;IBMUSER.COBOL.SRC&apos;) OUTDSN(&apos;IBMUSER.COBOL.SRC.XMIT&apos;)RECEIVE命令RECEIVE命令用于解包XMIT档案。语法同样，这里先展示RECEIVE命令的语法：1RECEIVE INDSN(&apos;xmit.dataset.name&apos;)其中 INDSN 为XMIT档案的文件名。示例如果现在我在另一台主机上接收到了这个XMIT档案，那么我可以使用如下命令解包这个文件：1RECEIVE INDSN(&apos;IBMUSER.COBOL.SRC.XMIT&apos;)在RECEIVE命令成功识别指定的XMIT档案之后，会输出如下信息：12INMR901I Dataset IBMUSER.COBOL.SRC from IBMUSER on NODENAMEINMR906A Enter restore parameters or &apos;DELETE&apos; or &apos;END&apos; +此时RECEIVE命令等待用户输入解包信息，我们可以回复如下命令：1DA(&apos;IBMUSER.COBOL.SRC&apos;)来将内容解包至 IBMUSER.COBOL.SRC 中。此处需要注意的是，如果目标数据集不存在，则RECEIVE会自动创建一个同名数据集，但接下来的解包过程可能会因这个数据集的空间不够用于存放解包出来的文件而报出 ABEND B37 。为避免这种情况发生，建议在RECEIVE前预先创建好需要的数据集，并保证数据集的空间足够。在输入DA命令后，RECEIVE将会试图向指定位置解包，并且会将结果输出至终端。对INMR906A消息的回复对 INMR906A 的消息，有如下三种回复：DATASET(‘output.dataset.name’) - 将XMIT档案解包至指定位置，可简写为DA()DELETE - 删除该XMIT档案END - 退出，不执行任何操作参考文档TRANSMIT commandTRANSMIT command syntaxTRANSMIT command operandsRECEIVE commandReceiving Data Sets with the RECEIVE CommandTransfering Load Modules between Mainframes using XMIT and ftp]]></content>
      <categories>
        <category>其他</category>
      </categories>
      <tags>
        <tag>Mainframe</tag>
        <tag>z/OS</tag>
        <tag>TRANSMIT</tag>
        <tag>XMIT</tag>
        <tag>RECEIVE</tag>
      </tags>
  </entry>
</search>
